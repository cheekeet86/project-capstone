{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "\n",
    "- [Header](#Header)\n",
    "- [Import Data](#Import-Data)\n",
    "- [Functions](#Functions)\n",
    "\n",
    "\n",
    "- [Drop Rows](#Drop-Rows)\n",
    "- [Select and Merge Sports](#Select-and-Merge-Sports)\n",
    "- [Select Features](#Select-Features)\n",
    "\n",
    "- [Plot df_model](#Plot-df_model)\n",
    "- [Create Features and Target](#Create-Features-and-Target)\n",
    "- [Handle Imbalanced Data](#Handle-Imbalanced-Data)\n",
    "\n",
    "\n",
    "- [Logistic Regression Model](#Logistic-Regression-Model)\n",
    "- [KNN Model](#KNN-Model)\n",
    "- [DTC Model](#DTC-Model)\n",
    "- [RTC Model](#RTC-Model)\n",
    "- [SVC Model](#SVC-Model)\n",
    "\n",
    "\n",
    "- [Combine Model Predictions](#Combine-Model-Predictions)\n",
    "- [VotingClassifier Model](#VotingClassifier-Model)\n",
    "- [GridSearch Model](#GridSearch-Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "\n",
    "# maths\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# visual\n",
    "#from matplotlib_venn import venn2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pydotplus\n",
    "\n",
    "# modelling\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler,PolynomialFeatures,LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, roc_curve,confusion_matrix,accuracy_score,r2_score,mean_squared_error,cohen_kappa_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import resample, shuffle\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier,export_graphviz\n",
    "from sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier,RandomForestRegressor,GradientBoostingClassifier,VotingClassifier\n",
    "from sklearn.externals.six import StringIO\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Others\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "\n",
    "raw_path = '../../data/0_raw/fitrec/' \n",
    "input_path = '../../data/1_input/fitrec/'\n",
    "clean_path = '../../data/2_clean/fitrec/' \n",
    "preprocess_path = '../../data/3_preprocess/fitrec/' \n",
    "output_path = '../../data/4_output/fitrec/'\n",
    "\n",
    "sports_path = '../../data/1_input/sports/' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'userId', 'gender', 'sport', 'url', 'time_start', 'time_end',\n",
       "       'time_dur', 'lat_start', 'lon_start', 'lat_end', 'lon_end', 'alt_avg',\n",
       "       'alt_min', 'alt_05', 'alt_25', 'alt_75', 'alt_95', 'alt_max',\n",
       "       'alt_diff', 'hr_avg', 'hr_min', 'hr_05', 'hr_25', 'hr_75', 'hr_95',\n",
       "       'hr_max', 'hr_outof', 'hr_fatburn', 'hr_cardio', 'hr_peak', 'spd_avg',\n",
       "       'spd_min', 'spd_05', 'spd_25', 'spd_75', 'spd_95', 'spd_max', 'spd_low',\n",
       "       'spd_med', 'spd_high', 'spd_vhigh', 'impute'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import summary csv\n",
    "\n",
    "#file = 'endomondoHR_proper_summary.csv'\n",
    "#file = 'endomondoHR_proper_dist_spd_summary.csv'\n",
    "file = 'endomondoHR_proper_dist_spd_time_summary.csv'\n",
    "\n",
    "in_path = clean_path + file\n",
    "\n",
    "df = pd.read_csv(in_path)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sport</th>\n",
       "      <th>sport_rename</th>\n",
       "      <th>type</th>\n",
       "      <th>venue</th>\n",
       "      <th>location_valid</th>\n",
       "      <th>distance_valid</th>\n",
       "      <th>speed_valid</th>\n",
       "      <th>speed_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aerobics</td>\n",
       "      <td>aerobics</td>\n",
       "      <td>gym</td>\n",
       "      <td>indoor</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>badminton</td>\n",
       "      <td>badminton</td>\n",
       "      <td>racket</td>\n",
       "      <td>indoor</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>basketball</td>\n",
       "      <td>basketball</td>\n",
       "      <td>team</td>\n",
       "      <td>outdoor/indoor</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bike</td>\n",
       "      <td>bike</td>\n",
       "      <td>aerobic</td>\n",
       "      <td>outdoor</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bike (transport)</td>\n",
       "      <td>bike</td>\n",
       "      <td>aerobic</td>\n",
       "      <td>outdoor</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>indoor cycling</td>\n",
       "      <td>bike</td>\n",
       "      <td>aerobic</td>\n",
       "      <td>indoor</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mountain bike</td>\n",
       "      <td>bike</td>\n",
       "      <td>aerobic</td>\n",
       "      <td>outdoor</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>circuit training</td>\n",
       "      <td>circuit training</td>\n",
       "      <td>aerobic</td>\n",
       "      <td>outdoor/indoor</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>climbing</td>\n",
       "      <td>climbing</td>\n",
       "      <td>aerobic</td>\n",
       "      <td>outdoor/indoor</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>core stability training</td>\n",
       "      <td>core stability training</td>\n",
       "      <td>indoor</td>\n",
       "      <td>indoor</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>elliptical</td>\n",
       "      <td>elliptical</td>\n",
       "      <td>gym</td>\n",
       "      <td>indoor</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>golf</td>\n",
       "      <td>golf</td>\n",
       "      <td>gentlemen</td>\n",
       "      <td>outdoor</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gymnastics</td>\n",
       "      <td>gymnastics</td>\n",
       "      <td>indoor</td>\n",
       "      <td>indoor</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hiking</td>\n",
       "      <td>hiking</td>\n",
       "      <td>aerobic</td>\n",
       "      <td>outdoor</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>horseback riding</td>\n",
       "      <td>horseback riding</td>\n",
       "      <td>gentlemen</td>\n",
       "      <td>outdoor</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>kayaking</td>\n",
       "      <td>kayaking</td>\n",
       "      <td>water</td>\n",
       "      <td>water</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>martial arts</td>\n",
       "      <td>martial arts</td>\n",
       "      <td>indoor</td>\n",
       "      <td>indoor</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>orienteering</td>\n",
       "      <td>orienteering</td>\n",
       "      <td>aerobic</td>\n",
       "      <td>outdoor</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rowing</td>\n",
       "      <td>rowing</td>\n",
       "      <td>water</td>\n",
       "      <td>water</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rugby</td>\n",
       "      <td>rugby</td>\n",
       "      <td>team</td>\n",
       "      <td>outdoor</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>run</td>\n",
       "      <td>run</td>\n",
       "      <td>aerobic</td>\n",
       "      <td>outdoor/indoor</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>treadmill running</td>\n",
       "      <td>run</td>\n",
       "      <td>aerobic</td>\n",
       "      <td>indoor</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sailing</td>\n",
       "      <td>sailing</td>\n",
       "      <td>water</td>\n",
       "      <td>water</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>skate</td>\n",
       "      <td>skate</td>\n",
       "      <td>aerobic</td>\n",
       "      <td>outdoor/indoor</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cross-country skiing</td>\n",
       "      <td>skiing</td>\n",
       "      <td>winter</td>\n",
       "      <td>winter</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>downhill skiing</td>\n",
       "      <td>skiing</td>\n",
       "      <td>winter</td>\n",
       "      <td>winter</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>roller skiing</td>\n",
       "      <td>skiing</td>\n",
       "      <td>winter</td>\n",
       "      <td>outdoor/indoor</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>snowboarding</td>\n",
       "      <td>snowboarding</td>\n",
       "      <td>winter</td>\n",
       "      <td>winter</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>snowshoeing</td>\n",
       "      <td>snowshoeing</td>\n",
       "      <td>winter</td>\n",
       "      <td>winter</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>soccer</td>\n",
       "      <td>soccer</td>\n",
       "      <td>team</td>\n",
       "      <td>outdoor</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>squash</td>\n",
       "      <td>squash</td>\n",
       "      <td>racket</td>\n",
       "      <td>indoor</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>stair climing</td>\n",
       "      <td>stair climbing</td>\n",
       "      <td>aerobic</td>\n",
       "      <td>outdoor/indoor</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>kite surfing</td>\n",
       "      <td>surfing</td>\n",
       "      <td>water</td>\n",
       "      <td>water</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>windsurfing</td>\n",
       "      <td>surfing</td>\n",
       "      <td>water</td>\n",
       "      <td>water</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>swimming</td>\n",
       "      <td>swimming</td>\n",
       "      <td>water</td>\n",
       "      <td>water</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>table tennis</td>\n",
       "      <td>table tennis</td>\n",
       "      <td>racket</td>\n",
       "      <td>indoor</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>tennis</td>\n",
       "      <td>tennis</td>\n",
       "      <td>racket</td>\n",
       "      <td>outdoor</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>fitness walking</td>\n",
       "      <td>walk</td>\n",
       "      <td>aerobic</td>\n",
       "      <td>outdoor/indoor</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>treadmill walking</td>\n",
       "      <td>walk</td>\n",
       "      <td>aerobic</td>\n",
       "      <td>indoor</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>walk</td>\n",
       "      <td>walk</td>\n",
       "      <td>aerobic</td>\n",
       "      <td>outdoor/indoor</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>weight training</td>\n",
       "      <td>weight training</td>\n",
       "      <td>gym</td>\n",
       "      <td>indoor</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>pilates</td>\n",
       "      <td>yoga</td>\n",
       "      <td>indoor</td>\n",
       "      <td>indoor</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>yoga</td>\n",
       "      <td>yoga</td>\n",
       "      <td>indoor</td>\n",
       "      <td>indoor</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      sport             sport_rename       type  \\\n",
       "0                  aerobics                 aerobics        gym   \n",
       "1                 badminton                badminton     racket   \n",
       "2                basketball               basketball       team   \n",
       "3                      bike                     bike    aerobic   \n",
       "4          bike (transport)                     bike    aerobic   \n",
       "5            indoor cycling                     bike    aerobic   \n",
       "6             mountain bike                     bike    aerobic   \n",
       "7          circuit training         circuit training    aerobic   \n",
       "8                  climbing                 climbing    aerobic   \n",
       "9   core stability training  core stability training     indoor   \n",
       "10               elliptical               elliptical        gym   \n",
       "11                     golf                     golf  gentlemen   \n",
       "12               gymnastics               gymnastics     indoor   \n",
       "13                   hiking                   hiking    aerobic   \n",
       "14         horseback riding         horseback riding  gentlemen   \n",
       "15                 kayaking                 kayaking      water   \n",
       "16             martial arts             martial arts     indoor   \n",
       "17             orienteering             orienteering    aerobic   \n",
       "18                   rowing            rowing             water   \n",
       "19                    rugby                    rugby       team   \n",
       "20                      run                      run    aerobic   \n",
       "21        treadmill running                      run    aerobic   \n",
       "22                  sailing                  sailing      water   \n",
       "23                    skate                    skate    aerobic   \n",
       "24     cross-country skiing                   skiing     winter   \n",
       "25          downhill skiing                   skiing     winter   \n",
       "26            roller skiing                   skiing     winter   \n",
       "27             snowboarding             snowboarding     winter   \n",
       "28              snowshoeing              snowshoeing     winter   \n",
       "29                   soccer                   soccer       team   \n",
       "30          squash                            squash     racket   \n",
       "31          stair climing             stair climbing    aerobic   \n",
       "32             kite surfing                  surfing      water   \n",
       "33              windsurfing                  surfing      water   \n",
       "34                 swimming                 swimming      water   \n",
       "35             table tennis             table tennis     racket   \n",
       "36                   tennis                   tennis     racket   \n",
       "37          fitness walking                     walk    aerobic   \n",
       "38        treadmill walking                     walk    aerobic   \n",
       "39                     walk                     walk    aerobic   \n",
       "40          weight training          weight training        gym   \n",
       "41                  pilates                     yoga     indoor   \n",
       "42                     yoga                     yoga     indoor   \n",
       "\n",
       "             venue  location_valid  distance_valid  speed_valid  speed_max  \n",
       "0           indoor               0               0            0          0  \n",
       "1           indoor               0               1            0          0  \n",
       "2   outdoor/indoor               1               1            0          0  \n",
       "3          outdoor               1               1            1        244  \n",
       "4          outdoor               1               1            1        244  \n",
       "5           indoor               0               1            1        244  \n",
       "6          outdoor               1               1            1        244  \n",
       "7   outdoor/indoor               0               0            0          0  \n",
       "8   outdoor/indoor               1               0            0          0  \n",
       "9           indoor               0               0            0          0  \n",
       "10          indoor               0               0            0          0  \n",
       "11         outdoor               1               1            0          0  \n",
       "12          indoor               0               1            0          0  \n",
       "13         outdoor               1               1            1         45  \n",
       "14         outdoor               1               1            1         71  \n",
       "15           water               1               1            1         32  \n",
       "16          indoor               0               0            0          0  \n",
       "17         outdoor               1               1            1         45  \n",
       "18           water               1               1            1         23  \n",
       "19         outdoor               1               1            0          0  \n",
       "20  outdoor/indoor               1               1            1         45  \n",
       "21          indoor               0               1            1         45  \n",
       "22           water               1               1            1        121  \n",
       "23  outdoor/indoor               1               1            1         55  \n",
       "24          winter               1               1            1        255  \n",
       "25          winter               1               1            1        255  \n",
       "26  outdoor/indoor               1               1            1         50  \n",
       "27          winter               1               1            1        203  \n",
       "28          winter               1               1            1         45  \n",
       "29         outdoor               1               1            0          0  \n",
       "30          indoor               0               1            0          0  \n",
       "31  outdoor/indoor               1               0            0          0  \n",
       "32           water               1               1            1         99  \n",
       "33           water               1               1            1         99  \n",
       "34           water               0               1            1          9  \n",
       "35          indoor               0               1            0          0  \n",
       "36         outdoor               0               1            0          0  \n",
       "37  outdoor/indoor               1               1            1         45  \n",
       "38          indoor               0               1            1         45  \n",
       "39  outdoor/indoor               1               1            1         45  \n",
       "40          indoor               0               0            0          0  \n",
       "41          indoor               0               0            0          0  \n",
       "42          indoor               0               0            0          0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import sports.xlsx\n",
    "\n",
    "path = sports_path + 'sports.xlsx'\n",
    "df_sports = pd.read_excel(path)\n",
    "df_sports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: 167783\n",
      "after: 167046\n",
      "drop: 737\n"
     ]
    }
   ],
   "source": [
    "# drop rows with abnormal heartrate\n",
    "\n",
    "before = len(df)\n",
    "print('before:',before)\n",
    "\n",
    "cond_1 = df['hr_min'] >= 40\n",
    "cond_2 = df['hr_avg'] >= 50\n",
    "cond_3 = df['hr_max'] >= 60\n",
    "\n",
    "df = df[cond_1 & cond_2 & cond_3]\n",
    "\n",
    "after = len(df)\n",
    "print('after:',after)\n",
    "drop = before - after\n",
    "print('drop:',drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: 167046\n",
      "after: 167042\n",
      "drop: 4\n"
     ]
    }
   ],
   "source": [
    "# drop rows with abnormal workout duration\n",
    "\n",
    "before = len(df)\n",
    "print('before:',before)\n",
    "\n",
    "# time_dur in minutes\n",
    "time_dur_mask = df['time_dur'] < 24 * 60\n",
    "df = df[time_dur_mask]\n",
    "\n",
    "after = len(df)\n",
    "print('after:',after)\n",
    "drop = before - after\n",
    "print('drop:',drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: 167042\n",
      "after: 159231\n",
      "drop: 7811\n"
     ]
    }
   ],
   "source": [
    "# drop rows with abnormal altitude\n",
    "\n",
    "before = len(df)\n",
    "print('before:',before)\n",
    "\n",
    "# altitude in metres\n",
    "max_alt_mask = df['alt_max'] <= 4000 # below Mount Kinabalu\n",
    "min_alt_mask = df['alt_min'] >= -30 # 10 storeys underground\n",
    "df = df[max_alt_mask & min_alt_mask]\n",
    "\n",
    "after = len(df)\n",
    "print('after:',after)\n",
    "drop = before - after\n",
    "print('drop:',drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows if speed is nan\n",
    "\n",
    "# before = len(df)\n",
    "# print('before:',before)\n",
    "\n",
    "# df.dropna(subset=['spd_avg'],inplace=True)\n",
    "\n",
    "# after = len(df)\n",
    "# print('after:',after)\n",
    "# drop = before - after\n",
    "# print('drop:',drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select and Merge Sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bike                       67962\n",
       "run                        67298\n",
       "mountain bike              10283\n",
       "bike (transport)            7162\n",
       "indoor cycling              1628\n",
       "walk                        1222\n",
       "orienteering                 849\n",
       "cross-country skiing         781\n",
       "core stability training      435\n",
       "fitness walking              275\n",
       "skate                        246\n",
       "roller skiing                237\n",
       "hiking                       232\n",
       "kayaking                      89\n",
       "circuit training              86\n",
       "rowing                        70\n",
       "weight training               69\n",
       "gymnastics                    66\n",
       "soccer                        51\n",
       "downhill skiing               43\n",
       "treadmill running             27\n",
       "snowshoeing                   16\n",
       "swimming                      13\n",
       "golf                          12\n",
       "horseback riding              10\n",
       "elliptical                    10\n",
       "badminton                      9\n",
       "basketball                     8\n",
       "tennis                         8\n",
       "aerobics                       7\n",
       "climbing                       5\n",
       "table tennis                   4\n",
       "rugby                          3\n",
       "stair climing                  3\n",
       "snowboarding                   3\n",
       "pilates                        2\n",
       "martial arts                   1\n",
       "windsurfing                    1\n",
       "sailing                        1\n",
       "yoga                           1\n",
       "kite surfing                   1\n",
       "squash                         1\n",
       "treadmill walking              1\n",
       "Name: sport, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print number of workouts per sport (after dropping rows)\n",
    "\n",
    "df['sport'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bike', 'bike (transport)', 'run', 'mountain bike', 'rowing',\n",
       "       'orienteering', 'kayaking', 'indoor cycling', 'skate',\n",
       "       'cross-country skiing', 'walk', 'hiking', 'treadmill running',\n",
       "       'snowshoeing', 'snowboarding', 'fitness walking', 'roller skiing',\n",
       "       'horseback riding', 'downhill skiing', 'swimming',\n",
       "       'treadmill walking', 'sailing', 'kite surfing', 'windsurfing'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select only sports with speed_valid = 1\n",
    "\n",
    "valid_mask = df_sports['speed_valid'] == 1\n",
    "valid_sport_list = df_sports[valid_mask]['sport']\n",
    "valid_sport_list = list(valid_sport_list)\n",
    "\n",
    "# overwrite: compare specific sports\n",
    "#valid_sport_list = ['kayaking','rowing']\n",
    "\n",
    "valid_mask_2 = df['sport'].isin(valid_sport_list)\n",
    "df = df[valid_mask_2]\n",
    "df['sport'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aerobics aerobics\n",
      "badminton badminton\n",
      "basketball basketball\n",
      "bike bike\n",
      "bike (transport) bike\n",
      "indoor cycling bike\n",
      "mountain bike bike\n",
      "circuit training circuit training\n",
      "climbing climbing\n",
      "core stability training core stability training\n",
      "elliptical elliptical\n",
      "golf golf\n",
      "gymnastics gymnastics\n",
      "hiking hiking\n",
      "horseback riding horseback riding\n",
      "kayaking kayaking\n",
      "martial arts martial arts\n",
      "orienteering orienteering\n",
      "rowing rowing       \n",
      "rugby rugby\n",
      "run run\n",
      "treadmill running run\n",
      "sailing sailing\n",
      "skate skate\n",
      "cross-country skiing skiing\n",
      "downhill skiing skiing\n",
      "roller skiing skiing\n",
      "snowboarding snowboarding\n",
      "snowshoeing snowshoeing\n",
      "soccer soccer\n",
      "squash squash\n",
      "stair climing stair climbing\n",
      "kite surfing surfing\n",
      "windsurfing surfing\n",
      "swimming swimming\n",
      "table tennis table tennis\n",
      "tennis tennis\n",
      "fitness walking walk\n",
      "treadmill walking walk\n",
      "walk walk\n",
      "weight training weight training\n",
      "pilates yoga\n",
      "yoga yoga\n"
     ]
    }
   ],
   "source": [
    "# merge similar sports\n",
    "\n",
    "for idx,row in df_sports.iterrows():\n",
    "    \n",
    "    sport = row['sport'].rstrip()\n",
    "    sport_rename = row['sport_rename']\n",
    "    print(sport,sport_rename)\n",
    "    \n",
    "    df['sport'].replace(sport,sport_rename,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bike                87035\n",
       "run                 67325\n",
       "walk                 1498\n",
       "skiing               1061\n",
       "orienteering          849\n",
       "skate                 246\n",
       "hiking                232\n",
       "kayaking               89\n",
       "rowing                 70\n",
       "snowshoeing            16\n",
       "swimming               13\n",
       "horseback riding       10\n",
       "snowboarding            3\n",
       "surfing                 2\n",
       "sailing                 1\n",
       "Name: sport, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print number of workouts per sport (after selecting and merging sports)\n",
    "\n",
    "df['sport'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection (select columns for df_model)\n",
    "\n",
    "# cols = ['sport','time_dur','alt_avg','alt_min','alt_25','alt_75','alt_max','hr_avg', 'hr_min','hr_25','hr_75','hr_max']\n",
    "\n",
    "#cols = ['sport','hr_avg','hr_min','hr_25','hr_75','hr_max']\n",
    "#cols = ['sport','hr_avg','hr_min','hr_05','hr_25','hr_75','hr_95','hr_max']\n",
    "#cols = ['sport','hr_avg','hr_min','hr_25','hr_75','hr_max','spd_avg']\n",
    "#cols = ['sport','hr_avg','hr_min','hr_25','hr_75','hr_max','spd_avg','spd_min','spd_25','spd_75','spd_max']\n",
    "\n",
    "#cols = ['sport','spd_avg']\n",
    "#cols = ['sport','spd_avg','spd_95']\n",
    "#cols = ['sport','spd_avg','spd_05','spd_25','spd_75','spd_95']\n",
    "\n",
    "#cols = ['sport','hr_outof','hr_fatburn','hr_cardio','hr_peak']\n",
    "#cols = ['sport','hr_outof','hr_fatburn','hr_cardio','hr_peak','spd_avg']\n",
    "#cols = ['sport','hr_outof','hr_fatburn','hr_cardio','hr_peak','spd_95']\n",
    "#cols = ['sport','hr_fatburn','hr_cardio','hr_peak','spd_avg','spd_95']\n",
    "cols = ['sport','hr_outof','hr_fatburn','hr_cardio','hr_peak','spd_avg','spd_95']\n",
    "#cols = ['sport','hr_outof','hr_fatburn','hr_cardio','hr_peak','spd_avg','spd_25','spd_75']\n",
    "#cols = ['sport','hr_outof','hr_fatburn','hr_cardio','hr_peak','spd_avg','spd_min','spd_25','spd_75','spd_max']\n",
    "\n",
    "#cols = ['sport','hr_outof','hr_fatburn','hr_cardio','hr_peak','spd_low','spd_med','spd_high','spd_vhigh']\n",
    "\n",
    "df_model = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only sports with minimal rows\n",
    "\n",
    "count = df_model['sport'].value_counts()\n",
    "\n",
    "#count_cond = count[count > 1].index\n",
    "#count_cond = count[count >= 5].inde\n",
    "#count_cond = count[count >= 10].index\n",
    "count_cond = count[count >= 50].index\n",
    "#count_cond = count[count >= 70].index\n",
    "#count_cond = count[count >= 100].index\n",
    "#count_cond = count[count >= 200].index\n",
    "#count_cond = count[count >= 800].index\n",
    "#count_cond = count[count >= 1500].index\n",
    "#count_cond = count[count >= 70000].index\n",
    "\n",
    "count_mask = df_model['sport'].isin(count_cond)\n",
    "df_model = df_model[count_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(158405, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sport</th>\n",
       "      <th>hr_outof</th>\n",
       "      <th>hr_fatburn</th>\n",
       "      <th>hr_cardio</th>\n",
       "      <th>hr_peak</th>\n",
       "      <th>spd_avg</th>\n",
       "      <th>spd_95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bike</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008026</td>\n",
       "      <td>0.507878</td>\n",
       "      <td>0.484096</td>\n",
       "      <td>26.152328</td>\n",
       "      <td>41.02704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bike</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011256</td>\n",
       "      <td>0.612177</td>\n",
       "      <td>0.376567</td>\n",
       "      <td>27.636272</td>\n",
       "      <td>43.17102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bike</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085785</td>\n",
       "      <td>0.790413</td>\n",
       "      <td>0.123802</td>\n",
       "      <td>26.159896</td>\n",
       "      <td>39.83040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bike</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031234</td>\n",
       "      <td>0.674708</td>\n",
       "      <td>0.294058</td>\n",
       "      <td>27.135904</td>\n",
       "      <td>42.42096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bike</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005738</td>\n",
       "      <td>0.076230</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>31.241183</td>\n",
       "      <td>46.51405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sport  hr_outof  hr_fatburn  hr_cardio   hr_peak    spd_avg    spd_95\n",
       "0  bike       0.0    0.008026   0.507878  0.484096  26.152328  41.02704\n",
       "1  bike       0.0    0.011256   0.612177  0.376567  27.636272  43.17102\n",
       "2  bike       0.0    0.085785   0.790413  0.123802  26.159896  39.83040\n",
       "3  bike       0.0    0.031234   0.674708  0.294058  27.135904  42.42096\n",
       "4  bike       0.0    0.005738   0.076230  0.918033  31.241183  46.51405"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_model.shape)\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bike             87035\n",
       "run              67325\n",
       "walk              1498\n",
       "skiing            1061\n",
       "orienteering       849\n",
       "skate              246\n",
       "hiking             232\n",
       "kayaking            89\n",
       "rowing              70\n",
       "Name: sport, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print number of workout by sports (with minimal rows)\n",
    "\n",
    "df_model['sport'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order = df_model.groupby('sport')['hr_max'].median().sort_values(ascending=False).index\n",
    "\n",
    "# plt.figure(figsize=(20,15))\n",
    "# #plt.xlim(0,300)\n",
    "\n",
    "# sns.boxplot(data=df_model,x='hr_max',y='sport',order=order);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order = df_model.groupby('sport')['hr_avg'].median().sort_values(ascending=False).index\n",
    "\n",
    "# plt.figure(figsize=(20,15))\n",
    "# #plt.xlim(0,300)\n",
    "\n",
    "# sns.boxplot(data=df_model,x='hr_avg',y='sport',order=order);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order = df_model.groupby('sport')['hr_min'].median().sort_values(ascending=False).index\n",
    "\n",
    "# plt.figure(figsize=(20,15))\n",
    "# #plt.xlim(0,300)\n",
    "\n",
    "# sns.boxplot(data=df_model,x='hr_min',y='sport',order=order);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sport</th>\n",
       "      <th>hr_outof</th>\n",
       "      <th>hr_fatburn</th>\n",
       "      <th>hr_cardio</th>\n",
       "      <th>hr_peak</th>\n",
       "      <th>spd_avg</th>\n",
       "      <th>spd_95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bike</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008026</td>\n",
       "      <td>0.507878</td>\n",
       "      <td>0.484096</td>\n",
       "      <td>26.152328</td>\n",
       "      <td>41.02704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bike</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011256</td>\n",
       "      <td>0.612177</td>\n",
       "      <td>0.376567</td>\n",
       "      <td>27.636272</td>\n",
       "      <td>43.17102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bike</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085785</td>\n",
       "      <td>0.790413</td>\n",
       "      <td>0.123802</td>\n",
       "      <td>26.159896</td>\n",
       "      <td>39.83040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bike</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031234</td>\n",
       "      <td>0.674708</td>\n",
       "      <td>0.294058</td>\n",
       "      <td>27.135904</td>\n",
       "      <td>42.42096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bike</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005738</td>\n",
       "      <td>0.076230</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>31.241183</td>\n",
       "      <td>46.51405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sport  hr_outof  hr_fatburn  hr_cardio   hr_peak    spd_avg    spd_95\n",
       "0  bike       0.0    0.008026   0.507878  0.484096  26.152328  41.02704\n",
       "1  bike       0.0    0.011256   0.612177  0.376567  27.636272  43.17102\n",
       "2  bike       0.0    0.085785   0.790413  0.123802  26.159896  39.83040\n",
       "3  bike       0.0    0.031234   0.674708  0.294058  27.135904  42.42096\n",
       "4  bike       0.0    0.005738   0.076230  0.918033  31.241183  46.51405"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing scaling and encoding before create X and y\n",
    "\n",
    "cols = df_model.columns[1:]\n",
    "\n",
    "ss = StandardScaler()\n",
    "df_model[cols] = ss.fit_transform(df_model[cols])\n",
    "\n",
    "le = LabelEncoder()\n",
    "df_model['sport'] = le.fit_transform(df_model['sport'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature and target. next perform train_test_split\n",
    "\n",
    "X = df_model.drop(columns='sport')\n",
    "y = df_model['sport']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3,stratify=y,random_state=3050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sport</th>\n",
       "      <th>hr_outof</th>\n",
       "      <th>hr_fatburn</th>\n",
       "      <th>hr_cardio</th>\n",
       "      <th>hr_peak</th>\n",
       "      <th>spd_avg</th>\n",
       "      <th>spd_95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.314315</td>\n",
       "      <td>-0.751071</td>\n",
       "      <td>0.109732</td>\n",
       "      <td>0.654394</td>\n",
       "      <td>0.948678</td>\n",
       "      <td>1.182728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.314315</td>\n",
       "      <td>-0.739741</td>\n",
       "      <td>0.436342</td>\n",
       "      <td>0.316973</td>\n",
       "      <td>1.124650</td>\n",
       "      <td>1.347898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.314315</td>\n",
       "      <td>-0.478304</td>\n",
       "      <td>0.994482</td>\n",
       "      <td>-0.476190</td>\n",
       "      <td>0.949576</td>\n",
       "      <td>1.090540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.314315</td>\n",
       "      <td>-0.669661</td>\n",
       "      <td>0.632156</td>\n",
       "      <td>0.058064</td>\n",
       "      <td>1.065315</td>\n",
       "      <td>1.290114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.314315</td>\n",
       "      <td>-0.759099</td>\n",
       "      <td>-1.241957</td>\n",
       "      <td>2.016061</td>\n",
       "      <td>1.552134</td>\n",
       "      <td>1.605442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sport  hr_outof  hr_fatburn  hr_cardio   hr_peak   spd_avg    spd_95\n",
       "0      0 -0.314315   -0.751071   0.109732  0.654394  0.948678  1.182728\n",
       "1      0 -0.314315   -0.739741   0.436342  0.316973  1.124650  1.347898\n",
       "2      0 -0.314315   -0.478304   0.994482 -0.476190  0.949576  1.090540\n",
       "3      0 -0.314315   -0.669661   0.632156  0.058064  1.065315  1.290114\n",
       "4      0 -0.314315   -0.759099  -1.241957  2.016061  1.552134  1.605442"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110883, 6)\n",
      "(47522, 6)\n",
      "(110883,)\n",
      "(47522,)\n"
     ]
    }
   ],
   "source": [
    "# check before upsample/downsample\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 60924, 1: 163, 2: 62, 3: 594, 4: 49, 5: 47127, 6: 172, 7: 743, 8: 1049}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check before upsample/downsample\n",
    "\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm = SMOTE(random_state=3050)\n",
    "# X_train, y_train = sm.fit_sample(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get majority class index and row count\n",
    "\n",
    "# sport_counts = df_model['sport'].value_counts()\n",
    "# print(sport_counts)\n",
    "\n",
    "# major_class_index = sport_counts.index[0]\n",
    "# major_class_count = sport_counts.values[0]\n",
    "# print(major_class_index,major_class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    60924\n",
      "5    47127\n",
      "8     1049\n",
      "7      743\n",
      "3      594\n",
      "6      172\n",
      "1      163\n",
      "2       62\n",
      "4       49\n",
      "Name: sport, dtype: int64\n",
      "(110883, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hr_outof</th>\n",
       "      <th>hr_fatburn</th>\n",
       "      <th>hr_cardio</th>\n",
       "      <th>hr_peak</th>\n",
       "      <th>spd_avg</th>\n",
       "      <th>spd_95</th>\n",
       "      <th>sport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124508</th>\n",
       "      <td>-0.221229</td>\n",
       "      <td>0.592657</td>\n",
       "      <td>0.373080</td>\n",
       "      <td>-0.838918</td>\n",
       "      <td>0.892324</td>\n",
       "      <td>0.449526</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159550</th>\n",
       "      <td>-0.266947</td>\n",
       "      <td>1.217311</td>\n",
       "      <td>-0.145424</td>\n",
       "      <td>-0.864672</td>\n",
       "      <td>1.490039</td>\n",
       "      <td>0.925204</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85115</th>\n",
       "      <td>2.094027</td>\n",
       "      <td>1.243319</td>\n",
       "      <td>-0.861898</td>\n",
       "      <td>-0.864672</td>\n",
       "      <td>0.230398</td>\n",
       "      <td>0.885185</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7886</th>\n",
       "      <td>-0.314315</td>\n",
       "      <td>-0.736719</td>\n",
       "      <td>-0.012171</td>\n",
       "      <td>0.763711</td>\n",
       "      <td>-1.005802</td>\n",
       "      <td>-0.983467</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104905</th>\n",
       "      <td>-0.314315</td>\n",
       "      <td>0.100726</td>\n",
       "      <td>0.093449</td>\n",
       "      <td>-0.091263</td>\n",
       "      <td>0.965268</td>\n",
       "      <td>1.646294</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        hr_outof  hr_fatburn  hr_cardio   hr_peak   spd_avg    spd_95  sport\n",
       "124508 -0.221229    0.592657   0.373080 -0.838918  0.892324  0.449526      0\n",
       "159550 -0.266947    1.217311  -0.145424 -0.864672  1.490039  0.925204      0\n",
       "85115   2.094027    1.243319  -0.861898 -0.864672  0.230398  0.885185      0\n",
       "7886   -0.314315   -0.736719  -0.012171  0.763711 -1.005802 -0.983467      5\n",
       "104905 -0.314315    0.100726   0.093449 -0.091263  0.965268  1.646294      0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate our training data back together\n",
    "\n",
    "Xy_train = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "sport_counts = Xy_train['sport'].value_counts()\n",
    "print(sport_counts)\n",
    "\n",
    "print(Xy_train.shape)\n",
    "Xy_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downsampling 0 60924\n",
      "downsampling 5 47127\n",
      "upsampling 4 49\n",
      "upsampling 3 594\n",
      "upsampling 2 62\n",
      "upsampling 6 172\n",
      "upsampling 7 743\n",
      "upsampling 8 1049\n",
      "upsampling 1 163\n"
     ]
    }
   ],
   "source": [
    "# perform upsampling and downsampling\n",
    "\n",
    "sample_size = 12000\n",
    "\n",
    "df_all_sample = pd.DataFrame()\n",
    "\n",
    "sport_list = df_model['sport'].unique()\n",
    "sport_list\n",
    "\n",
    "for sport in sport_list:\n",
    "    \n",
    "    cond = Xy_train['sport'] == sport\n",
    "    df_sport = Xy_train[cond]\n",
    "    \n",
    "    # perform downsampling\n",
    "    if sport_counts[sport] >= sample_size:    \n",
    "        print('downsampling',sport,sport_counts[sport])\n",
    "        df_sample = df_sport.sample(sample_size,replace=False,random_state=3050)\n",
    "        \n",
    "    # perform upsampling\n",
    "    # sport_counts[sport] < sample_size: \n",
    "    else:\n",
    "        print('upsampling',sport,sport_counts[sport])\n",
    "        df_sample = df_sport.sample(sample_size,replace=True,random_state=3050)\n",
    "        \n",
    "    df_all_sample = pd.concat([df_all_sample, df_sample], axis=0)\n",
    "    \n",
    "X_train = df_all_sample.drop(columns='sport').values\n",
    "y_train = df_all_sample['sport'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # perform upsampling for minority classes\n",
    "\n",
    "# df_all_sample = pd.DataFrame()\n",
    "\n",
    "# sport_list = df_model['sport'].unique()\n",
    "\n",
    "# for sport in sport_list:\n",
    "    \n",
    "#     if sport != major_class_index:\n",
    "        \n",
    "#         cond = df_model['sport'] == sport\n",
    "#         df_sport = df_model[cond]\n",
    "#         #print(sport,len(df_sport))\n",
    "        \n",
    "#         df_sample = df_sport.sample(major_class_count,replace=True,random_state=3050)\n",
    "#         df_all_sample = pd.concat([df_all_sample, df_sample], axis=0)\n",
    "        \n",
    "# cond = df_model['sport'] == major_class_index\n",
    "# df_top = df_model[cond]\n",
    "# df_all_sample = pd.concat([df_all_sample, df_top], axis=0)\n",
    "\n",
    "# X_train = df_all_sample.drop(columns='sport').values\n",
    "# y_train = df_all_sample['sport'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108000, 6)\n",
      "(47522, 6)\n",
      "(108000,)\n",
      "(47522,)\n"
     ]
    }
   ],
   "source": [
    "# check after upsample/downsample\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 12000,\n",
       " 1: 12000,\n",
       " 2: 12000,\n",
       " 3: 12000,\n",
       " 4: 12000,\n",
       " 5: 12000,\n",
       " 6: 12000,\n",
       " 7: 12000,\n",
       " 8: 12000}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check after upsample/downsample\n",
    "\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store predictions in df_pred\n",
    "\n",
    "df_pred = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-e2c9c290de89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "print(stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# perform cross validation\n",
    "score = cross_val_score(logreg,X,y,cv=5)\n",
    "print('score:',score.mean(),score)\n",
    "\n",
    "# fit model\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# score model\n",
    "print(\"train r2:\",logreg.score(X_train, y_train))\n",
    "print(\"test r2:\",logreg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "print('Logisitic Regression Model')\n",
    "print('rows:actual columns:predicted')\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "df_pred['lr'] = y_pred\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "df_cm = pd.DataFrame(data=cm, columns=le.classes_, index=le.classes_)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(df_cm,annot=True,cmap=\"Blues\");\n",
    "\n",
    "# cohen_score = cohen_kappa_score(y_test, y_pred)\n",
    "# print('cohen_score',cohen_score)\n",
    "\n",
    "# y_pred = logreg.predict_proba(X_test)\n",
    "# pd.DataFrame(y_pred,columns=le.classes_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# perform cross validation\n",
    "score = cross_val_score(knn,X,y,cv=5)\n",
    "print('score:',score.mean(),score)\n",
    "\n",
    "# fit model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# score model\n",
    "print(\"train r2:\",knn.score(X_train, y_train))\n",
    "print(\"test r2:\",knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "print('KNN Model')\n",
    "print('rows:actual columns:predicted')\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "df_pred['knn'] = y_pred\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "df_cm = pd.DataFrame(data=cm, columns=le.classes_, index=le.classes_)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(df_cm,annot=True,cmap=\"Blues\");\n",
    "\n",
    "# cohen_score = cohen_kappa_score(y_test, y_pred)\n",
    "# print('cohen_score',cohen_score)\n",
    "\n",
    "# y_pred = knn.predict_proba(X_test)\n",
    "# pd.DataFrame(y_pred,columns=le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DTC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "dtc = DecisionTreeClassifier(max_depth=10,random_state=3050)\n",
    "\n",
    "# perform cross validation\n",
    "score = cross_val_score(dtc,X,y,cv=5)\n",
    "print(score.mean(),score)\n",
    "\n",
    "# fit model\n",
    "dtc = dtc.fit(X_train,y_train)\n",
    "\n",
    "# score model\n",
    "print(\"train r2:\",dtc.score(X_train, y_train))\n",
    "print(\"test r2:\",dtc.score(X_test, y_test))\n",
    "\n",
    "# cohen_score = cohen_kappa_score(y_test, y_pred)\n",
    "# print('cohen_score',cohen_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "print('DTC Model')\n",
    "print('rows:actual columns:predicted')\n",
    "\n",
    "y_pred = dtc.predict(X_test)\n",
    "df_pred['dtc'] = y_pred\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "df_cm = pd.DataFrame(data=cm, columns=le.classes_, index=le.classes_)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(df_cm,annot=True,cmap=\"Blues\");\n",
    "\n",
    "# y_pred = dtc.predict_proba(X_test)\n",
    "# pd.DataFrame(y_pred,columns=le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initialize the output file object\n",
    "# dot_data = StringIO() \n",
    "\n",
    "# # my fit DecisionTreeRegressor object here is: dtr1\n",
    "# # for feature_names i put the columns of my Xr matrix\n",
    "# export_graphviz(dtc, \n",
    "#                 out_file=dot_data,  \n",
    "#                 filled=True, \n",
    "#                 rounded=True,\n",
    "#                 special_characters=True,\n",
    "#                 feature_names=df_model[features].columns\n",
    "#                )  \n",
    "\n",
    "# graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "# Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "rfc = RandomForestClassifier(n_estimators=10,max_depth=10,n_jobs=-1, random_state=3050)\n",
    "\n",
    "# perform cross validation\n",
    "score = cross_val_score(rfc,X,y,cv=5)\n",
    "print(score.mean(),score)\n",
    "\n",
    "# fit model\n",
    "rfc = rfc.fit(X_train,y_train)\n",
    "\n",
    "# score model\n",
    "print(\"train r2:\",rfc.score(X_train, y_train))\n",
    "print(\"test r2:\",rfc.score(X_test, y_test))\n",
    "\n",
    "# cohen_score = cohen_kappa_score(y_test, y_pred)\n",
    "# print('cohen_score',cohen_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "print('RFC Model')\n",
    "print('rows:actual columns:predicted')\n",
    "\n",
    "y_pred = rfc.predict(X_test)\n",
    "df_pred['rfc'] = y_pred\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "df_cm = pd.DataFrame(data=cm, columns=le.classes_, index=le.classes_)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(df_cm,annot=True,cmap=\"Blues\");\n",
    "\n",
    "# y_pred = rfc.predict_proba(X_test)\n",
    "# pd.DataFrame(y_pred,columns=le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "svc = SVC()\n",
    "\n",
    "# fit model\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# score model\n",
    "print(\"train r2:\",svc.score(X_train, y_train))\n",
    "print(\"test r2:\",svc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "print('SVC Model')\n",
    "print('rows:actual columns:predicted')\n",
    "\n",
    "y_pred = svc.predict(X_test)\n",
    "df_pred['svc'] = y_pred\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "df_cm = pd.DataFrame(data=cm, columns=le.classes_, index=le.classes_)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(df_cm,annot=True,cmap=\"Blues\");\n",
    "\n",
    "# cohen_score = cohen_kappa_score(y_test, y_pred)\n",
    "# print('cohen_score',cohen_score)\n",
    "\n",
    "# y_pred = logreg.predict_proba(X_test)\n",
    "# pd.DataFrame(y_pred,columns=le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check predictions\n",
    "\n",
    "print(df_pred.shape)\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['svc','rfc','dtc','lr','knn']\n",
    "df_pred = df_pred[cols]\n",
    "\n",
    "df_pred_mode = df_pred.mode(axis=1)\n",
    "df_pred_mode.reset_index(inplace=True)\n",
    "\n",
    "df_pred_final = df_pred_mode[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,row in df_pred_mode.iterrows():\n",
    "    \n",
    "    if np.isnan(row[1]) == False:\n",
    "\n",
    "        mode_list = list(row[1:])\n",
    "        #print(mode_list)\n",
    "        \n",
    "        pred_row = df_pred.iloc[idx,:]\n",
    "        #print(pred_row)\n",
    "        \n",
    "        \n",
    "        for idx_2,cell in pred_row.iteritems():\n",
    "            \n",
    "            if cell in mode_list:\n",
    "                #print(idx,idx_2,cell)\n",
    "                df_pred_final[idx] = cell\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = df_pred_final.values\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_final)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "df_cm = pd.DataFrame(data=cm, columns=le.classes_, index=le.classes_)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(df_cm,annot=True,cmap=\"Blues\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VotingClassifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init models\n",
    "\n",
    "lr = LogisticRegression()\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "dtc = DecisionTreeClassifier(max_depth=10,random_state=3050)\n",
    "rfc = RandomForestClassifier(n_estimators=10,max_depth=10,n_jobs=-1, random_state=3050)\n",
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr knn dtc rfc svc\n",
    "\n",
    "estimators = [\n",
    "        ('lr', lr), \n",
    "        ('knn', knn), \n",
    "        ('dtc', dtc),\n",
    "        ('rfc', rfc),\n",
    "        ('svc', svc)\n",
    "            ]\n",
    "\n",
    "vc = VotingClassifier(estimators=estimators, voting='hard')\n",
    "#vc = VotingClassifier(estimators=estimators, voting='soft')\n",
    "vc = vc.fit(X_train, y_train)\n",
    "y_pred = vc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "print('VC Model')\n",
    "print('rows:actual columns:predicted')\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "df_cm = pd.DataFrame(data=cm, columns=le.classes_, index=le.classes_)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(df_cm,annot=True,cmap=\"Blues\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init models\n",
    "\n",
    "estimators = {\n",
    "    'lr': LogisticRegression(),\n",
    "    'knn': KNeighborsClassifier(),\n",
    "    'dtc': DecisionTreeClassifier(),\n",
    "    'rfc': RandomForestClassifier(),\n",
    "    'abc': AdaBoostClassifier(),\n",
    "    'gbc': GradientBoostingClassifier()\n",
    "}.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model parameters\n",
    "\n",
    "params = {\n",
    "    'lr': {\n",
    "        'lr__penalty': ['l1','l2'],\n",
    "        #'lr__penalty': ['l1','l2','elasticnet'],\n",
    "        #'l1__ratio': np.arange(.1, 1, .2)\n",
    "    },\n",
    "    'knn': {\n",
    "        'knn__n_neighbors': [3,5,7,9],\n",
    "        'knn__weights': ['uniform','distance']\n",
    "    },\n",
    "\n",
    "    'dtc': {\n",
    "        'dtc__max_features': ['auto', 'log2', None],\n",
    "        'dtc__max_depth': np.arange(3, 16, 2),\n",
    "        'dtc__min_samples_split': np.linspace(0.1, 0.5, 5)\n",
    "    },\n",
    "    'rfc': {\n",
    "        'rfc__n_estimators': [10, 15, 20, 25],\n",
    "        'rfc__max_features': ['auto', 'log2', None],\n",
    "        'rfc__max_depth': np.arange(3, 16, 2),\n",
    "        'rfc__min_samples_split': np.linspace(0.1, 0.5, 5)\n",
    "    },\n",
    "    'abc': {\n",
    "        'abc__n_estimators' : np.arange(50, 151, 25),\n",
    "        'abc__learning_rate' : np.linspace(0.1, 1, 8)\n",
    "    }, \n",
    "    'gbc': {\n",
    "        'gbc__n_estimators' : np.arange(10, 101, 15),\n",
    "        'gbc__learning_rate' : np.linspace(0.1, 1, 8),\n",
    "        'gbc__max_depth' : [1, 2, 3]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  lr\n",
      "Best parameters: {'lr__penalty': 'l1'}\n",
      "Best score: 0.5149907407407407\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_lr__penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.396726</td>\n",
       "      <td>25.836005</td>\n",
       "      <td>0.014762</td>\n",
       "      <td>0.009614</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'lr__penalty': 'l1'}</td>\n",
       "      <td>0.513565</td>\n",
       "      <td>0.515324</td>\n",
       "      <td>0.519769</td>\n",
       "      <td>0.515787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.514991</td>\n",
       "      <td>0.003023</td>\n",
       "      <td>1</td>\n",
       "      <td>0.516991</td>\n",
       "      <td>0.515208</td>\n",
       "      <td>0.515498</td>\n",
       "      <td>0.513507</td>\n",
       "      <td>0.512986</td>\n",
       "      <td>0.514838</td>\n",
       "      <td>0.001443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.294566</td>\n",
       "      <td>0.189372</td>\n",
       "      <td>0.011769</td>\n",
       "      <td>0.002311</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'lr__penalty': 'l2'}</td>\n",
       "      <td>0.513611</td>\n",
       "      <td>0.515046</td>\n",
       "      <td>0.516574</td>\n",
       "      <td>0.516157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.514481</td>\n",
       "      <td>0.002013</td>\n",
       "      <td>2</td>\n",
       "      <td>0.516933</td>\n",
       "      <td>0.515104</td>\n",
       "      <td>0.512778</td>\n",
       "      <td>0.513588</td>\n",
       "      <td>0.513565</td>\n",
       "      <td>0.514394</td>\n",
       "      <td>0.001476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      88.396726     25.836005         0.014762        0.009614   \n",
       "1       5.294566      0.189372         0.011769        0.002311   \n",
       "\n",
       "  param_lr__penalty                 params  split0_test_score  \\\n",
       "0                l1  {'lr__penalty': 'l1'}           0.513565   \n",
       "1                l2  {'lr__penalty': 'l2'}           0.513611   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  ...  \\\n",
       "0           0.515324           0.519769           0.515787  ...   \n",
       "1           0.515046           0.516574           0.516157  ...   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0         0.514991        0.003023                1            0.516991   \n",
       "1         0.514481        0.002013                2            0.516933   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0            0.515208            0.515498            0.513507   \n",
       "1            0.515104            0.512778            0.513588   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.512986          0.514838         0.001443  \n",
       "1            0.513565          0.514394         0.001476  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   58.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  knn\n",
      "Best parameters: {'knn__n_neighbors': 3, 'knn__weights': 'distance'}\n",
      "Best score: 0.9781481481481481\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_knn__n_neighbors</th>\n",
       "      <th>param_knn__weights</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.264294</td>\n",
       "      <td>0.045752</td>\n",
       "      <td>1.439057</td>\n",
       "      <td>0.058037</td>\n",
       "      <td>3</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'knn__n_neighbors': 3, 'knn__weights': 'unifo...</td>\n",
       "      <td>0.978056</td>\n",
       "      <td>0.977870</td>\n",
       "      <td>0.978102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977750</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>2</td>\n",
       "      <td>0.986713</td>\n",
       "      <td>0.986250</td>\n",
       "      <td>0.986146</td>\n",
       "      <td>0.986377</td>\n",
       "      <td>0.986377</td>\n",
       "      <td>0.986373</td>\n",
       "      <td>0.000191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.258112</td>\n",
       "      <td>0.062321</td>\n",
       "      <td>0.612669</td>\n",
       "      <td>0.066836</td>\n",
       "      <td>3</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'knn__n_neighbors': 3, 'knn__weights': 'dista...</td>\n",
       "      <td>0.978657</td>\n",
       "      <td>0.978241</td>\n",
       "      <td>0.978426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999931</td>\n",
       "      <td>0.999884</td>\n",
       "      <td>0.999919</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.195278</td>\n",
       "      <td>0.027455</td>\n",
       "      <td>1.578009</td>\n",
       "      <td>0.196582</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'knn__n_neighbors': 5, 'knn__weights': 'unifo...</td>\n",
       "      <td>0.972454</td>\n",
       "      <td>0.971574</td>\n",
       "      <td>0.972731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.971778</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>4</td>\n",
       "      <td>0.978322</td>\n",
       "      <td>0.978426</td>\n",
       "      <td>0.978692</td>\n",
       "      <td>0.978854</td>\n",
       "      <td>0.978542</td>\n",
       "      <td>0.978567</td>\n",
       "      <td>0.000189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.186501</td>\n",
       "      <td>0.016737</td>\n",
       "      <td>0.522221</td>\n",
       "      <td>0.040932</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'knn__n_neighbors': 5, 'knn__weights': 'dista...</td>\n",
       "      <td>0.973657</td>\n",
       "      <td>0.972870</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972991</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999931</td>\n",
       "      <td>0.999884</td>\n",
       "      <td>0.999919</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.203462</td>\n",
       "      <td>0.068787</td>\n",
       "      <td>1.794132</td>\n",
       "      <td>0.419619</td>\n",
       "      <td>7</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'knn__n_neighbors': 7, 'knn__weights': 'unifo...</td>\n",
       "      <td>0.966481</td>\n",
       "      <td>0.965556</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966074</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>6</td>\n",
       "      <td>0.971771</td>\n",
       "      <td>0.972280</td>\n",
       "      <td>0.972014</td>\n",
       "      <td>0.972407</td>\n",
       "      <td>0.972361</td>\n",
       "      <td>0.972167</td>\n",
       "      <td>0.000240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.246147</td>\n",
       "      <td>0.075031</td>\n",
       "      <td>0.813241</td>\n",
       "      <td>0.236114</td>\n",
       "      <td>7</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'knn__n_neighbors': 7, 'knn__weights': 'dista...</td>\n",
       "      <td>0.969537</td>\n",
       "      <td>0.968565</td>\n",
       "      <td>0.968935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968713</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999931</td>\n",
       "      <td>0.999884</td>\n",
       "      <td>0.999919</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.167255</td>\n",
       "      <td>0.013303</td>\n",
       "      <td>1.526834</td>\n",
       "      <td>0.113583</td>\n",
       "      <td>9</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'knn__n_neighbors': 9, 'knn__weights': 'unifo...</td>\n",
       "      <td>0.961019</td>\n",
       "      <td>0.960463</td>\n",
       "      <td>0.961713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961176</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>8</td>\n",
       "      <td>0.966262</td>\n",
       "      <td>0.966644</td>\n",
       "      <td>0.966435</td>\n",
       "      <td>0.966759</td>\n",
       "      <td>0.967130</td>\n",
       "      <td>0.966646</td>\n",
       "      <td>0.000296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.189396</td>\n",
       "      <td>0.021816</td>\n",
       "      <td>0.635803</td>\n",
       "      <td>0.067079</td>\n",
       "      <td>9</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'knn__n_neighbors': 9, 'knn__weights': 'dista...</td>\n",
       "      <td>0.964491</td>\n",
       "      <td>0.964722</td>\n",
       "      <td>0.965370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964815</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999931</td>\n",
       "      <td>0.999884</td>\n",
       "      <td>0.999919</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.264294      0.045752         1.439057        0.058037   \n",
       "1       0.258112      0.062321         0.612669        0.066836   \n",
       "2       0.195278      0.027455         1.578009        0.196582   \n",
       "3       0.186501      0.016737         0.522221        0.040932   \n",
       "4       0.203462      0.068787         1.794132        0.419619   \n",
       "5       0.246147      0.075031         0.813241        0.236114   \n",
       "6       0.167255      0.013303         1.526834        0.113583   \n",
       "7       0.189396      0.021816         0.635803        0.067079   \n",
       "\n",
       "  param_knn__n_neighbors param_knn__weights  \\\n",
       "0                      3            uniform   \n",
       "1                      3           distance   \n",
       "2                      5            uniform   \n",
       "3                      5           distance   \n",
       "4                      7            uniform   \n",
       "5                      7           distance   \n",
       "6                      9            uniform   \n",
       "7                      9           distance   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'knn__n_neighbors': 3, 'knn__weights': 'unifo...           0.978056   \n",
       "1  {'knn__n_neighbors': 3, 'knn__weights': 'dista...           0.978657   \n",
       "2  {'knn__n_neighbors': 5, 'knn__weights': 'unifo...           0.972454   \n",
       "3  {'knn__n_neighbors': 5, 'knn__weights': 'dista...           0.973657   \n",
       "4  {'knn__n_neighbors': 7, 'knn__weights': 'unifo...           0.966481   \n",
       "5  {'knn__n_neighbors': 7, 'knn__weights': 'dista...           0.969537   \n",
       "6  {'knn__n_neighbors': 9, 'knn__weights': 'unifo...           0.961019   \n",
       "7  {'knn__n_neighbors': 9, 'knn__weights': 'dista...           0.964491   \n",
       "\n",
       "   split1_test_score  split2_test_score  ...  mean_test_score  std_test_score  \\\n",
       "0           0.977870           0.978102  ...         0.977750        0.000645   \n",
       "1           0.978241           0.978426  ...         0.978148        0.000687   \n",
       "2           0.971574           0.972731  ...         0.971778        0.000712   \n",
       "3           0.972870           0.973333  ...         0.972991        0.000445   \n",
       "4           0.965556           0.966667  ...         0.966074        0.000551   \n",
       "5           0.968565           0.968935  ...         0.968713        0.000528   \n",
       "6           0.960463           0.961713  ...         0.961176        0.000628   \n",
       "7           0.964722           0.965370  ...         0.964815        0.000425   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                2            0.986713            0.986250   \n",
       "1                1            0.999931            0.999884   \n",
       "2                4            0.978322            0.978426   \n",
       "3                3            0.999931            0.999884   \n",
       "4                6            0.971771            0.972280   \n",
       "5                5            0.999931            0.999884   \n",
       "6                8            0.966262            0.966644   \n",
       "7                7            0.999931            0.999884   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            0.986146            0.986377            0.986377   \n",
       "1            0.999919            0.999907            0.999896   \n",
       "2            0.978692            0.978854            0.978542   \n",
       "3            0.999919            0.999907            0.999896   \n",
       "4            0.972014            0.972407            0.972361   \n",
       "5            0.999919            0.999907            0.999896   \n",
       "6            0.966435            0.966759            0.967130   \n",
       "7            0.999919            0.999907            0.999896   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.986373         0.000191  \n",
       "1          0.999907         0.000016  \n",
       "2          0.978567         0.000189  \n",
       "3          0.999907         0.000016  \n",
       "4          0.972167         0.000240  \n",
       "5          0.999907         0.000016  \n",
       "6          0.966646         0.000296  \n",
       "7          0.999907         0.000016  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 105 candidates, totalling 525 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   21.6s\n",
      "[Parallel(n_jobs=-1)]: Done 518 out of 525 | elapsed:   31.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 525 out of 525 | elapsed:   31.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  dtc\n",
      "Best parameters: {'dtc__max_depth': 7, 'dtc__max_features': None, 'dtc__min_samples_split': 0.1}\n",
      "Best score: 0.5673888888888889\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_dtc__max_depth</th>\n",
       "      <th>param_dtc__max_features</th>\n",
       "      <th>param_dtc__min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.154388</td>\n",
       "      <td>0.031332</td>\n",
       "      <td>0.006382</td>\n",
       "      <td>0.001492</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'dtc__max_depth': 3, 'dtc__max_features': 'au...</td>\n",
       "      <td>0.404074</td>\n",
       "      <td>0.409028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412157</td>\n",
       "      <td>0.020037</td>\n",
       "      <td>39</td>\n",
       "      <td>0.410787</td>\n",
       "      <td>0.412755</td>\n",
       "      <td>0.388113</td>\n",
       "      <td>0.408900</td>\n",
       "      <td>0.446933</td>\n",
       "      <td>0.413498</td>\n",
       "      <td>0.018928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.164959</td>\n",
       "      <td>0.021087</td>\n",
       "      <td>0.009575</td>\n",
       "      <td>0.005936</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'dtc__max_depth': 3, 'dtc__max_features': 'au...</td>\n",
       "      <td>0.408380</td>\n",
       "      <td>0.417593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.419991</td>\n",
       "      <td>0.024686</td>\n",
       "      <td>37</td>\n",
       "      <td>0.411609</td>\n",
       "      <td>0.420012</td>\n",
       "      <td>0.402917</td>\n",
       "      <td>0.398993</td>\n",
       "      <td>0.467917</td>\n",
       "      <td>0.420289</td>\n",
       "      <td>0.024896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.145812</td>\n",
       "      <td>0.019486</td>\n",
       "      <td>0.008974</td>\n",
       "      <td>0.004038</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'dtc__max_depth': 3, 'dtc__max_features': 'au...</td>\n",
       "      <td>0.414537</td>\n",
       "      <td>0.318565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378231</td>\n",
       "      <td>0.031892</td>\n",
       "      <td>51</td>\n",
       "      <td>0.414329</td>\n",
       "      <td>0.316921</td>\n",
       "      <td>0.385174</td>\n",
       "      <td>0.387060</td>\n",
       "      <td>0.383762</td>\n",
       "      <td>0.377449</td>\n",
       "      <td>0.032297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.127061</td>\n",
       "      <td>0.019159</td>\n",
       "      <td>0.007978</td>\n",
       "      <td>0.004549</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'dtc__max_depth': 3, 'dtc__max_features': 'au...</td>\n",
       "      <td>0.344676</td>\n",
       "      <td>0.305231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319907</td>\n",
       "      <td>0.013286</td>\n",
       "      <td>79</td>\n",
       "      <td>0.342743</td>\n",
       "      <td>0.303380</td>\n",
       "      <td>0.317049</td>\n",
       "      <td>0.317083</td>\n",
       "      <td>0.313356</td>\n",
       "      <td>0.318722</td>\n",
       "      <td>0.013013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.100133</td>\n",
       "      <td>0.007766</td>\n",
       "      <td>0.016157</td>\n",
       "      <td>0.014068</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'dtc__max_depth': 3, 'dtc__max_features': 'au...</td>\n",
       "      <td>0.263056</td>\n",
       "      <td>0.311806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.271102</td>\n",
       "      <td>0.037739</td>\n",
       "      <td>103</td>\n",
       "      <td>0.263414</td>\n",
       "      <td>0.313623</td>\n",
       "      <td>0.313299</td>\n",
       "      <td>0.212384</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.272308</td>\n",
       "      <td>0.038050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.156781</td>\n",
       "      <td>0.013025</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.002327</td>\n",
       "      <td>3</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'dtc__max_depth': 3, 'dtc__max_features': 'lo...</td>\n",
       "      <td>0.441296</td>\n",
       "      <td>0.412731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408259</td>\n",
       "      <td>0.050907</td>\n",
       "      <td>48</td>\n",
       "      <td>0.444294</td>\n",
       "      <td>0.414965</td>\n",
       "      <td>0.314155</td>\n",
       "      <td>0.462442</td>\n",
       "      <td>0.407870</td>\n",
       "      <td>0.408745</td>\n",
       "      <td>0.051252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.159179</td>\n",
       "      <td>0.020406</td>\n",
       "      <td>0.006382</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>3</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'dtc__max_depth': 3, 'dtc__max_features': 'lo...</td>\n",
       "      <td>0.320278</td>\n",
       "      <td>0.334028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.374065</td>\n",
       "      <td>0.043201</td>\n",
       "      <td>54</td>\n",
       "      <td>0.320775</td>\n",
       "      <td>0.332396</td>\n",
       "      <td>0.403866</td>\n",
       "      <td>0.373924</td>\n",
       "      <td>0.434155</td>\n",
       "      <td>0.373023</td>\n",
       "      <td>0.042590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.135641</td>\n",
       "      <td>0.015597</td>\n",
       "      <td>0.015757</td>\n",
       "      <td>0.013840</td>\n",
       "      <td>3</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'dtc__max_depth': 3, 'dtc__max_features': 'lo...</td>\n",
       "      <td>0.336852</td>\n",
       "      <td>0.383889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361009</td>\n",
       "      <td>0.023675</td>\n",
       "      <td>57</td>\n",
       "      <td>0.335706</td>\n",
       "      <td>0.384826</td>\n",
       "      <td>0.328067</td>\n",
       "      <td>0.367755</td>\n",
       "      <td>0.387813</td>\n",
       "      <td>0.360833</td>\n",
       "      <td>0.024724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.130451</td>\n",
       "      <td>0.014825</td>\n",
       "      <td>0.007978</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>3</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'dtc__max_depth': 3, 'dtc__max_features': 'lo...</td>\n",
       "      <td>0.343889</td>\n",
       "      <td>0.358241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325491</td>\n",
       "      <td>0.045301</td>\n",
       "      <td>76</td>\n",
       "      <td>0.342639</td>\n",
       "      <td>0.358113</td>\n",
       "      <td>0.242789</td>\n",
       "      <td>0.367106</td>\n",
       "      <td>0.317488</td>\n",
       "      <td>0.325627</td>\n",
       "      <td>0.044707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.115492</td>\n",
       "      <td>0.020041</td>\n",
       "      <td>0.011169</td>\n",
       "      <td>0.006747</td>\n",
       "      <td>3</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'dtc__max_depth': 3, 'dtc__max_features': 'lo...</td>\n",
       "      <td>0.289676</td>\n",
       "      <td>0.318565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.276806</td>\n",
       "      <td>0.038599</td>\n",
       "      <td>102</td>\n",
       "      <td>0.290162</td>\n",
       "      <td>0.316921</td>\n",
       "      <td>0.307338</td>\n",
       "      <td>0.212384</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.277125</td>\n",
       "      <td>0.037929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.343088</td>\n",
       "      <td>0.040948</td>\n",
       "      <td>0.016555</td>\n",
       "      <td>0.014266</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'dtc__max_depth': 3, 'dtc__max_features': Non...</td>\n",
       "      <td>0.467407</td>\n",
       "      <td>0.477963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.477259</td>\n",
       "      <td>0.007533</td>\n",
       "      <td>24</td>\n",
       "      <td>0.471875</td>\n",
       "      <td>0.482454</td>\n",
       "      <td>0.475231</td>\n",
       "      <td>0.484016</td>\n",
       "      <td>0.481123</td>\n",
       "      <td>0.478940</td>\n",
       "      <td>0.004616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.266492</td>\n",
       "      <td>0.037865</td>\n",
       "      <td>0.007978</td>\n",
       "      <td>0.005007</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'dtc__max_depth': 3, 'dtc__max_features': Non...</td>\n",
       "      <td>0.453611</td>\n",
       "      <td>0.463935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.462370</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>26</td>\n",
       "      <td>0.457650</td>\n",
       "      <td>0.468287</td>\n",
       "      <td>0.457373</td>\n",
       "      <td>0.466400</td>\n",
       "      <td>0.467257</td>\n",
       "      <td>0.463394</td>\n",
       "      <td>0.004840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.196475</td>\n",
       "      <td>0.008174</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'dtc__max_depth': 3, 'dtc__max_features': Non...</td>\n",
       "      <td>0.403380</td>\n",
       "      <td>0.411806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.409870</td>\n",
       "      <td>0.006162</td>\n",
       "      <td>41</td>\n",
       "      <td>0.404583</td>\n",
       "      <td>0.415694</td>\n",
       "      <td>0.404907</td>\n",
       "      <td>0.414213</td>\n",
       "      <td>0.415069</td>\n",
       "      <td>0.410894</td>\n",
       "      <td>0.005043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.191090</td>\n",
       "      <td>0.038485</td>\n",
       "      <td>0.007779</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'dtc__max_depth': 3, 'dtc__max_features': Non...</td>\n",
       "      <td>0.314213</td>\n",
       "      <td>0.311806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333574</td>\n",
       "      <td>0.025490</td>\n",
       "      <td>67</td>\n",
       "      <td>0.313032</td>\n",
       "      <td>0.313623</td>\n",
       "      <td>0.359815</td>\n",
       "      <td>0.370220</td>\n",
       "      <td>0.313356</td>\n",
       "      <td>0.334009</td>\n",
       "      <td>0.025532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.179920</td>\n",
       "      <td>0.020398</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'dtc__max_depth': 3, 'dtc__max_features': Non...</td>\n",
       "      <td>0.314213</td>\n",
       "      <td>0.311806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313259</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>81</td>\n",
       "      <td>0.313032</td>\n",
       "      <td>0.313623</td>\n",
       "      <td>0.313299</td>\n",
       "      <td>0.313032</td>\n",
       "      <td>0.313356</td>\n",
       "      <td>0.313269</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.238165</td>\n",
       "      <td>0.052516</td>\n",
       "      <td>0.012166</td>\n",
       "      <td>0.007119</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'dtc__max_depth': 5, 'dtc__max_features': 'au...</td>\n",
       "      <td>0.490370</td>\n",
       "      <td>0.540463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.505009</td>\n",
       "      <td>0.018058</td>\n",
       "      <td>20</td>\n",
       "      <td>0.494722</td>\n",
       "      <td>0.540833</td>\n",
       "      <td>0.503414</td>\n",
       "      <td>0.501481</td>\n",
       "      <td>0.497373</td>\n",
       "      <td>0.507565</td>\n",
       "      <td>0.016911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.186902</td>\n",
       "      <td>0.020908</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'dtc__max_depth': 5, 'dtc__max_features': 'au...</td>\n",
       "      <td>0.462407</td>\n",
       "      <td>0.424352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.437102</td>\n",
       "      <td>0.036177</td>\n",
       "      <td>34</td>\n",
       "      <td>0.461319</td>\n",
       "      <td>0.425648</td>\n",
       "      <td>0.493414</td>\n",
       "      <td>0.401366</td>\n",
       "      <td>0.397280</td>\n",
       "      <td>0.435806</td>\n",
       "      <td>0.036724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.150997</td>\n",
       "      <td>0.011910</td>\n",
       "      <td>0.006184</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'dtc__max_depth': 5, 'dtc__max_features': 'au...</td>\n",
       "      <td>0.404306</td>\n",
       "      <td>0.361759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.392759</td>\n",
       "      <td>0.019503</td>\n",
       "      <td>49</td>\n",
       "      <td>0.400116</td>\n",
       "      <td>0.363588</td>\n",
       "      <td>0.379282</td>\n",
       "      <td>0.412245</td>\n",
       "      <td>0.404363</td>\n",
       "      <td>0.391919</td>\n",
       "      <td>0.017875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.120678</td>\n",
       "      <td>0.015945</td>\n",
       "      <td>0.013563</td>\n",
       "      <td>0.010529</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'dtc__max_depth': 5, 'dtc__max_features': 'au...</td>\n",
       "      <td>0.330278</td>\n",
       "      <td>0.311806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338824</td>\n",
       "      <td>0.023695</td>\n",
       "      <td>64</td>\n",
       "      <td>0.331343</td>\n",
       "      <td>0.313623</td>\n",
       "      <td>0.317049</td>\n",
       "      <td>0.370220</td>\n",
       "      <td>0.362593</td>\n",
       "      <td>0.338965</td>\n",
       "      <td>0.023306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.116489</td>\n",
       "      <td>0.008330</td>\n",
       "      <td>0.005187</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'dtc__max_depth': 5, 'dtc__max_features': 'au...</td>\n",
       "      <td>0.308287</td>\n",
       "      <td>0.257917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286713</td>\n",
       "      <td>0.037202</td>\n",
       "      <td>96</td>\n",
       "      <td>0.307338</td>\n",
       "      <td>0.257905</td>\n",
       "      <td>0.226354</td>\n",
       "      <td>0.313032</td>\n",
       "      <td>0.327083</td>\n",
       "      <td>0.286343</td>\n",
       "      <td>0.038001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.211635</td>\n",
       "      <td>0.027871</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>0.001545</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'dtc__max_depth': 5, 'dtc__max_features': 'lo...</td>\n",
       "      <td>0.487407</td>\n",
       "      <td>0.489074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.476352</td>\n",
       "      <td>0.025602</td>\n",
       "      <td>25</td>\n",
       "      <td>0.490012</td>\n",
       "      <td>0.495694</td>\n",
       "      <td>0.452616</td>\n",
       "      <td>0.437870</td>\n",
       "      <td>0.513507</td>\n",
       "      <td>0.477940</td>\n",
       "      <td>0.028188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.162765</td>\n",
       "      <td>0.008726</td>\n",
       "      <td>0.005585</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'dtc__max_depth': 5, 'dtc__max_features': 'lo...</td>\n",
       "      <td>0.437130</td>\n",
       "      <td>0.487361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459454</td>\n",
       "      <td>0.019923</td>\n",
       "      <td>27</td>\n",
       "      <td>0.432847</td>\n",
       "      <td>0.492546</td>\n",
       "      <td>0.436030</td>\n",
       "      <td>0.449942</td>\n",
       "      <td>0.475127</td>\n",
       "      <td>0.457299</td>\n",
       "      <td>0.023085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.133244</td>\n",
       "      <td>0.013568</td>\n",
       "      <td>0.010372</td>\n",
       "      <td>0.005449</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'dtc__max_depth': 5, 'dtc__max_features': 'lo...</td>\n",
       "      <td>0.324954</td>\n",
       "      <td>0.375880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.336546</td>\n",
       "      <td>0.022778</td>\n",
       "      <td>65</td>\n",
       "      <td>0.331840</td>\n",
       "      <td>0.379988</td>\n",
       "      <td>0.344583</td>\n",
       "      <td>0.323843</td>\n",
       "      <td>0.315833</td>\n",
       "      <td>0.339218</td>\n",
       "      <td>0.022489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.117087</td>\n",
       "      <td>0.016743</td>\n",
       "      <td>0.010571</td>\n",
       "      <td>0.007533</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'dtc__max_depth': 5, 'dtc__max_features': 'lo...</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.322824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327481</td>\n",
       "      <td>0.017814</td>\n",
       "      <td>74</td>\n",
       "      <td>0.317488</td>\n",
       "      <td>0.323981</td>\n",
       "      <td>0.317049</td>\n",
       "      <td>0.362755</td>\n",
       "      <td>0.317488</td>\n",
       "      <td>0.327752</td>\n",
       "      <td>0.017690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.128059</td>\n",
       "      <td>0.023320</td>\n",
       "      <td>0.011369</td>\n",
       "      <td>0.007453</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'dtc__max_depth': 5, 'dtc__max_features': 'lo...</td>\n",
       "      <td>0.314213</td>\n",
       "      <td>0.305741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302676</td>\n",
       "      <td>0.019610</td>\n",
       "      <td>93</td>\n",
       "      <td>0.313032</td>\n",
       "      <td>0.307975</td>\n",
       "      <td>0.317049</td>\n",
       "      <td>0.263090</td>\n",
       "      <td>0.311493</td>\n",
       "      <td>0.302528</td>\n",
       "      <td>0.019933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.437630</td>\n",
       "      <td>0.101625</td>\n",
       "      <td>0.005984</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'dtc__max_depth': 5, 'dtc__max_features': Non...</td>\n",
       "      <td>0.553796</td>\n",
       "      <td>0.570463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564546</td>\n",
       "      <td>0.008006</td>\n",
       "      <td>6</td>\n",
       "      <td>0.557963</td>\n",
       "      <td>0.568287</td>\n",
       "      <td>0.561806</td>\n",
       "      <td>0.571817</td>\n",
       "      <td>0.569676</td>\n",
       "      <td>0.565910</td>\n",
       "      <td>0.005191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.267685</td>\n",
       "      <td>0.035044</td>\n",
       "      <td>0.007581</td>\n",
       "      <td>0.002720</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'dtc__max_depth': 5, 'dtc__max_features': Non...</td>\n",
       "      <td>0.503565</td>\n",
       "      <td>0.502546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.505870</td>\n",
       "      <td>0.002745</td>\n",
       "      <td>14</td>\n",
       "      <td>0.508183</td>\n",
       "      <td>0.506192</td>\n",
       "      <td>0.507569</td>\n",
       "      <td>0.504248</td>\n",
       "      <td>0.505116</td>\n",
       "      <td>0.506262</td>\n",
       "      <td>0.001468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.280057</td>\n",
       "      <td>0.025786</td>\n",
       "      <td>0.008777</td>\n",
       "      <td>0.006096</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'dtc__max_depth': 5, 'dtc__max_features': Non...</td>\n",
       "      <td>0.403380</td>\n",
       "      <td>0.411806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.409870</td>\n",
       "      <td>0.006162</td>\n",
       "      <td>41</td>\n",
       "      <td>0.404583</td>\n",
       "      <td>0.415694</td>\n",
       "      <td>0.404907</td>\n",
       "      <td>0.414213</td>\n",
       "      <td>0.415069</td>\n",
       "      <td>0.410894</td>\n",
       "      <td>0.005043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.262405</td>\n",
       "      <td>0.034097</td>\n",
       "      <td>0.011170</td>\n",
       "      <td>0.006951</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'dtc__max_depth': 5, 'dtc__max_features': Non...</td>\n",
       "      <td>0.314213</td>\n",
       "      <td>0.311806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333574</td>\n",
       "      <td>0.025490</td>\n",
       "      <td>67</td>\n",
       "      <td>0.313032</td>\n",
       "      <td>0.313623</td>\n",
       "      <td>0.359815</td>\n",
       "      <td>0.370220</td>\n",
       "      <td>0.313356</td>\n",
       "      <td>0.334009</td>\n",
       "      <td>0.025532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.224503</td>\n",
       "      <td>0.015029</td>\n",
       "      <td>0.006382</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'dtc__max_depth': 5, 'dtc__max_features': Non...</td>\n",
       "      <td>0.314213</td>\n",
       "      <td>0.311806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313259</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>81</td>\n",
       "      <td>0.313032</td>\n",
       "      <td>0.313623</td>\n",
       "      <td>0.313299</td>\n",
       "      <td>0.313032</td>\n",
       "      <td>0.313356</td>\n",
       "      <td>0.313269</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.178522</td>\n",
       "      <td>0.011441</td>\n",
       "      <td>0.012168</td>\n",
       "      <td>0.005691</td>\n",
       "      <td>13</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'dtc__max_depth': 13, 'dtc__max_features': 'a...</td>\n",
       "      <td>0.555370</td>\n",
       "      <td>0.557824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.543185</td>\n",
       "      <td>0.018945</td>\n",
       "      <td>7</td>\n",
       "      <td>0.561782</td>\n",
       "      <td>0.558854</td>\n",
       "      <td>0.550787</td>\n",
       "      <td>0.509352</td>\n",
       "      <td>0.542616</td>\n",
       "      <td>0.544678</td>\n",
       "      <td>0.018884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.186900</td>\n",
       "      <td>0.067496</td>\n",
       "      <td>0.011176</td>\n",
       "      <td>0.008904</td>\n",
       "      <td>13</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'dtc__max_depth': 13, 'dtc__max_features': 'a...</td>\n",
       "      <td>0.373796</td>\n",
       "      <td>0.473750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.427648</td>\n",
       "      <td>0.032852</td>\n",
       "      <td>35</td>\n",
       "      <td>0.380451</td>\n",
       "      <td>0.473229</td>\n",
       "      <td>0.415197</td>\n",
       "      <td>0.431343</td>\n",
       "      <td>0.442002</td>\n",
       "      <td>0.428444</td>\n",
       "      <td>0.030583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.157580</td>\n",
       "      <td>0.028504</td>\n",
       "      <td>0.009775</td>\n",
       "      <td>0.003178</td>\n",
       "      <td>13</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'dtc__max_depth': 13, 'dtc__max_features': 'a...</td>\n",
       "      <td>0.354769</td>\n",
       "      <td>0.403519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.377620</td>\n",
       "      <td>0.019905</td>\n",
       "      <td>52</td>\n",
       "      <td>0.351308</td>\n",
       "      <td>0.409664</td>\n",
       "      <td>0.370208</td>\n",
       "      <td>0.396030</td>\n",
       "      <td>0.363009</td>\n",
       "      <td>0.378044</td>\n",
       "      <td>0.021567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.174540</td>\n",
       "      <td>0.029291</td>\n",
       "      <td>0.009772</td>\n",
       "      <td>0.005621</td>\n",
       "      <td>13</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'dtc__max_depth': 13, 'dtc__max_features': 'a...</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.358241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.316926</td>\n",
       "      <td>0.021207</td>\n",
       "      <td>80</td>\n",
       "      <td>0.309456</td>\n",
       "      <td>0.358113</td>\n",
       "      <td>0.301806</td>\n",
       "      <td>0.314653</td>\n",
       "      <td>0.303252</td>\n",
       "      <td>0.317456</td>\n",
       "      <td>0.020840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.119680</td>\n",
       "      <td>0.009419</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>13</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'dtc__max_depth': 13, 'dtc__max_features': 'a...</td>\n",
       "      <td>0.289213</td>\n",
       "      <td>0.200880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259870</td>\n",
       "      <td>0.044330</td>\n",
       "      <td>105</td>\n",
       "      <td>0.287975</td>\n",
       "      <td>0.200602</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.212384</td>\n",
       "      <td>0.289317</td>\n",
       "      <td>0.260278</td>\n",
       "      <td>0.044832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.232287</td>\n",
       "      <td>0.034426</td>\n",
       "      <td>0.012766</td>\n",
       "      <td>0.011603</td>\n",
       "      <td>13</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'dtc__max_depth': 13, 'dtc__max_features': 'l...</td>\n",
       "      <td>0.419120</td>\n",
       "      <td>0.551667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523870</td>\n",
       "      <td>0.054731</td>\n",
       "      <td>11</td>\n",
       "      <td>0.420278</td>\n",
       "      <td>0.555613</td>\n",
       "      <td>0.518461</td>\n",
       "      <td>0.564063</td>\n",
       "      <td>0.557535</td>\n",
       "      <td>0.523190</td>\n",
       "      <td>0.053879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.192685</td>\n",
       "      <td>0.020991</td>\n",
       "      <td>0.008577</td>\n",
       "      <td>0.002792</td>\n",
       "      <td>13</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'dtc__max_depth': 13, 'dtc__max_features': 'l...</td>\n",
       "      <td>0.454352</td>\n",
       "      <td>0.442361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438222</td>\n",
       "      <td>0.018622</td>\n",
       "      <td>32</td>\n",
       "      <td>0.454572</td>\n",
       "      <td>0.447604</td>\n",
       "      <td>0.407650</td>\n",
       "      <td>0.426030</td>\n",
       "      <td>0.457789</td>\n",
       "      <td>0.438729</td>\n",
       "      <td>0.019080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.151995</td>\n",
       "      <td>0.007152</td>\n",
       "      <td>0.006981</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>13</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'dtc__max_depth': 13, 'dtc__max_features': 'l...</td>\n",
       "      <td>0.347176</td>\n",
       "      <td>0.412731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.374417</td>\n",
       "      <td>0.029799</td>\n",
       "      <td>53</td>\n",
       "      <td>0.342685</td>\n",
       "      <td>0.416181</td>\n",
       "      <td>0.400370</td>\n",
       "      <td>0.368773</td>\n",
       "      <td>0.338854</td>\n",
       "      <td>0.373373</td>\n",
       "      <td>0.030711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.154787</td>\n",
       "      <td>0.011449</td>\n",
       "      <td>0.006382</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>13</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'dtc__max_depth': 13, 'dtc__max_features': 'l...</td>\n",
       "      <td>0.367130</td>\n",
       "      <td>0.309815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305602</td>\n",
       "      <td>0.040426</td>\n",
       "      <td>91</td>\n",
       "      <td>0.366806</td>\n",
       "      <td>0.311690</td>\n",
       "      <td>0.317049</td>\n",
       "      <td>0.287789</td>\n",
       "      <td>0.245637</td>\n",
       "      <td>0.305794</td>\n",
       "      <td>0.039565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.156187</td>\n",
       "      <td>0.022320</td>\n",
       "      <td>0.008378</td>\n",
       "      <td>0.005338</td>\n",
       "      <td>13</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'dtc__max_depth': 13, 'dtc__max_features': 'l...</td>\n",
       "      <td>0.289676</td>\n",
       "      <td>0.311806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293787</td>\n",
       "      <td>0.020088</td>\n",
       "      <td>94</td>\n",
       "      <td>0.290162</td>\n",
       "      <td>0.313623</td>\n",
       "      <td>0.257431</td>\n",
       "      <td>0.289792</td>\n",
       "      <td>0.317442</td>\n",
       "      <td>0.293690</td>\n",
       "      <td>0.021466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.529194</td>\n",
       "      <td>0.035996</td>\n",
       "      <td>0.006582</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>13</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'dtc__max_depth': 13, 'dtc__max_features': No...</td>\n",
       "      <td>0.554213</td>\n",
       "      <td>0.571204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.567389</td>\n",
       "      <td>0.009441</td>\n",
       "      <td>1</td>\n",
       "      <td>0.559387</td>\n",
       "      <td>0.569329</td>\n",
       "      <td>0.562998</td>\n",
       "      <td>0.572743</td>\n",
       "      <td>0.581215</td>\n",
       "      <td>0.569134</td>\n",
       "      <td>0.007638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.353464</td>\n",
       "      <td>0.046187</td>\n",
       "      <td>0.012566</td>\n",
       "      <td>0.012176</td>\n",
       "      <td>13</td>\n",
       "      <td>None</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'dtc__max_depth': 13, 'dtc__max_features': No...</td>\n",
       "      <td>0.503565</td>\n",
       "      <td>0.502546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.505870</td>\n",
       "      <td>0.002745</td>\n",
       "      <td>14</td>\n",
       "      <td>0.508183</td>\n",
       "      <td>0.506192</td>\n",
       "      <td>0.507569</td>\n",
       "      <td>0.504248</td>\n",
       "      <td>0.505116</td>\n",
       "      <td>0.506262</td>\n",
       "      <td>0.001468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.282048</td>\n",
       "      <td>0.022287</td>\n",
       "      <td>0.008376</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>13</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'dtc__max_depth': 13, 'dtc__max_features': No...</td>\n",
       "      <td>0.403380</td>\n",
       "      <td>0.411806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.409870</td>\n",
       "      <td>0.006162</td>\n",
       "      <td>41</td>\n",
       "      <td>0.404583</td>\n",
       "      <td>0.415694</td>\n",
       "      <td>0.404907</td>\n",
       "      <td>0.414213</td>\n",
       "      <td>0.415069</td>\n",
       "      <td>0.410894</td>\n",
       "      <td>0.005043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.241463</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.007378</td>\n",
       "      <td>0.001495</td>\n",
       "      <td>13</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'dtc__max_depth': 13, 'dtc__max_features': No...</td>\n",
       "      <td>0.314213</td>\n",
       "      <td>0.311806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333574</td>\n",
       "      <td>0.025490</td>\n",
       "      <td>67</td>\n",
       "      <td>0.313032</td>\n",
       "      <td>0.313623</td>\n",
       "      <td>0.359815</td>\n",
       "      <td>0.370220</td>\n",
       "      <td>0.313356</td>\n",
       "      <td>0.334009</td>\n",
       "      <td>0.025532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.214638</td>\n",
       "      <td>0.016350</td>\n",
       "      <td>0.008379</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>13</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'dtc__max_depth': 13, 'dtc__max_features': No...</td>\n",
       "      <td>0.314213</td>\n",
       "      <td>0.311806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313259</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>81</td>\n",
       "      <td>0.313032</td>\n",
       "      <td>0.313623</td>\n",
       "      <td>0.313299</td>\n",
       "      <td>0.313032</td>\n",
       "      <td>0.313356</td>\n",
       "      <td>0.313269</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.182922</td>\n",
       "      <td>0.015249</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>15</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'dtc__max_depth': 15, 'dtc__max_features': 'a...</td>\n",
       "      <td>0.500278</td>\n",
       "      <td>0.527037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.510935</td>\n",
       "      <td>0.023041</td>\n",
       "      <td>13</td>\n",
       "      <td>0.503310</td>\n",
       "      <td>0.525914</td>\n",
       "      <td>0.549479</td>\n",
       "      <td>0.487431</td>\n",
       "      <td>0.491678</td>\n",
       "      <td>0.511562</td>\n",
       "      <td>0.023193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.158287</td>\n",
       "      <td>0.014751</td>\n",
       "      <td>0.009175</td>\n",
       "      <td>0.004433</td>\n",
       "      <td>15</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'dtc__max_depth': 15, 'dtc__max_features': 'a...</td>\n",
       "      <td>0.473704</td>\n",
       "      <td>0.434630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.437944</td>\n",
       "      <td>0.031944</td>\n",
       "      <td>33</td>\n",
       "      <td>0.478889</td>\n",
       "      <td>0.438287</td>\n",
       "      <td>0.382604</td>\n",
       "      <td>0.468623</td>\n",
       "      <td>0.425197</td>\n",
       "      <td>0.438720</td>\n",
       "      <td>0.034175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.143617</td>\n",
       "      <td>0.018658</td>\n",
       "      <td>0.009174</td>\n",
       "      <td>0.003858</td>\n",
       "      <td>15</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'dtc__max_depth': 15, 'dtc__max_features': 'a...</td>\n",
       "      <td>0.312454</td>\n",
       "      <td>0.354167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363231</td>\n",
       "      <td>0.028718</td>\n",
       "      <td>56</td>\n",
       "      <td>0.312593</td>\n",
       "      <td>0.355116</td>\n",
       "      <td>0.396424</td>\n",
       "      <td>0.376123</td>\n",
       "      <td>0.375856</td>\n",
       "      <td>0.363222</td>\n",
       "      <td>0.028487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.164367</td>\n",
       "      <td>0.013955</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.001849</td>\n",
       "      <td>15</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'dtc__max_depth': 15, 'dtc__max_features': 'a...</td>\n",
       "      <td>0.231019</td>\n",
       "      <td>0.360556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.326083</td>\n",
       "      <td>0.048096</td>\n",
       "      <td>75</td>\n",
       "      <td>0.229456</td>\n",
       "      <td>0.363299</td>\n",
       "      <td>0.342477</td>\n",
       "      <td>0.339502</td>\n",
       "      <td>0.354444</td>\n",
       "      <td>0.325836</td>\n",
       "      <td>0.048938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.158484</td>\n",
       "      <td>0.032630</td>\n",
       "      <td>0.022540</td>\n",
       "      <td>0.019701</td>\n",
       "      <td>15</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'dtc__max_depth': 15, 'dtc__max_features': 'a...</td>\n",
       "      <td>0.224120</td>\n",
       "      <td>0.289259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277167</td>\n",
       "      <td>0.030072</td>\n",
       "      <td>101</td>\n",
       "      <td>0.227407</td>\n",
       "      <td>0.290255</td>\n",
       "      <td>0.277731</td>\n",
       "      <td>0.277836</td>\n",
       "      <td>0.317488</td>\n",
       "      <td>0.278144</td>\n",
       "      <td>0.029220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.280849</td>\n",
       "      <td>0.044202</td>\n",
       "      <td>0.018350</td>\n",
       "      <td>0.014433</td>\n",
       "      <td>15</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'dtc__max_depth': 15, 'dtc__max_features': 'l...</td>\n",
       "      <td>0.526065</td>\n",
       "      <td>0.461250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499213</td>\n",
       "      <td>0.025589</td>\n",
       "      <td>21</td>\n",
       "      <td>0.530220</td>\n",
       "      <td>0.463692</td>\n",
       "      <td>0.513588</td>\n",
       "      <td>0.481181</td>\n",
       "      <td>0.514711</td>\n",
       "      <td>0.500678</td>\n",
       "      <td>0.024431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.203359</td>\n",
       "      <td>0.024195</td>\n",
       "      <td>0.006781</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>15</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'dtc__max_depth': 15, 'dtc__max_features': 'l...</td>\n",
       "      <td>0.425602</td>\n",
       "      <td>0.386806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412028</td>\n",
       "      <td>0.026462</td>\n",
       "      <td>40</td>\n",
       "      <td>0.427025</td>\n",
       "      <td>0.390278</td>\n",
       "      <td>0.415926</td>\n",
       "      <td>0.456887</td>\n",
       "      <td>0.377095</td>\n",
       "      <td>0.413442</td>\n",
       "      <td>0.028056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.128509</td>\n",
       "      <td>0.009049</td>\n",
       "      <td>0.009078</td>\n",
       "      <td>0.003128</td>\n",
       "      <td>15</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'dtc__max_depth': 15, 'dtc__max_features': 'l...</td>\n",
       "      <td>0.371435</td>\n",
       "      <td>0.336620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339444</td>\n",
       "      <td>0.019129</td>\n",
       "      <td>63</td>\n",
       "      <td>0.370648</td>\n",
       "      <td>0.338148</td>\n",
       "      <td>0.344641</td>\n",
       "      <td>0.328542</td>\n",
       "      <td>0.315995</td>\n",
       "      <td>0.339595</td>\n",
       "      <td>0.018281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.151702</td>\n",
       "      <td>0.014020</td>\n",
       "      <td>0.007684</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>15</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'dtc__max_depth': 15, 'dtc__max_features': 'l...</td>\n",
       "      <td>0.336852</td>\n",
       "      <td>0.287639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321981</td>\n",
       "      <td>0.038246</td>\n",
       "      <td>78</td>\n",
       "      <td>0.335706</td>\n",
       "      <td>0.288368</td>\n",
       "      <td>0.355995</td>\n",
       "      <td>0.362755</td>\n",
       "      <td>0.266516</td>\n",
       "      <td>0.321868</td>\n",
       "      <td>0.037984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.132649</td>\n",
       "      <td>0.013496</td>\n",
       "      <td>0.009774</td>\n",
       "      <td>0.005178</td>\n",
       "      <td>15</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'dtc__max_depth': 15, 'dtc__max_features': 'l...</td>\n",
       "      <td>0.256296</td>\n",
       "      <td>0.303565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280556</td>\n",
       "      <td>0.019226</td>\n",
       "      <td>99</td>\n",
       "      <td>0.256991</td>\n",
       "      <td>0.301690</td>\n",
       "      <td>0.286065</td>\n",
       "      <td>0.257546</td>\n",
       "      <td>0.296366</td>\n",
       "      <td>0.279731</td>\n",
       "      <td>0.019017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.455088</td>\n",
       "      <td>0.052331</td>\n",
       "      <td>0.007379</td>\n",
       "      <td>0.002492</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'dtc__max_depth': 15, 'dtc__max_features': No...</td>\n",
       "      <td>0.554213</td>\n",
       "      <td>0.571204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.567389</td>\n",
       "      <td>0.009441</td>\n",
       "      <td>1</td>\n",
       "      <td>0.559387</td>\n",
       "      <td>0.569329</td>\n",
       "      <td>0.562998</td>\n",
       "      <td>0.572743</td>\n",
       "      <td>0.581215</td>\n",
       "      <td>0.569134</td>\n",
       "      <td>0.007638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.309675</td>\n",
       "      <td>0.054251</td>\n",
       "      <td>0.006184</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'dtc__max_depth': 15, 'dtc__max_features': No...</td>\n",
       "      <td>0.503565</td>\n",
       "      <td>0.502546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.505870</td>\n",
       "      <td>0.002745</td>\n",
       "      <td>14</td>\n",
       "      <td>0.508183</td>\n",
       "      <td>0.506192</td>\n",
       "      <td>0.507569</td>\n",
       "      <td>0.504248</td>\n",
       "      <td>0.505116</td>\n",
       "      <td>0.506262</td>\n",
       "      <td>0.001468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.256315</td>\n",
       "      <td>0.048989</td>\n",
       "      <td>0.011369</td>\n",
       "      <td>0.006603</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'dtc__max_depth': 15, 'dtc__max_features': No...</td>\n",
       "      <td>0.403380</td>\n",
       "      <td>0.411806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.409870</td>\n",
       "      <td>0.006162</td>\n",
       "      <td>41</td>\n",
       "      <td>0.404583</td>\n",
       "      <td>0.415694</td>\n",
       "      <td>0.404907</td>\n",
       "      <td>0.414213</td>\n",
       "      <td>0.415069</td>\n",
       "      <td>0.410894</td>\n",
       "      <td>0.005043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.278061</td>\n",
       "      <td>0.051665</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'dtc__max_depth': 15, 'dtc__max_features': No...</td>\n",
       "      <td>0.314213</td>\n",
       "      <td>0.311806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333574</td>\n",
       "      <td>0.025490</td>\n",
       "      <td>67</td>\n",
       "      <td>0.313032</td>\n",
       "      <td>0.313623</td>\n",
       "      <td>0.359815</td>\n",
       "      <td>0.370220</td>\n",
       "      <td>0.313356</td>\n",
       "      <td>0.334009</td>\n",
       "      <td>0.025532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.255721</td>\n",
       "      <td>0.061576</td>\n",
       "      <td>0.012765</td>\n",
       "      <td>0.014082</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'dtc__max_depth': 15, 'dtc__max_features': No...</td>\n",
       "      <td>0.314213</td>\n",
       "      <td>0.311806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313259</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>81</td>\n",
       "      <td>0.313032</td>\n",
       "      <td>0.313623</td>\n",
       "      <td>0.313299</td>\n",
       "      <td>0.313032</td>\n",
       "      <td>0.313356</td>\n",
       "      <td>0.313269</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         0.154388      0.031332         0.006382        0.001492   \n",
       "1         0.164959      0.021087         0.009575        0.005936   \n",
       "2         0.145812      0.019486         0.008974        0.004038   \n",
       "3         0.127061      0.019159         0.007978        0.004549   \n",
       "4         0.100133      0.007766         0.016157        0.014068   \n",
       "5         0.156781      0.013025         0.007380        0.002327   \n",
       "6         0.159179      0.020406         0.006382        0.000489   \n",
       "7         0.135641      0.015597         0.015757        0.013840   \n",
       "8         0.130451      0.014825         0.007978        0.005500   \n",
       "9         0.115492      0.020041         0.011169        0.006747   \n",
       "10        0.343088      0.040948         0.016555        0.014266   \n",
       "11        0.266492      0.037865         0.007978        0.005007   \n",
       "12        0.196475      0.008174         0.005785        0.000399   \n",
       "13        0.191090      0.038485         0.007779        0.002918   \n",
       "14        0.179920      0.020398         0.005784        0.000746   \n",
       "15        0.238165      0.052516         0.012166        0.007119   \n",
       "16        0.186902      0.020908         0.006381        0.001353   \n",
       "17        0.150997      0.011910         0.006184        0.000399   \n",
       "18        0.120678      0.015945         0.013563        0.010529   \n",
       "19        0.116489      0.008330         0.005187        0.000399   \n",
       "20        0.211635      0.027871         0.006982        0.001545   \n",
       "21        0.162765      0.008726         0.005585        0.000489   \n",
       "22        0.133244      0.013568         0.010372        0.005449   \n",
       "23        0.117087      0.016743         0.010571        0.007533   \n",
       "24        0.128059      0.023320         0.011369        0.007453   \n",
       "25        0.437630      0.101625         0.005984        0.000631   \n",
       "26        0.267685      0.035044         0.007581        0.002720   \n",
       "27        0.280057      0.025786         0.008777        0.006096   \n",
       "28        0.262405      0.034097         0.011170        0.006951   \n",
       "29        0.224503      0.015029         0.006382        0.001353   \n",
       "..             ...           ...              ...             ...   \n",
       "75        0.178522      0.011441         0.012168        0.005691   \n",
       "76        0.186900      0.067496         0.011176        0.008904   \n",
       "77        0.157580      0.028504         0.009775        0.003178   \n",
       "78        0.174540      0.029291         0.009772        0.005621   \n",
       "79        0.119680      0.009419         0.007380        0.002326   \n",
       "80        0.232287      0.034426         0.012766        0.011603   \n",
       "81        0.192685      0.020991         0.008577        0.002792   \n",
       "82        0.151995      0.007152         0.006981        0.001092   \n",
       "83        0.154787      0.011449         0.006382        0.001017   \n",
       "84        0.156187      0.022320         0.008378        0.005338   \n",
       "85        0.529194      0.035996         0.006582        0.001197   \n",
       "86        0.353464      0.046187         0.012566        0.012176   \n",
       "87        0.282048      0.022287         0.008376        0.002999   \n",
       "88        0.241463      0.028571         0.007378        0.001495   \n",
       "89        0.214638      0.016350         0.008379        0.002058   \n",
       "90        0.182922      0.015249         0.007380        0.001016   \n",
       "91        0.158287      0.014751         0.009175        0.004433   \n",
       "92        0.143617      0.018658         0.009174        0.003858   \n",
       "93        0.164367      0.013955         0.007380        0.001849   \n",
       "94        0.158484      0.032630         0.022540        0.019701   \n",
       "95        0.280849      0.044202         0.018350        0.014433   \n",
       "96        0.203359      0.024195         0.006781        0.000747   \n",
       "97        0.128509      0.009049         0.009078        0.003128   \n",
       "98        0.151702      0.014020         0.007684        0.002778   \n",
       "99        0.132649      0.013496         0.009774        0.005178   \n",
       "100       0.455088      0.052331         0.007379        0.002492   \n",
       "101       0.309675      0.054251         0.006184        0.000400   \n",
       "102       0.256315      0.048989         0.011369        0.006603   \n",
       "103       0.278061      0.051665         0.006782        0.002632   \n",
       "104       0.255721      0.061576         0.012765        0.014082   \n",
       "\n",
       "    param_dtc__max_depth param_dtc__max_features param_dtc__min_samples_split  \\\n",
       "0                      3                    auto                          0.1   \n",
       "1                      3                    auto                          0.2   \n",
       "2                      3                    auto                          0.3   \n",
       "3                      3                    auto                          0.4   \n",
       "4                      3                    auto                          0.5   \n",
       "5                      3                    log2                          0.1   \n",
       "6                      3                    log2                          0.2   \n",
       "7                      3                    log2                          0.3   \n",
       "8                      3                    log2                          0.4   \n",
       "9                      3                    log2                          0.5   \n",
       "10                     3                    None                          0.1   \n",
       "11                     3                    None                          0.2   \n",
       "12                     3                    None                          0.3   \n",
       "13                     3                    None                          0.4   \n",
       "14                     3                    None                          0.5   \n",
       "15                     5                    auto                          0.1   \n",
       "16                     5                    auto                          0.2   \n",
       "17                     5                    auto                          0.3   \n",
       "18                     5                    auto                          0.4   \n",
       "19                     5                    auto                          0.5   \n",
       "20                     5                    log2                          0.1   \n",
       "21                     5                    log2                          0.2   \n",
       "22                     5                    log2                          0.3   \n",
       "23                     5                    log2                          0.4   \n",
       "24                     5                    log2                          0.5   \n",
       "25                     5                    None                          0.1   \n",
       "26                     5                    None                          0.2   \n",
       "27                     5                    None                          0.3   \n",
       "28                     5                    None                          0.4   \n",
       "29                     5                    None                          0.5   \n",
       "..                   ...                     ...                          ...   \n",
       "75                    13                    auto                          0.1   \n",
       "76                    13                    auto                          0.2   \n",
       "77                    13                    auto                          0.3   \n",
       "78                    13                    auto                          0.4   \n",
       "79                    13                    auto                          0.5   \n",
       "80                    13                    log2                          0.1   \n",
       "81                    13                    log2                          0.2   \n",
       "82                    13                    log2                          0.3   \n",
       "83                    13                    log2                          0.4   \n",
       "84                    13                    log2                          0.5   \n",
       "85                    13                    None                          0.1   \n",
       "86                    13                    None                          0.2   \n",
       "87                    13                    None                          0.3   \n",
       "88                    13                    None                          0.4   \n",
       "89                    13                    None                          0.5   \n",
       "90                    15                    auto                          0.1   \n",
       "91                    15                    auto                          0.2   \n",
       "92                    15                    auto                          0.3   \n",
       "93                    15                    auto                          0.4   \n",
       "94                    15                    auto                          0.5   \n",
       "95                    15                    log2                          0.1   \n",
       "96                    15                    log2                          0.2   \n",
       "97                    15                    log2                          0.3   \n",
       "98                    15                    log2                          0.4   \n",
       "99                    15                    log2                          0.5   \n",
       "100                   15                    None                          0.1   \n",
       "101                   15                    None                          0.2   \n",
       "102                   15                    None                          0.3   \n",
       "103                   15                    None                          0.4   \n",
       "104                   15                    None                          0.5   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "0    {'dtc__max_depth': 3, 'dtc__max_features': 'au...           0.404074   \n",
       "1    {'dtc__max_depth': 3, 'dtc__max_features': 'au...           0.408380   \n",
       "2    {'dtc__max_depth': 3, 'dtc__max_features': 'au...           0.414537   \n",
       "3    {'dtc__max_depth': 3, 'dtc__max_features': 'au...           0.344676   \n",
       "4    {'dtc__max_depth': 3, 'dtc__max_features': 'au...           0.263056   \n",
       "5    {'dtc__max_depth': 3, 'dtc__max_features': 'lo...           0.441296   \n",
       "6    {'dtc__max_depth': 3, 'dtc__max_features': 'lo...           0.320278   \n",
       "7    {'dtc__max_depth': 3, 'dtc__max_features': 'lo...           0.336852   \n",
       "8    {'dtc__max_depth': 3, 'dtc__max_features': 'lo...           0.343889   \n",
       "9    {'dtc__max_depth': 3, 'dtc__max_features': 'lo...           0.289676   \n",
       "10   {'dtc__max_depth': 3, 'dtc__max_features': Non...           0.467407   \n",
       "11   {'dtc__max_depth': 3, 'dtc__max_features': Non...           0.453611   \n",
       "12   {'dtc__max_depth': 3, 'dtc__max_features': Non...           0.403380   \n",
       "13   {'dtc__max_depth': 3, 'dtc__max_features': Non...           0.314213   \n",
       "14   {'dtc__max_depth': 3, 'dtc__max_features': Non...           0.314213   \n",
       "15   {'dtc__max_depth': 5, 'dtc__max_features': 'au...           0.490370   \n",
       "16   {'dtc__max_depth': 5, 'dtc__max_features': 'au...           0.462407   \n",
       "17   {'dtc__max_depth': 5, 'dtc__max_features': 'au...           0.404306   \n",
       "18   {'dtc__max_depth': 5, 'dtc__max_features': 'au...           0.330278   \n",
       "19   {'dtc__max_depth': 5, 'dtc__max_features': 'au...           0.308287   \n",
       "20   {'dtc__max_depth': 5, 'dtc__max_features': 'lo...           0.487407   \n",
       "21   {'dtc__max_depth': 5, 'dtc__max_features': 'lo...           0.437130   \n",
       "22   {'dtc__max_depth': 5, 'dtc__max_features': 'lo...           0.324954   \n",
       "23   {'dtc__max_depth': 5, 'dtc__max_features': 'lo...           0.316667   \n",
       "24   {'dtc__max_depth': 5, 'dtc__max_features': 'lo...           0.314213   \n",
       "25   {'dtc__max_depth': 5, 'dtc__max_features': Non...           0.553796   \n",
       "26   {'dtc__max_depth': 5, 'dtc__max_features': Non...           0.503565   \n",
       "27   {'dtc__max_depth': 5, 'dtc__max_features': Non...           0.403380   \n",
       "28   {'dtc__max_depth': 5, 'dtc__max_features': Non...           0.314213   \n",
       "29   {'dtc__max_depth': 5, 'dtc__max_features': Non...           0.314213   \n",
       "..                                                 ...                ...   \n",
       "75   {'dtc__max_depth': 13, 'dtc__max_features': 'a...           0.555370   \n",
       "76   {'dtc__max_depth': 13, 'dtc__max_features': 'a...           0.373796   \n",
       "77   {'dtc__max_depth': 13, 'dtc__max_features': 'a...           0.354769   \n",
       "78   {'dtc__max_depth': 13, 'dtc__max_features': 'a...           0.310000   \n",
       "79   {'dtc__max_depth': 13, 'dtc__max_features': 'a...           0.289213   \n",
       "80   {'dtc__max_depth': 13, 'dtc__max_features': 'l...           0.419120   \n",
       "81   {'dtc__max_depth': 13, 'dtc__max_features': 'l...           0.454352   \n",
       "82   {'dtc__max_depth': 13, 'dtc__max_features': 'l...           0.347176   \n",
       "83   {'dtc__max_depth': 13, 'dtc__max_features': 'l...           0.367130   \n",
       "84   {'dtc__max_depth': 13, 'dtc__max_features': 'l...           0.289676   \n",
       "85   {'dtc__max_depth': 13, 'dtc__max_features': No...           0.554213   \n",
       "86   {'dtc__max_depth': 13, 'dtc__max_features': No...           0.503565   \n",
       "87   {'dtc__max_depth': 13, 'dtc__max_features': No...           0.403380   \n",
       "88   {'dtc__max_depth': 13, 'dtc__max_features': No...           0.314213   \n",
       "89   {'dtc__max_depth': 13, 'dtc__max_features': No...           0.314213   \n",
       "90   {'dtc__max_depth': 15, 'dtc__max_features': 'a...           0.500278   \n",
       "91   {'dtc__max_depth': 15, 'dtc__max_features': 'a...           0.473704   \n",
       "92   {'dtc__max_depth': 15, 'dtc__max_features': 'a...           0.312454   \n",
       "93   {'dtc__max_depth': 15, 'dtc__max_features': 'a...           0.231019   \n",
       "94   {'dtc__max_depth': 15, 'dtc__max_features': 'a...           0.224120   \n",
       "95   {'dtc__max_depth': 15, 'dtc__max_features': 'l...           0.526065   \n",
       "96   {'dtc__max_depth': 15, 'dtc__max_features': 'l...           0.425602   \n",
       "97   {'dtc__max_depth': 15, 'dtc__max_features': 'l...           0.371435   \n",
       "98   {'dtc__max_depth': 15, 'dtc__max_features': 'l...           0.336852   \n",
       "99   {'dtc__max_depth': 15, 'dtc__max_features': 'l...           0.256296   \n",
       "100  {'dtc__max_depth': 15, 'dtc__max_features': No...           0.554213   \n",
       "101  {'dtc__max_depth': 15, 'dtc__max_features': No...           0.503565   \n",
       "102  {'dtc__max_depth': 15, 'dtc__max_features': No...           0.403380   \n",
       "103  {'dtc__max_depth': 15, 'dtc__max_features': No...           0.314213   \n",
       "104  {'dtc__max_depth': 15, 'dtc__max_features': No...           0.314213   \n",
       "\n",
       "     split1_test_score  ...  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0             0.409028  ...         0.412157        0.020037               39   \n",
       "1             0.417593  ...         0.419991        0.024686               37   \n",
       "2             0.318565  ...         0.378231        0.031892               51   \n",
       "3             0.305231  ...         0.319907        0.013286               79   \n",
       "4             0.311806  ...         0.271102        0.037739              103   \n",
       "5             0.412731  ...         0.408259        0.050907               48   \n",
       "6             0.334028  ...         0.374065        0.043201               54   \n",
       "7             0.383889  ...         0.361009        0.023675               57   \n",
       "8             0.358241  ...         0.325491        0.045301               76   \n",
       "9             0.318565  ...         0.276806        0.038599              102   \n",
       "10            0.477963  ...         0.477259        0.007533               24   \n",
       "11            0.463935  ...         0.462370        0.007143               26   \n",
       "12            0.411806  ...         0.409870        0.006162               41   \n",
       "13            0.311806  ...         0.333574        0.025490               67   \n",
       "14            0.311806  ...         0.313259        0.000901               81   \n",
       "15            0.540463  ...         0.505009        0.018058               20   \n",
       "16            0.424352  ...         0.437102        0.036177               34   \n",
       "17            0.361759  ...         0.392759        0.019503               49   \n",
       "18            0.311806  ...         0.338824        0.023695               64   \n",
       "19            0.257917  ...         0.286713        0.037202               96   \n",
       "20            0.489074  ...         0.476352        0.025602               25   \n",
       "21            0.487361  ...         0.459454        0.019923               27   \n",
       "22            0.375880  ...         0.336546        0.022778               65   \n",
       "23            0.322824  ...         0.327481        0.017814               74   \n",
       "24            0.305741  ...         0.302676        0.019610               93   \n",
       "25            0.570463  ...         0.564546        0.008006                6   \n",
       "26            0.502546  ...         0.505870        0.002745               14   \n",
       "27            0.411806  ...         0.409870        0.006162               41   \n",
       "28            0.311806  ...         0.333574        0.025490               67   \n",
       "29            0.311806  ...         0.313259        0.000901               81   \n",
       "..                 ...  ...              ...             ...              ...   \n",
       "75            0.557824  ...         0.543185        0.018945                7   \n",
       "76            0.473750  ...         0.427648        0.032852               35   \n",
       "77            0.403519  ...         0.377620        0.019905               52   \n",
       "78            0.358241  ...         0.316926        0.021207               80   \n",
       "79            0.200880  ...         0.259870        0.044330              105   \n",
       "80            0.551667  ...         0.523870        0.054731               11   \n",
       "81            0.442361  ...         0.438222        0.018622               32   \n",
       "82            0.412731  ...         0.374417        0.029799               53   \n",
       "83            0.309815  ...         0.305602        0.040426               91   \n",
       "84            0.311806  ...         0.293787        0.020088               94   \n",
       "85            0.571204  ...         0.567389        0.009441                1   \n",
       "86            0.502546  ...         0.505870        0.002745               14   \n",
       "87            0.411806  ...         0.409870        0.006162               41   \n",
       "88            0.311806  ...         0.333574        0.025490               67   \n",
       "89            0.311806  ...         0.313259        0.000901               81   \n",
       "90            0.527037  ...         0.510935        0.023041               13   \n",
       "91            0.434630  ...         0.437944        0.031944               33   \n",
       "92            0.354167  ...         0.363231        0.028718               56   \n",
       "93            0.360556  ...         0.326083        0.048096               75   \n",
       "94            0.289259  ...         0.277167        0.030072              101   \n",
       "95            0.461250  ...         0.499213        0.025589               21   \n",
       "96            0.386806  ...         0.412028        0.026462               40   \n",
       "97            0.336620  ...         0.339444        0.019129               63   \n",
       "98            0.287639  ...         0.321981        0.038246               78   \n",
       "99            0.303565  ...         0.280556        0.019226               99   \n",
       "100           0.571204  ...         0.567389        0.009441                1   \n",
       "101           0.502546  ...         0.505870        0.002745               14   \n",
       "102           0.411806  ...         0.409870        0.006162               41   \n",
       "103           0.311806  ...         0.333574        0.025490               67   \n",
       "104           0.311806  ...         0.313259        0.000901               81   \n",
       "\n",
       "     split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0              0.410787            0.412755            0.388113   \n",
       "1              0.411609            0.420012            0.402917   \n",
       "2              0.414329            0.316921            0.385174   \n",
       "3              0.342743            0.303380            0.317049   \n",
       "4              0.263414            0.313623            0.313299   \n",
       "5              0.444294            0.414965            0.314155   \n",
       "6              0.320775            0.332396            0.403866   \n",
       "7              0.335706            0.384826            0.328067   \n",
       "8              0.342639            0.358113            0.242789   \n",
       "9              0.290162            0.316921            0.307338   \n",
       "10             0.471875            0.482454            0.475231   \n",
       "11             0.457650            0.468287            0.457373   \n",
       "12             0.404583            0.415694            0.404907   \n",
       "13             0.313032            0.313623            0.359815   \n",
       "14             0.313032            0.313623            0.313299   \n",
       "15             0.494722            0.540833            0.503414   \n",
       "16             0.461319            0.425648            0.493414   \n",
       "17             0.400116            0.363588            0.379282   \n",
       "18             0.331343            0.313623            0.317049   \n",
       "19             0.307338            0.257905            0.226354   \n",
       "20             0.490012            0.495694            0.452616   \n",
       "21             0.432847            0.492546            0.436030   \n",
       "22             0.331840            0.379988            0.344583   \n",
       "23             0.317488            0.323981            0.317049   \n",
       "24             0.313032            0.307975            0.317049   \n",
       "25             0.557963            0.568287            0.561806   \n",
       "26             0.508183            0.506192            0.507569   \n",
       "27             0.404583            0.415694            0.404907   \n",
       "28             0.313032            0.313623            0.359815   \n",
       "29             0.313032            0.313623            0.313299   \n",
       "..                  ...                 ...                 ...   \n",
       "75             0.561782            0.558854            0.550787   \n",
       "76             0.380451            0.473229            0.415197   \n",
       "77             0.351308            0.409664            0.370208   \n",
       "78             0.309456            0.358113            0.301806   \n",
       "79             0.287975            0.200602            0.311111   \n",
       "80             0.420278            0.555613            0.518461   \n",
       "81             0.454572            0.447604            0.407650   \n",
       "82             0.342685            0.416181            0.400370   \n",
       "83             0.366806            0.311690            0.317049   \n",
       "84             0.290162            0.313623            0.257431   \n",
       "85             0.559387            0.569329            0.562998   \n",
       "86             0.508183            0.506192            0.507569   \n",
       "87             0.404583            0.415694            0.404907   \n",
       "88             0.313032            0.313623            0.359815   \n",
       "89             0.313032            0.313623            0.313299   \n",
       "90             0.503310            0.525914            0.549479   \n",
       "91             0.478889            0.438287            0.382604   \n",
       "92             0.312593            0.355116            0.396424   \n",
       "93             0.229456            0.363299            0.342477   \n",
       "94             0.227407            0.290255            0.277731   \n",
       "95             0.530220            0.463692            0.513588   \n",
       "96             0.427025            0.390278            0.415926   \n",
       "97             0.370648            0.338148            0.344641   \n",
       "98             0.335706            0.288368            0.355995   \n",
       "99             0.256991            0.301690            0.286065   \n",
       "100            0.559387            0.569329            0.562998   \n",
       "101            0.508183            0.506192            0.507569   \n",
       "102            0.404583            0.415694            0.404907   \n",
       "103            0.313032            0.313623            0.359815   \n",
       "104            0.313032            0.313623            0.313299   \n",
       "\n",
       "     split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0              0.408900            0.446933          0.413498         0.018928  \n",
       "1              0.398993            0.467917          0.420289         0.024896  \n",
       "2              0.387060            0.383762          0.377449         0.032297  \n",
       "3              0.317083            0.313356          0.318722         0.013013  \n",
       "4              0.212384            0.258819          0.272308         0.038050  \n",
       "5              0.462442            0.407870          0.408745         0.051252  \n",
       "6              0.373924            0.434155          0.373023         0.042590  \n",
       "7              0.367755            0.387813          0.360833         0.024724  \n",
       "8              0.367106            0.317488          0.325627         0.044707  \n",
       "9              0.212384            0.258819          0.277125         0.037929  \n",
       "10             0.484016            0.481123          0.478940         0.004616  \n",
       "11             0.466400            0.467257          0.463394         0.004840  \n",
       "12             0.414213            0.415069          0.410894         0.005043  \n",
       "13             0.370220            0.313356          0.334009         0.025532  \n",
       "14             0.313032            0.313356          0.313269         0.000222  \n",
       "15             0.501481            0.497373          0.507565         0.016911  \n",
       "16             0.401366            0.397280          0.435806         0.036724  \n",
       "17             0.412245            0.404363          0.391919         0.017875  \n",
       "18             0.370220            0.362593          0.338965         0.023306  \n",
       "19             0.313032            0.327083          0.286343         0.038001  \n",
       "20             0.437870            0.513507          0.477940         0.028188  \n",
       "21             0.449942            0.475127          0.457299         0.023085  \n",
       "22             0.323843            0.315833          0.339218         0.022489  \n",
       "23             0.362755            0.317488          0.327752         0.017690  \n",
       "24             0.263090            0.311493          0.302528         0.019933  \n",
       "25             0.571817            0.569676          0.565910         0.005191  \n",
       "26             0.504248            0.505116          0.506262         0.001468  \n",
       "27             0.414213            0.415069          0.410894         0.005043  \n",
       "28             0.370220            0.313356          0.334009         0.025532  \n",
       "29             0.313032            0.313356          0.313269         0.000222  \n",
       "..                  ...                 ...               ...              ...  \n",
       "75             0.509352            0.542616          0.544678         0.018884  \n",
       "76             0.431343            0.442002          0.428444         0.030583  \n",
       "77             0.396030            0.363009          0.378044         0.021567  \n",
       "78             0.314653            0.303252          0.317456         0.020840  \n",
       "79             0.212384            0.289317          0.260278         0.044832  \n",
       "80             0.564063            0.557535          0.523190         0.053879  \n",
       "81             0.426030            0.457789          0.438729         0.019080  \n",
       "82             0.368773            0.338854          0.373373         0.030711  \n",
       "83             0.287789            0.245637          0.305794         0.039565  \n",
       "84             0.289792            0.317442          0.293690         0.021466  \n",
       "85             0.572743            0.581215          0.569134         0.007638  \n",
       "86             0.504248            0.505116          0.506262         0.001468  \n",
       "87             0.414213            0.415069          0.410894         0.005043  \n",
       "88             0.370220            0.313356          0.334009         0.025532  \n",
       "89             0.313032            0.313356          0.313269         0.000222  \n",
       "90             0.487431            0.491678          0.511562         0.023193  \n",
       "91             0.468623            0.425197          0.438720         0.034175  \n",
       "92             0.376123            0.375856          0.363222         0.028487  \n",
       "93             0.339502            0.354444          0.325836         0.048938  \n",
       "94             0.277836            0.317488          0.278144         0.029220  \n",
       "95             0.481181            0.514711          0.500678         0.024431  \n",
       "96             0.456887            0.377095          0.413442         0.028056  \n",
       "97             0.328542            0.315995          0.339595         0.018281  \n",
       "98             0.362755            0.266516          0.321868         0.037984  \n",
       "99             0.257546            0.296366          0.279731         0.019017  \n",
       "100            0.572743            0.581215          0.569134         0.007638  \n",
       "101            0.504248            0.505116          0.506262         0.001468  \n",
       "102            0.414213            0.415069          0.410894         0.005043  \n",
       "103            0.370220            0.313356          0.334009         0.025532  \n",
       "104            0.313032            0.313356          0.313269         0.000222  \n",
       "\n",
       "[105 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 420 candidates, totalling 2100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   25.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 15.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2100 out of 2100 | elapsed: 18.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  rfc\n",
      "Best parameters: {'rfc__max_depth': 11, 'rfc__max_features': 'auto', 'rfc__min_samples_split': 0.1, 'rfc__n_estimators': 25}\n",
      "Best score: 0.5728518518518518\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_rfc__max_depth</th>\n",
       "      <th>param_rfc__max_features</th>\n",
       "      <th>param_rfc__min_samples_split</th>\n",
       "      <th>param_rfc__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.171200</td>\n",
       "      <td>0.083672</td>\n",
       "      <td>0.064927</td>\n",
       "      <td>0.008878</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'rfc__max_depth': 3, 'rfc__max_features': 'au...</td>\n",
       "      <td>0.496620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509583</td>\n",
       "      <td>0.020373</td>\n",
       "      <td>83</td>\n",
       "      <td>0.502049</td>\n",
       "      <td>0.500069</td>\n",
       "      <td>0.541400</td>\n",
       "      <td>0.518843</td>\n",
       "      <td>0.489201</td>\n",
       "      <td>0.510313</td>\n",
       "      <td>0.018211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.697184</td>\n",
       "      <td>0.075793</td>\n",
       "      <td>0.116096</td>\n",
       "      <td>0.016702</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>{'rfc__max_depth': 3, 'rfc__max_features': 'au...</td>\n",
       "      <td>0.527917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527000</td>\n",
       "      <td>0.017146</td>\n",
       "      <td>79</td>\n",
       "      <td>0.531076</td>\n",
       "      <td>0.534294</td>\n",
       "      <td>0.540868</td>\n",
       "      <td>0.491331</td>\n",
       "      <td>0.543947</td>\n",
       "      <td>0.528303</td>\n",
       "      <td>0.019043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.336400</td>\n",
       "      <td>0.181875</td>\n",
       "      <td>0.142524</td>\n",
       "      <td>0.025512</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'rfc__max_depth': 3, 'rfc__max_features': 'au...</td>\n",
       "      <td>0.539167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.537741</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>69</td>\n",
       "      <td>0.545197</td>\n",
       "      <td>0.540475</td>\n",
       "      <td>0.534549</td>\n",
       "      <td>0.545602</td>\n",
       "      <td>0.529711</td>\n",
       "      <td>0.539106</td>\n",
       "      <td>0.006168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.814732</td>\n",
       "      <td>0.066674</td>\n",
       "      <td>0.177730</td>\n",
       "      <td>0.008795</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'rfc__max_depth': 3, 'rfc__max_features': 'au...</td>\n",
       "      <td>0.515694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527713</td>\n",
       "      <td>0.013402</td>\n",
       "      <td>78</td>\n",
       "      <td>0.517731</td>\n",
       "      <td>0.538981</td>\n",
       "      <td>0.509213</td>\n",
       "      <td>0.536840</td>\n",
       "      <td>0.540729</td>\n",
       "      <td>0.528699</td>\n",
       "      <td>0.012781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.897203</td>\n",
       "      <td>0.031347</td>\n",
       "      <td>0.076395</td>\n",
       "      <td>0.008732</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>{'rfc__max_depth': 3, 'rfc__max_features': 'au...</td>\n",
       "      <td>0.472870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.461037</td>\n",
       "      <td>0.010641</td>\n",
       "      <td>134</td>\n",
       "      <td>0.472882</td>\n",
       "      <td>0.456620</td>\n",
       "      <td>0.465301</td>\n",
       "      <td>0.441852</td>\n",
       "      <td>0.464259</td>\n",
       "      <td>0.460183</td>\n",
       "      <td>0.010515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.393985</td>\n",
       "      <td>0.139624</td>\n",
       "      <td>0.102827</td>\n",
       "      <td>0.006544</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.2</td>\n",
       "      <td>15</td>\n",
       "      <td>{'rfc__max_depth': 3, 'rfc__max_features': 'au...</td>\n",
       "      <td>0.440324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.461074</td>\n",
       "      <td>0.026648</td>\n",
       "      <td>133</td>\n",
       "      <td>0.442500</td>\n",
       "      <td>0.447512</td>\n",
       "      <td>0.496227</td>\n",
       "      <td>0.432593</td>\n",
       "      <td>0.495845</td>\n",
       "      <td>0.462935</td>\n",
       "      <td>0.027450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.976421</td>\n",
       "      <td>0.077330</td>\n",
       "      <td>0.126860</td>\n",
       "      <td>0.017187</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.2</td>\n",
       "      <td>20</td>\n",
       "      <td>{'rfc__max_depth': 3, 'rfc__max_features': 'au...</td>\n",
       "      <td>0.462407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463981</td>\n",
       "      <td>0.019041</td>\n",
       "      <td>130</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.471412</td>\n",
       "      <td>0.481227</td>\n",
       "      <td>0.473750</td>\n",
       "      <td>0.427789</td>\n",
       "      <td>0.464169</td>\n",
       "      <td>0.018788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.241251</td>\n",
       "      <td>0.070342</td>\n",
       "      <td>0.168548</td>\n",
       "      <td>0.020892</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.2</td>\n",
       "      <td>25</td>\n",
       "      <td>{'rfc__max_depth': 3, 'rfc__max_features': 'au...</td>\n",
       "      <td>0.467593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.462981</td>\n",
       "      <td>0.021387</td>\n",
       "      <td>131</td>\n",
       "      <td>0.469757</td>\n",
       "      <td>0.505833</td>\n",
       "      <td>0.441019</td>\n",
       "      <td>0.457141</td>\n",
       "      <td>0.447743</td>\n",
       "      <td>0.464299</td>\n",
       "      <td>0.022901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.810837</td>\n",
       "      <td>0.066474</td>\n",
       "      <td>0.068320</td>\n",
       "      <td>0.017075</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'rfc__max_depth': 3, 'rfc__max_features': 'au...</td>\n",
       "      <td>0.413889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.423231</td>\n",
       "      <td>0.022121</td>\n",
       "      <td>146</td>\n",
       "      <td>0.414676</td>\n",
       "      <td>0.431458</td>\n",
       "      <td>0.383495</td>\n",
       "      <td>0.442095</td>\n",
       "      <td>0.447292</td>\n",
       "      <td>0.423803</td>\n",
       "      <td>0.023034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.009927</td>\n",
       "      <td>0.018288</td>\n",
       "      <td>0.080985</td>\n",
       "      <td>0.010122</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15</td>\n",
       "      <td>{'rfc__max_depth': 3, 'rfc__max_features': 'au...</td>\n",
       "      <td>0.401806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408444</td>\n",
       "      <td>0.010719</td>\n",
       "      <td>239</td>\n",
       "      <td>0.403484</td>\n",
       "      <td>0.401007</td>\n",
       "      <td>0.399792</td>\n",
       "      <td>0.420116</td>\n",
       "      <td>0.425498</td>\n",
       "      <td>0.409979</td>\n",
       "      <td>0.010678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.330076</td>\n",
       "      <td>0.051085</td>\n",
       "      <td>0.123675</td>\n",
       "      <td>0.005504</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20</td>\n",
       "      <td>{'rfc__max_depth': 3, 'rfc__max_features': 'au...</td>\n",
       "      <td>0.429167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417565</td>\n",
       "      <td>0.007101</td>\n",
       "      <td>170</td>\n",
       "      <td>0.429167</td>\n",
       "      <td>0.420729</td>\n",
       "      <td>0.415382</td>\n",
       "      <td>0.412674</td>\n",
       "      <td>0.409340</td>\n",
       "      <td>0.417458</td>\n",
       "      <td>0.006941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.695285</td>\n",
       "      <td>0.082647</td>\n",
       "      <td>0.147406</td>\n",
       "      <td>0.006657</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.3</td>\n",
       "      <td>25</td>\n",
       "      <td>{'rfc__max_depth': 3, 'rfc__max_features': 'au...</td>\n",
       "      <td>0.412315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.420648</td>\n",
       "      <td>0.005686</td>\n",
       "      <td>154</td>\n",
       "      <td>0.414282</td>\n",
       "      <td>0.419653</td>\n",
       "      <td>0.422963</td>\n",
       "      <td>0.413588</td>\n",
       "      <td>0.433565</td>\n",
       "      <td>0.420810</td>\n",
       "      <td>0.007258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.612190</td>\n",
       "      <td>0.018055</td>\n",
       "      <td>0.066023</td>\n",
       "      <td>0.006383</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10</td>\n",
       "      <td>{'rfc__max_depth': 3, 'rfc__max_features': 'au...</td>\n",
       "      <td>0.422593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407259</td>\n",
       "      <td>0.015336</td>\n",
       "      <td>244</td>\n",
       "      <td>0.424329</td>\n",
       "      <td>0.421273</td>\n",
       "      <td>0.408194</td>\n",
       "      <td>0.399757</td>\n",
       "      <td>0.385197</td>\n",
       "      <td>0.407750</td>\n",
       "      <td>0.014356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.881780</td>\n",
       "      <td>0.033822</td>\n",
       "      <td>0.087977</td>\n",
       "      <td>0.011058</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "      <td>{'rfc__max_depth': 3, 'rfc__max_features': 'au...</td>\n",
       "      <td>0.423426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.424269</td>\n",
       "      <td>0.009492</td>\n",
       "      <td>144</td>\n",
       "      <td>0.423472</td>\n",
       "      <td>0.422546</td>\n",
       "      <td>0.438032</td>\n",
       "      <td>0.423681</td>\n",
       "      <td>0.408924</td>\n",
       "      <td>0.423331</td>\n",
       "      <td>0.009214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.230547</td>\n",
       "      <td>0.051988</td>\n",
       "      <td>0.115496</td>\n",
       "      <td>0.005609</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.4</td>\n",
       "      <td>20</td>\n",
       "      <td>{'rfc__max_depth': 3, 'rfc__max_features': 'au...</td>\n",
       "      <td>0.409722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404426</td>\n",
       "      <td>0.009232</td>\n",
       "      <td>250</td>\n",
       "      <td>0.409850</td>\n",
       "      <td>0.398715</td>\n",
       "      <td>0.414039</td>\n",
       "      <td>0.407500</td>\n",
       "      <td>0.390937</td>\n",
       "      <td>0.404208</td>\n",
       "      <td>0.008314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.469904</td>\n",
       "      <td>0.095830</td>\n",
       "      <td>0.140527</td>\n",
       "      <td>0.007923</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.4</td>\n",
       "      <td>25</td>\n",
       "      <td>{'rfc__max_depth': 3, 'rfc__max_features': 'au...</td>\n",
       "      <td>0.410602</td>\n",
       "      <td>...</td>\n",
       "      <td>0.416259</td>\n",
       "      <td>0.004308</td>\n",
       "      <td>183</td>\n",
       "      <td>0.412431</td>\n",
       "      <td>0.423634</td>\n",
       "      <td>0.411736</td>\n",
       "      <td>0.416840</td>\n",
       "      <td>0.421887</td>\n",
       "      <td>0.417306</td>\n",
       "      <td>0.004817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.513544</td>\n",
       "      <td>0.018622</td>\n",
       "      <td>0.055154</td>\n",
       "      <td>0.007149</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'rfc__max_depth': 3, 'rfc__max_features': 'au...</td>\n",
       "      <td>0.366806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347769</td>\n",
       "      <td>0.025205</td>\n",
       "      <td>320</td>\n",
       "      <td>0.365984</td>\n",
       "      <td>0.352002</td>\n",
       "      <td>0.300752</td>\n",
       "      <td>0.346817</td>\n",
       "      <td>0.376447</td>\n",
       "      <td>0.348400</td>\n",
       "      <td>0.026006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.726582</td>\n",
       "      <td>0.015258</td>\n",
       "      <td>0.081780</td>\n",
       "      <td>0.008742</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15</td>\n",
       "      <td>{'rfc__max_depth': 3, 'rfc__max_features': 'au...</td>\n",
       "      <td>0.341435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366537</td>\n",
       "      <td>0.015316</td>\n",
       "      <td>288</td>\n",
       "      <td>0.340926</td>\n",
       "      <td>0.363958</td>\n",
       "      <td>0.372002</td>\n",
       "      <td>0.387292</td>\n",
       "      <td>0.368287</td>\n",
       "      <td>0.366493</td>\n",
       "      <td>0.015008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.980989</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>0.113097</td>\n",
       "      <td>0.013196</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.5</td>\n",
       "      <td>20</td>\n",
       "      <td>{'rfc__max_depth': 3, 'rfc__max_features': 'au...</td>\n",
       "      <td>0.339120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.357361</td>\n",
       "      <td>0.016124</td>\n",
       "      <td>303</td>\n",
       "      <td>0.337882</td>\n",
       "      <td>0.349641</td>\n",
       "      <td>0.349259</td>\n",
       "      <td>0.385579</td>\n",
       "      <td>0.364606</td>\n",
       "      <td>0.357394</td>\n",
       "      <td>0.016452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.373334</td>\n",
       "      <td>0.116570</td>\n",
       "      <td>0.176829</td>\n",
       "      <td>0.054951</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.5</td>\n",
       "      <td>25</td>\n",
       "      <td>{'rfc__max_depth': 3, 'rfc__max_features': 'au...</td>\n",
       "      <td>0.378102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.364417</td>\n",
       "      <td>0.009334</td>\n",
       "      <td>293</td>\n",
       "      <td>0.375139</td>\n",
       "      <td>0.358079</td>\n",
       "      <td>0.370012</td>\n",
       "      <td>0.352604</td>\n",
       "      <td>0.364271</td>\n",
       "      <td>0.364021</td>\n",
       "      <td>0.008065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.896522</td>\n",
       "      <td>0.049427</td>\n",
       "      <td>0.059546</td>\n",
       "      <td>0.008393</td>\n",
       "      <td>3</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'rfc__max_depth': 3, 'rfc__max_features': 'lo...</td>\n",
       "      <td>0.529676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534611</td>\n",
       "      <td>0.012022</td>\n",
       "      <td>74</td>\n",
       "      <td>0.533495</td>\n",
       "      <td>0.525903</td>\n",
       "      <td>0.555706</td>\n",
       "      <td>0.523044</td>\n",
       "      <td>0.534051</td>\n",
       "      <td>0.534440</td>\n",
       "      <td>0.011455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.175584</td>\n",
       "      <td>0.051405</td>\n",
       "      <td>0.076100</td>\n",
       "      <td>0.006571</td>\n",
       "      <td>3</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>{'rfc__max_depth': 3, 'rfc__max_features': 'lo...</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.532287</td>\n",
       "      <td>0.008163</td>\n",
       "      <td>77</td>\n",
       "      <td>0.547361</td>\n",
       "      <td>0.529225</td>\n",
       "      <td>0.523438</td>\n",
       "      <td>0.525509</td>\n",
       "      <td>0.542836</td>\n",
       "      <td>0.533674</td>\n",
       "      <td>0.009618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.673537</td>\n",
       "      <td>0.134226</td>\n",
       "      <td>0.118881</td>\n",
       "      <td>0.019528</td>\n",
       "      <td>3</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'rfc__max_depth': 3, 'rfc__max_features': 'lo...</td>\n",
       "      <td>0.532778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534250</td>\n",
       "      <td>0.012534</td>\n",
       "      <td>75</td>\n",
       "      <td>0.535810</td>\n",
       "      <td>0.514213</td>\n",
       "      <td>0.534109</td>\n",
       "      <td>0.542963</td>\n",
       "      <td>0.540046</td>\n",
       "      <td>0.533428</td>\n",
       "      <td>0.010100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.149427</td>\n",
       "      <td>0.145288</td>\n",
       "      <td>0.162578</td>\n",
       "      <td>0.055694</td>\n",
       "      <td>3</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'rfc__max_depth': 3, 'rfc__max_features': 'lo...</td>\n",
       "      <td>0.534769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533148</td>\n",
       "      <td>0.012363</td>\n",
       "      <td>76</td>\n",
       "      <td>0.539954</td>\n",
       "      <td>0.514132</td>\n",
       "      <td>0.544271</td>\n",
       "      <td>0.534190</td>\n",
       "      <td>0.538414</td>\n",
       "      <td>0.534192</td>\n",
       "      <td>0.010536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.880268</td>\n",
       "      <td>0.174455</td>\n",
       "      <td>0.069620</td>\n",
       "      <td>0.010159</td>\n",
       "      <td>3</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>{'rfc__max_depth': 3, 'rfc__max_features': 'lo...</td>\n",
       "      <td>0.494630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467954</td>\n",
       "      <td>0.020177</td>\n",
       "      <td>116</td>\n",
       "      <td>0.495972</td>\n",
       "      <td>0.493472</td>\n",
       "      <td>0.446424</td>\n",
       "      <td>0.459062</td>\n",
       "      <td>0.453553</td>\n",
       "      <td>0.469697</td>\n",
       "      <td>0.020838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.469406</td>\n",
       "      <td>0.103968</td>\n",
       "      <td>0.105318</td>\n",
       "      <td>0.008888</td>\n",
       "      <td>3</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>15</td>\n",
       "      <td>{'rfc__max_depth': 3, 'rfc__max_features': 'lo...</td>\n",
       "      <td>0.487593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464898</td>\n",
       "      <td>0.014718</td>\n",
       "      <td>127</td>\n",
       "      <td>0.487928</td>\n",
       "      <td>0.475336</td>\n",
       "      <td>0.446238</td>\n",
       "      <td>0.468600</td>\n",
       "      <td>0.447465</td>\n",
       "      <td>0.465113</td>\n",
       "      <td>0.016155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.457726</td>\n",
       "      <td>0.042955</td>\n",
       "      <td>0.101729</td>\n",
       "      <td>0.004805</td>\n",
       "      <td>3</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>20</td>\n",
       "      <td>{'rfc__max_depth': 3, 'rfc__max_features': 'lo...</td>\n",
       "      <td>0.445370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454769</td>\n",
       "      <td>0.013775</td>\n",
       "      <td>138</td>\n",
       "      <td>0.446713</td>\n",
       "      <td>0.484352</td>\n",
       "      <td>0.454884</td>\n",
       "      <td>0.437454</td>\n",
       "      <td>0.460104</td>\n",
       "      <td>0.456701</td>\n",
       "      <td>0.015809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.115598</td>\n",
       "      <td>0.086269</td>\n",
       "      <td>0.183613</td>\n",
       "      <td>0.031312</td>\n",
       "      <td>3</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>25</td>\n",
       "      <td>{'rfc__max_depth': 3, 'rfc__max_features': 'lo...</td>\n",
       "      <td>0.497315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.480417</td>\n",
       "      <td>0.011187</td>\n",
       "      <td>93</td>\n",
       "      <td>0.497442</td>\n",
       "      <td>0.471771</td>\n",
       "      <td>0.482789</td>\n",
       "      <td>0.482593</td>\n",
       "      <td>0.472500</td>\n",
       "      <td>0.481419</td>\n",
       "      <td>0.009302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.738953</td>\n",
       "      <td>0.085800</td>\n",
       "      <td>0.064826</td>\n",
       "      <td>0.022346</td>\n",
       "      <td>3</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'rfc__max_depth': 3, 'rfc__max_features': 'lo...</td>\n",
       "      <td>0.420648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418352</td>\n",
       "      <td>0.015553</td>\n",
       "      <td>168</td>\n",
       "      <td>0.420463</td>\n",
       "      <td>0.393738</td>\n",
       "      <td>0.431042</td>\n",
       "      <td>0.406586</td>\n",
       "      <td>0.442917</td>\n",
       "      <td>0.418949</td>\n",
       "      <td>0.017386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.930894</td>\n",
       "      <td>0.085558</td>\n",
       "      <td>0.087365</td>\n",
       "      <td>0.018750</td>\n",
       "      <td>3</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15</td>\n",
       "      <td>{'rfc__max_depth': 3, 'rfc__max_features': 'lo...</td>\n",
       "      <td>0.437315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418352</td>\n",
       "      <td>0.017783</td>\n",
       "      <td>168</td>\n",
       "      <td>0.440810</td>\n",
       "      <td>0.423958</td>\n",
       "      <td>0.380961</td>\n",
       "      <td>0.423102</td>\n",
       "      <td>0.421447</td>\n",
       "      <td>0.418056</td>\n",
       "      <td>0.019827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1.245354</td>\n",
       "      <td>0.046297</td>\n",
       "      <td>0.105366</td>\n",
       "      <td>0.007916</td>\n",
       "      <td>15</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20</td>\n",
       "      <td>{'rfc__max_depth': 15, 'rfc__max_features': 'l...</td>\n",
       "      <td>0.409676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415815</td>\n",
       "      <td>0.005117</td>\n",
       "      <td>188</td>\n",
       "      <td>0.410625</td>\n",
       "      <td>0.415833</td>\n",
       "      <td>0.422164</td>\n",
       "      <td>0.408681</td>\n",
       "      <td>0.418912</td>\n",
       "      <td>0.415243</td>\n",
       "      <td>0.005022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1.573724</td>\n",
       "      <td>0.067553</td>\n",
       "      <td>0.147978</td>\n",
       "      <td>0.019636</td>\n",
       "      <td>15</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>25</td>\n",
       "      <td>{'rfc__max_depth': 15, 'rfc__max_features': 'l...</td>\n",
       "      <td>0.418194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.421602</td>\n",
       "      <td>0.010382</td>\n",
       "      <td>150</td>\n",
       "      <td>0.419687</td>\n",
       "      <td>0.419815</td>\n",
       "      <td>0.438715</td>\n",
       "      <td>0.408079</td>\n",
       "      <td>0.419375</td>\n",
       "      <td>0.421134</td>\n",
       "      <td>0.009864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>0.636214</td>\n",
       "      <td>0.029730</td>\n",
       "      <td>0.069429</td>\n",
       "      <td>0.008942</td>\n",
       "      <td>15</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10</td>\n",
       "      <td>{'rfc__max_depth': 15, 'rfc__max_features': 'l...</td>\n",
       "      <td>0.389074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408574</td>\n",
       "      <td>0.010843</td>\n",
       "      <td>237</td>\n",
       "      <td>0.390336</td>\n",
       "      <td>0.420556</td>\n",
       "      <td>0.407095</td>\n",
       "      <td>0.409178</td>\n",
       "      <td>0.416227</td>\n",
       "      <td>0.408678</td>\n",
       "      <td>0.010366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0.980238</td>\n",
       "      <td>0.037955</td>\n",
       "      <td>0.093364</td>\n",
       "      <td>0.010070</td>\n",
       "      <td>15</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "      <td>{'rfc__max_depth': 15, 'rfc__max_features': 'l...</td>\n",
       "      <td>0.410602</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412426</td>\n",
       "      <td>0.007112</td>\n",
       "      <td>214</td>\n",
       "      <td>0.412002</td>\n",
       "      <td>0.423600</td>\n",
       "      <td>0.404815</td>\n",
       "      <td>0.402257</td>\n",
       "      <td>0.422963</td>\n",
       "      <td>0.413127</td>\n",
       "      <td>0.008887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>1.353571</td>\n",
       "      <td>0.011588</td>\n",
       "      <td>0.118028</td>\n",
       "      <td>0.020102</td>\n",
       "      <td>15</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>20</td>\n",
       "      <td>{'rfc__max_depth': 15, 'rfc__max_features': 'l...</td>\n",
       "      <td>0.418194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.420296</td>\n",
       "      <td>0.003741</td>\n",
       "      <td>156</td>\n",
       "      <td>0.420567</td>\n",
       "      <td>0.415752</td>\n",
       "      <td>0.420845</td>\n",
       "      <td>0.420648</td>\n",
       "      <td>0.424456</td>\n",
       "      <td>0.420454</td>\n",
       "      <td>0.002769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1.559414</td>\n",
       "      <td>0.098074</td>\n",
       "      <td>0.161193</td>\n",
       "      <td>0.014565</td>\n",
       "      <td>15</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>25</td>\n",
       "      <td>{'rfc__max_depth': 15, 'rfc__max_features': 'l...</td>\n",
       "      <td>0.411343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399880</td>\n",
       "      <td>0.012469</td>\n",
       "      <td>262</td>\n",
       "      <td>0.412072</td>\n",
       "      <td>0.402350</td>\n",
       "      <td>0.397975</td>\n",
       "      <td>0.375486</td>\n",
       "      <td>0.410764</td>\n",
       "      <td>0.399729</td>\n",
       "      <td>0.013204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.572209</td>\n",
       "      <td>0.023835</td>\n",
       "      <td>0.062084</td>\n",
       "      <td>0.012953</td>\n",
       "      <td>15</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'rfc__max_depth': 15, 'rfc__max_features': 'l...</td>\n",
       "      <td>0.320278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.369398</td>\n",
       "      <td>0.025183</td>\n",
       "      <td>285</td>\n",
       "      <td>0.320741</td>\n",
       "      <td>0.378750</td>\n",
       "      <td>0.386100</td>\n",
       "      <td>0.386250</td>\n",
       "      <td>0.377708</td>\n",
       "      <td>0.369910</td>\n",
       "      <td>0.024842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.779478</td>\n",
       "      <td>0.031127</td>\n",
       "      <td>0.090448</td>\n",
       "      <td>0.010191</td>\n",
       "      <td>15</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15</td>\n",
       "      <td>{'rfc__max_depth': 15, 'rfc__max_features': 'l...</td>\n",
       "      <td>0.361204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345741</td>\n",
       "      <td>0.026880</td>\n",
       "      <td>322</td>\n",
       "      <td>0.358634</td>\n",
       "      <td>0.376852</td>\n",
       "      <td>0.339687</td>\n",
       "      <td>0.296551</td>\n",
       "      <td>0.356424</td>\n",
       "      <td>0.345630</td>\n",
       "      <td>0.027219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.888547</td>\n",
       "      <td>0.060148</td>\n",
       "      <td>0.094676</td>\n",
       "      <td>0.010069</td>\n",
       "      <td>15</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>20</td>\n",
       "      <td>{'rfc__max_depth': 15, 'rfc__max_features': 'l...</td>\n",
       "      <td>0.381528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.362333</td>\n",
       "      <td>0.016151</td>\n",
       "      <td>296</td>\n",
       "      <td>0.378935</td>\n",
       "      <td>0.353009</td>\n",
       "      <td>0.352361</td>\n",
       "      <td>0.345394</td>\n",
       "      <td>0.388287</td>\n",
       "      <td>0.363597</td>\n",
       "      <td>0.016820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1.038354</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.123657</td>\n",
       "      <td>0.010121</td>\n",
       "      <td>15</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>25</td>\n",
       "      <td>{'rfc__max_depth': 15, 'rfc__max_features': 'l...</td>\n",
       "      <td>0.302778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341769</td>\n",
       "      <td>0.029053</td>\n",
       "      <td>328</td>\n",
       "      <td>0.301308</td>\n",
       "      <td>0.355046</td>\n",
       "      <td>0.360613</td>\n",
       "      <td>0.309225</td>\n",
       "      <td>0.384884</td>\n",
       "      <td>0.342215</td>\n",
       "      <td>0.031892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>1.956204</td>\n",
       "      <td>0.043059</td>\n",
       "      <td>0.049036</td>\n",
       "      <td>0.004177</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'rfc__max_depth': 15, 'rfc__max_features': No...</td>\n",
       "      <td>0.523981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.536815</td>\n",
       "      <td>0.010649</td>\n",
       "      <td>72</td>\n",
       "      <td>0.529363</td>\n",
       "      <td>0.545046</td>\n",
       "      <td>0.526169</td>\n",
       "      <td>0.543160</td>\n",
       "      <td>0.544294</td>\n",
       "      <td>0.537606</td>\n",
       "      <td>0.008120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>2.860524</td>\n",
       "      <td>0.078749</td>\n",
       "      <td>0.071356</td>\n",
       "      <td>0.003576</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>{'rfc__max_depth': 15, 'rfc__max_features': No...</td>\n",
       "      <td>0.538056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538852</td>\n",
       "      <td>0.007866</td>\n",
       "      <td>67</td>\n",
       "      <td>0.542755</td>\n",
       "      <td>0.544780</td>\n",
       "      <td>0.526030</td>\n",
       "      <td>0.543067</td>\n",
       "      <td>0.544201</td>\n",
       "      <td>0.540167</td>\n",
       "      <td>0.007107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>4.396005</td>\n",
       "      <td>0.288353</td>\n",
       "      <td>0.111052</td>\n",
       "      <td>0.005982</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'rfc__max_depth': 15, 'rfc__max_features': No...</td>\n",
       "      <td>0.537361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.542907</td>\n",
       "      <td>0.010025</td>\n",
       "      <td>63</td>\n",
       "      <td>0.542407</td>\n",
       "      <td>0.545104</td>\n",
       "      <td>0.529410</td>\n",
       "      <td>0.543391</td>\n",
       "      <td>0.557234</td>\n",
       "      <td>0.543509</td>\n",
       "      <td>0.008842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>6.344413</td>\n",
       "      <td>0.105236</td>\n",
       "      <td>0.164120</td>\n",
       "      <td>0.019209</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'rfc__max_depth': 15, 'rfc__max_features': No...</td>\n",
       "      <td>0.537083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545667</td>\n",
       "      <td>0.006868</td>\n",
       "      <td>55</td>\n",
       "      <td>0.541771</td>\n",
       "      <td>0.544780</td>\n",
       "      <td>0.545081</td>\n",
       "      <td>0.543669</td>\n",
       "      <td>0.557234</td>\n",
       "      <td>0.546507</td>\n",
       "      <td>0.005488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>1.774058</td>\n",
       "      <td>0.172665</td>\n",
       "      <td>0.073204</td>\n",
       "      <td>0.015395</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>{'rfc__max_depth': 15, 'rfc__max_features': No...</td>\n",
       "      <td>0.406991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400602</td>\n",
       "      <td>0.015971</td>\n",
       "      <td>261</td>\n",
       "      <td>0.408819</td>\n",
       "      <td>0.370556</td>\n",
       "      <td>0.408345</td>\n",
       "      <td>0.408206</td>\n",
       "      <td>0.408449</td>\n",
       "      <td>0.400875</td>\n",
       "      <td>0.015161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>2.984823</td>\n",
       "      <td>0.050499</td>\n",
       "      <td>0.112300</td>\n",
       "      <td>0.013195</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>0.2</td>\n",
       "      <td>15</td>\n",
       "      <td>{'rfc__max_depth': 15, 'rfc__max_features': No...</td>\n",
       "      <td>0.407685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393102</td>\n",
       "      <td>0.019108</td>\n",
       "      <td>268</td>\n",
       "      <td>0.410613</td>\n",
       "      <td>0.370741</td>\n",
       "      <td>0.408345</td>\n",
       "      <td>0.408380</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.393690</td>\n",
       "      <td>0.018907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>3.620925</td>\n",
       "      <td>0.079126</td>\n",
       "      <td>0.135835</td>\n",
       "      <td>0.016209</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>0.2</td>\n",
       "      <td>20</td>\n",
       "      <td>{'rfc__max_depth': 15, 'rfc__max_features': No...</td>\n",
       "      <td>0.406991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.409611</td>\n",
       "      <td>0.026639</td>\n",
       "      <td>229</td>\n",
       "      <td>0.408819</td>\n",
       "      <td>0.370556</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.408229</td>\n",
       "      <td>0.453160</td>\n",
       "      <td>0.410153</td>\n",
       "      <td>0.026165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>4.521915</td>\n",
       "      <td>0.225494</td>\n",
       "      <td>0.152791</td>\n",
       "      <td>0.029949</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>0.2</td>\n",
       "      <td>25</td>\n",
       "      <td>{'rfc__max_depth': 15, 'rfc__max_features': No...</td>\n",
       "      <td>0.407685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408880</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>235</td>\n",
       "      <td>0.410625</td>\n",
       "      <td>0.408553</td>\n",
       "      <td>0.410012</td>\n",
       "      <td>0.408356</td>\n",
       "      <td>0.408310</td>\n",
       "      <td>0.409171</td>\n",
       "      <td>0.000960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>1.359964</td>\n",
       "      <td>0.059394</td>\n",
       "      <td>0.059841</td>\n",
       "      <td>0.007853</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'rfc__max_depth': 15, 'rfc__max_features': No...</td>\n",
       "      <td>0.313981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313213</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>359</td>\n",
       "      <td>0.312975</td>\n",
       "      <td>0.313623</td>\n",
       "      <td>0.313287</td>\n",
       "      <td>0.313032</td>\n",
       "      <td>0.313345</td>\n",
       "      <td>0.313252</td>\n",
       "      <td>0.000233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>1.886158</td>\n",
       "      <td>0.063425</td>\n",
       "      <td>0.087764</td>\n",
       "      <td>0.011405</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15</td>\n",
       "      <td>{'rfc__max_depth': 15, 'rfc__max_features': No...</td>\n",
       "      <td>0.314028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313213</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>359</td>\n",
       "      <td>0.313009</td>\n",
       "      <td>0.313623</td>\n",
       "      <td>0.313287</td>\n",
       "      <td>0.313021</td>\n",
       "      <td>0.313322</td>\n",
       "      <td>0.313252</td>\n",
       "      <td>0.000226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>2.099187</td>\n",
       "      <td>0.034883</td>\n",
       "      <td>0.105518</td>\n",
       "      <td>0.024433</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20</td>\n",
       "      <td>{'rfc__max_depth': 15, 'rfc__max_features': No...</td>\n",
       "      <td>0.314213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313296</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>337</td>\n",
       "      <td>0.313032</td>\n",
       "      <td>0.313600</td>\n",
       "      <td>0.313461</td>\n",
       "      <td>0.313032</td>\n",
       "      <td>0.313356</td>\n",
       "      <td>0.313296</td>\n",
       "      <td>0.000229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>3.045061</td>\n",
       "      <td>0.317872</td>\n",
       "      <td>0.162766</td>\n",
       "      <td>0.022098</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>25</td>\n",
       "      <td>{'rfc__max_depth': 15, 'rfc__max_features': No...</td>\n",
       "      <td>0.313981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313213</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>359</td>\n",
       "      <td>0.312986</td>\n",
       "      <td>0.313623</td>\n",
       "      <td>0.313287</td>\n",
       "      <td>0.313032</td>\n",
       "      <td>0.313345</td>\n",
       "      <td>0.313255</td>\n",
       "      <td>0.000231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>1.612291</td>\n",
       "      <td>0.177478</td>\n",
       "      <td>0.065625</td>\n",
       "      <td>0.019146</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10</td>\n",
       "      <td>{'rfc__max_depth': 15, 'rfc__max_features': No...</td>\n",
       "      <td>0.313981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313185</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>391</td>\n",
       "      <td>0.312986</td>\n",
       "      <td>0.313623</td>\n",
       "      <td>0.313218</td>\n",
       "      <td>0.313021</td>\n",
       "      <td>0.313356</td>\n",
       "      <td>0.313241</td>\n",
       "      <td>0.000234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>2.007234</td>\n",
       "      <td>0.088330</td>\n",
       "      <td>0.078590</td>\n",
       "      <td>0.007394</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "      <td>{'rfc__max_depth': 15, 'rfc__max_features': No...</td>\n",
       "      <td>0.314028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313213</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>359</td>\n",
       "      <td>0.313021</td>\n",
       "      <td>0.313623</td>\n",
       "      <td>0.313287</td>\n",
       "      <td>0.313021</td>\n",
       "      <td>0.313356</td>\n",
       "      <td>0.313262</td>\n",
       "      <td>0.000226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>2.323388</td>\n",
       "      <td>0.096593</td>\n",
       "      <td>0.131648</td>\n",
       "      <td>0.036492</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4</td>\n",
       "      <td>20</td>\n",
       "      <td>{'rfc__max_depth': 15, 'rfc__max_features': No...</td>\n",
       "      <td>0.313981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313213</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>359</td>\n",
       "      <td>0.312986</td>\n",
       "      <td>0.313623</td>\n",
       "      <td>0.313299</td>\n",
       "      <td>0.313021</td>\n",
       "      <td>0.313322</td>\n",
       "      <td>0.313250</td>\n",
       "      <td>0.000232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>2.863746</td>\n",
       "      <td>0.326015</td>\n",
       "      <td>0.108908</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4</td>\n",
       "      <td>25</td>\n",
       "      <td>{'rfc__max_depth': 15, 'rfc__max_features': No...</td>\n",
       "      <td>0.314213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313250</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>342</td>\n",
       "      <td>0.313032</td>\n",
       "      <td>0.313623</td>\n",
       "      <td>0.313264</td>\n",
       "      <td>0.313009</td>\n",
       "      <td>0.313356</td>\n",
       "      <td>0.313257</td>\n",
       "      <td>0.000226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>0.695142</td>\n",
       "      <td>0.006765</td>\n",
       "      <td>0.045480</td>\n",
       "      <td>0.001622</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'rfc__max_depth': 15, 'rfc__max_features': No...</td>\n",
       "      <td>0.217963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217769</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>393</td>\n",
       "      <td>0.217720</td>\n",
       "      <td>0.217940</td>\n",
       "      <td>0.217616</td>\n",
       "      <td>0.217627</td>\n",
       "      <td>0.217940</td>\n",
       "      <td>0.217769</td>\n",
       "      <td>0.000144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1.286961</td>\n",
       "      <td>0.038350</td>\n",
       "      <td>0.085571</td>\n",
       "      <td>0.005329</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15</td>\n",
       "      <td>{'rfc__max_depth': 15, 'rfc__max_features': No...</td>\n",
       "      <td>0.217963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217769</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>393</td>\n",
       "      <td>0.217720</td>\n",
       "      <td>0.217940</td>\n",
       "      <td>0.217616</td>\n",
       "      <td>0.217627</td>\n",
       "      <td>0.217940</td>\n",
       "      <td>0.217769</td>\n",
       "      <td>0.000144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>1.576188</td>\n",
       "      <td>0.030077</td>\n",
       "      <td>0.106715</td>\n",
       "      <td>0.014175</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>20</td>\n",
       "      <td>{'rfc__max_depth': 15, 'rfc__max_features': No...</td>\n",
       "      <td>0.217963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217769</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>393</td>\n",
       "      <td>0.217720</td>\n",
       "      <td>0.217940</td>\n",
       "      <td>0.217616</td>\n",
       "      <td>0.217627</td>\n",
       "      <td>0.217940</td>\n",
       "      <td>0.217769</td>\n",
       "      <td>0.000144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>1.878180</td>\n",
       "      <td>0.073264</td>\n",
       "      <td>0.113496</td>\n",
       "      <td>0.008112</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>25</td>\n",
       "      <td>{'rfc__max_depth': 15, 'rfc__max_features': No...</td>\n",
       "      <td>0.217963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217769</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>393</td>\n",
       "      <td>0.217720</td>\n",
       "      <td>0.217940</td>\n",
       "      <td>0.217616</td>\n",
       "      <td>0.217627</td>\n",
       "      <td>0.217940</td>\n",
       "      <td>0.217769</td>\n",
       "      <td>0.000144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         1.171200      0.083672         0.064927        0.008878   \n",
       "1         1.697184      0.075793         0.116096        0.016702   \n",
       "2         2.336400      0.181875         0.142524        0.025512   \n",
       "3         2.814732      0.066674         0.177730        0.008795   \n",
       "4         0.897203      0.031347         0.076395        0.008732   \n",
       "5         1.393985      0.139624         0.102827        0.006544   \n",
       "6         1.976421      0.077330         0.126860        0.017187   \n",
       "7         2.241251      0.070342         0.168548        0.020892   \n",
       "8         0.810837      0.066474         0.068320        0.017075   \n",
       "9         1.009927      0.018288         0.080985        0.010122   \n",
       "10        1.330076      0.051085         0.123675        0.005504   \n",
       "11        1.695285      0.082647         0.147406        0.006657   \n",
       "12        0.612190      0.018055         0.066023        0.006383   \n",
       "13        0.881780      0.033822         0.087977        0.011058   \n",
       "14        1.230547      0.051988         0.115496        0.005609   \n",
       "15        1.469904      0.095830         0.140527        0.007923   \n",
       "16        0.513544      0.018622         0.055154        0.007149   \n",
       "17        0.726582      0.015258         0.081780        0.008742   \n",
       "18        0.980989      0.003096         0.113097        0.013196   \n",
       "19        1.373334      0.116570         0.176829        0.054951   \n",
       "20        0.896522      0.049427         0.059546        0.008393   \n",
       "21        1.175584      0.051405         0.076100        0.006571   \n",
       "22        1.673537      0.134226         0.118881        0.019528   \n",
       "23        2.149427      0.145288         0.162578        0.055694   \n",
       "24        0.880268      0.174455         0.069620        0.010159   \n",
       "25        1.469406      0.103968         0.105318        0.008888   \n",
       "26        1.457726      0.042955         0.101729        0.004805   \n",
       "27        2.115598      0.086269         0.183613        0.031312   \n",
       "28        0.738953      0.085800         0.064826        0.022346   \n",
       "29        0.930894      0.085558         0.087365        0.018750   \n",
       "..             ...           ...              ...             ...   \n",
       "390       1.245354      0.046297         0.105366        0.007916   \n",
       "391       1.573724      0.067553         0.147978        0.019636   \n",
       "392       0.636214      0.029730         0.069429        0.008942   \n",
       "393       0.980238      0.037955         0.093364        0.010070   \n",
       "394       1.353571      0.011588         0.118028        0.020102   \n",
       "395       1.559414      0.098074         0.161193        0.014565   \n",
       "396       0.572209      0.023835         0.062084        0.012953   \n",
       "397       0.779478      0.031127         0.090448        0.010191   \n",
       "398       0.888547      0.060148         0.094676        0.010069   \n",
       "399       1.038354      0.025000         0.123657        0.010121   \n",
       "400       1.956204      0.043059         0.049036        0.004177   \n",
       "401       2.860524      0.078749         0.071356        0.003576   \n",
       "402       4.396005      0.288353         0.111052        0.005982   \n",
       "403       6.344413      0.105236         0.164120        0.019209   \n",
       "404       1.774058      0.172665         0.073204        0.015395   \n",
       "405       2.984823      0.050499         0.112300        0.013195   \n",
       "406       3.620925      0.079126         0.135835        0.016209   \n",
       "407       4.521915      0.225494         0.152791        0.029949   \n",
       "408       1.359964      0.059394         0.059841        0.007853   \n",
       "409       1.886158      0.063425         0.087764        0.011405   \n",
       "410       2.099187      0.034883         0.105518        0.024433   \n",
       "411       3.045061      0.317872         0.162766        0.022098   \n",
       "412       1.612291      0.177478         0.065625        0.019146   \n",
       "413       2.007234      0.088330         0.078590        0.007394   \n",
       "414       2.323388      0.096593         0.131648        0.036492   \n",
       "415       2.863746      0.326015         0.108908        0.005100   \n",
       "416       0.695142      0.006765         0.045480        0.001622   \n",
       "417       1.286961      0.038350         0.085571        0.005329   \n",
       "418       1.576188      0.030077         0.106715        0.014175   \n",
       "419       1.878180      0.073264         0.113496        0.008112   \n",
       "\n",
       "    param_rfc__max_depth param_rfc__max_features param_rfc__min_samples_split  \\\n",
       "0                      3                    auto                          0.1   \n",
       "1                      3                    auto                          0.1   \n",
       "2                      3                    auto                          0.1   \n",
       "3                      3                    auto                          0.1   \n",
       "4                      3                    auto                          0.2   \n",
       "5                      3                    auto                          0.2   \n",
       "6                      3                    auto                          0.2   \n",
       "7                      3                    auto                          0.2   \n",
       "8                      3                    auto                          0.3   \n",
       "9                      3                    auto                          0.3   \n",
       "10                     3                    auto                          0.3   \n",
       "11                     3                    auto                          0.3   \n",
       "12                     3                    auto                          0.4   \n",
       "13                     3                    auto                          0.4   \n",
       "14                     3                    auto                          0.4   \n",
       "15                     3                    auto                          0.4   \n",
       "16                     3                    auto                          0.5   \n",
       "17                     3                    auto                          0.5   \n",
       "18                     3                    auto                          0.5   \n",
       "19                     3                    auto                          0.5   \n",
       "20                     3                    log2                          0.1   \n",
       "21                     3                    log2                          0.1   \n",
       "22                     3                    log2                          0.1   \n",
       "23                     3                    log2                          0.1   \n",
       "24                     3                    log2                          0.2   \n",
       "25                     3                    log2                          0.2   \n",
       "26                     3                    log2                          0.2   \n",
       "27                     3                    log2                          0.2   \n",
       "28                     3                    log2                          0.3   \n",
       "29                     3                    log2                          0.3   \n",
       "..                   ...                     ...                          ...   \n",
       "390                   15                    log2                          0.3   \n",
       "391                   15                    log2                          0.3   \n",
       "392                   15                    log2                          0.4   \n",
       "393                   15                    log2                          0.4   \n",
       "394                   15                    log2                          0.4   \n",
       "395                   15                    log2                          0.4   \n",
       "396                   15                    log2                          0.5   \n",
       "397                   15                    log2                          0.5   \n",
       "398                   15                    log2                          0.5   \n",
       "399                   15                    log2                          0.5   \n",
       "400                   15                    None                          0.1   \n",
       "401                   15                    None                          0.1   \n",
       "402                   15                    None                          0.1   \n",
       "403                   15                    None                          0.1   \n",
       "404                   15                    None                          0.2   \n",
       "405                   15                    None                          0.2   \n",
       "406                   15                    None                          0.2   \n",
       "407                   15                    None                          0.2   \n",
       "408                   15                    None                          0.3   \n",
       "409                   15                    None                          0.3   \n",
       "410                   15                    None                          0.3   \n",
       "411                   15                    None                          0.3   \n",
       "412                   15                    None                          0.4   \n",
       "413                   15                    None                          0.4   \n",
       "414                   15                    None                          0.4   \n",
       "415                   15                    None                          0.4   \n",
       "416                   15                    None                          0.5   \n",
       "417                   15                    None                          0.5   \n",
       "418                   15                    None                          0.5   \n",
       "419                   15                    None                          0.5   \n",
       "\n",
       "    param_rfc__n_estimators  \\\n",
       "0                        10   \n",
       "1                        15   \n",
       "2                        20   \n",
       "3                        25   \n",
       "4                        10   \n",
       "5                        15   \n",
       "6                        20   \n",
       "7                        25   \n",
       "8                        10   \n",
       "9                        15   \n",
       "10                       20   \n",
       "11                       25   \n",
       "12                       10   \n",
       "13                       15   \n",
       "14                       20   \n",
       "15                       25   \n",
       "16                       10   \n",
       "17                       15   \n",
       "18                       20   \n",
       "19                       25   \n",
       "20                       10   \n",
       "21                       15   \n",
       "22                       20   \n",
       "23                       25   \n",
       "24                       10   \n",
       "25                       15   \n",
       "26                       20   \n",
       "27                       25   \n",
       "28                       10   \n",
       "29                       15   \n",
       "..                      ...   \n",
       "390                      20   \n",
       "391                      25   \n",
       "392                      10   \n",
       "393                      15   \n",
       "394                      20   \n",
       "395                      25   \n",
       "396                      10   \n",
       "397                      15   \n",
       "398                      20   \n",
       "399                      25   \n",
       "400                      10   \n",
       "401                      15   \n",
       "402                      20   \n",
       "403                      25   \n",
       "404                      10   \n",
       "405                      15   \n",
       "406                      20   \n",
       "407                      25   \n",
       "408                      10   \n",
       "409                      15   \n",
       "410                      20   \n",
       "411                      25   \n",
       "412                      10   \n",
       "413                      15   \n",
       "414                      20   \n",
       "415                      25   \n",
       "416                      10   \n",
       "417                      15   \n",
       "418                      20   \n",
       "419                      25   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "0    {'rfc__max_depth': 3, 'rfc__max_features': 'au...           0.496620   \n",
       "1    {'rfc__max_depth': 3, 'rfc__max_features': 'au...           0.527917   \n",
       "2    {'rfc__max_depth': 3, 'rfc__max_features': 'au...           0.539167   \n",
       "3    {'rfc__max_depth': 3, 'rfc__max_features': 'au...           0.515694   \n",
       "4    {'rfc__max_depth': 3, 'rfc__max_features': 'au...           0.472870   \n",
       "5    {'rfc__max_depth': 3, 'rfc__max_features': 'au...           0.440324   \n",
       "6    {'rfc__max_depth': 3, 'rfc__max_features': 'au...           0.462407   \n",
       "7    {'rfc__max_depth': 3, 'rfc__max_features': 'au...           0.467593   \n",
       "8    {'rfc__max_depth': 3, 'rfc__max_features': 'au...           0.413889   \n",
       "9    {'rfc__max_depth': 3, 'rfc__max_features': 'au...           0.401806   \n",
       "10   {'rfc__max_depth': 3, 'rfc__max_features': 'au...           0.429167   \n",
       "11   {'rfc__max_depth': 3, 'rfc__max_features': 'au...           0.412315   \n",
       "12   {'rfc__max_depth': 3, 'rfc__max_features': 'au...           0.422593   \n",
       "13   {'rfc__max_depth': 3, 'rfc__max_features': 'au...           0.423426   \n",
       "14   {'rfc__max_depth': 3, 'rfc__max_features': 'au...           0.409722   \n",
       "15   {'rfc__max_depth': 3, 'rfc__max_features': 'au...           0.410602   \n",
       "16   {'rfc__max_depth': 3, 'rfc__max_features': 'au...           0.366806   \n",
       "17   {'rfc__max_depth': 3, 'rfc__max_features': 'au...           0.341435   \n",
       "18   {'rfc__max_depth': 3, 'rfc__max_features': 'au...           0.339120   \n",
       "19   {'rfc__max_depth': 3, 'rfc__max_features': 'au...           0.378102   \n",
       "20   {'rfc__max_depth': 3, 'rfc__max_features': 'lo...           0.529676   \n",
       "21   {'rfc__max_depth': 3, 'rfc__max_features': 'lo...           0.541667   \n",
       "22   {'rfc__max_depth': 3, 'rfc__max_features': 'lo...           0.532778   \n",
       "23   {'rfc__max_depth': 3, 'rfc__max_features': 'lo...           0.534769   \n",
       "24   {'rfc__max_depth': 3, 'rfc__max_features': 'lo...           0.494630   \n",
       "25   {'rfc__max_depth': 3, 'rfc__max_features': 'lo...           0.487593   \n",
       "26   {'rfc__max_depth': 3, 'rfc__max_features': 'lo...           0.445370   \n",
       "27   {'rfc__max_depth': 3, 'rfc__max_features': 'lo...           0.497315   \n",
       "28   {'rfc__max_depth': 3, 'rfc__max_features': 'lo...           0.420648   \n",
       "29   {'rfc__max_depth': 3, 'rfc__max_features': 'lo...           0.437315   \n",
       "..                                                 ...                ...   \n",
       "390  {'rfc__max_depth': 15, 'rfc__max_features': 'l...           0.409676   \n",
       "391  {'rfc__max_depth': 15, 'rfc__max_features': 'l...           0.418194   \n",
       "392  {'rfc__max_depth': 15, 'rfc__max_features': 'l...           0.389074   \n",
       "393  {'rfc__max_depth': 15, 'rfc__max_features': 'l...           0.410602   \n",
       "394  {'rfc__max_depth': 15, 'rfc__max_features': 'l...           0.418194   \n",
       "395  {'rfc__max_depth': 15, 'rfc__max_features': 'l...           0.411343   \n",
       "396  {'rfc__max_depth': 15, 'rfc__max_features': 'l...           0.320278   \n",
       "397  {'rfc__max_depth': 15, 'rfc__max_features': 'l...           0.361204   \n",
       "398  {'rfc__max_depth': 15, 'rfc__max_features': 'l...           0.381528   \n",
       "399  {'rfc__max_depth': 15, 'rfc__max_features': 'l...           0.302778   \n",
       "400  {'rfc__max_depth': 15, 'rfc__max_features': No...           0.523981   \n",
       "401  {'rfc__max_depth': 15, 'rfc__max_features': No...           0.538056   \n",
       "402  {'rfc__max_depth': 15, 'rfc__max_features': No...           0.537361   \n",
       "403  {'rfc__max_depth': 15, 'rfc__max_features': No...           0.537083   \n",
       "404  {'rfc__max_depth': 15, 'rfc__max_features': No...           0.406991   \n",
       "405  {'rfc__max_depth': 15, 'rfc__max_features': No...           0.407685   \n",
       "406  {'rfc__max_depth': 15, 'rfc__max_features': No...           0.406991   \n",
       "407  {'rfc__max_depth': 15, 'rfc__max_features': No...           0.407685   \n",
       "408  {'rfc__max_depth': 15, 'rfc__max_features': No...           0.313981   \n",
       "409  {'rfc__max_depth': 15, 'rfc__max_features': No...           0.314028   \n",
       "410  {'rfc__max_depth': 15, 'rfc__max_features': No...           0.314213   \n",
       "411  {'rfc__max_depth': 15, 'rfc__max_features': No...           0.313981   \n",
       "412  {'rfc__max_depth': 15, 'rfc__max_features': No...           0.313981   \n",
       "413  {'rfc__max_depth': 15, 'rfc__max_features': No...           0.314028   \n",
       "414  {'rfc__max_depth': 15, 'rfc__max_features': No...           0.313981   \n",
       "415  {'rfc__max_depth': 15, 'rfc__max_features': No...           0.314213   \n",
       "416  {'rfc__max_depth': 15, 'rfc__max_features': No...           0.217963   \n",
       "417  {'rfc__max_depth': 15, 'rfc__max_features': No...           0.217963   \n",
       "418  {'rfc__max_depth': 15, 'rfc__max_features': No...           0.217963   \n",
       "419  {'rfc__max_depth': 15, 'rfc__max_features': No...           0.217963   \n",
       "\n",
       "     ...  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0    ...         0.509583        0.020373               83   \n",
       "1    ...         0.527000        0.017146               79   \n",
       "2    ...         0.537741        0.007595               69   \n",
       "3    ...         0.527713        0.013402               78   \n",
       "4    ...         0.461037        0.010641              134   \n",
       "5    ...         0.461074        0.026648              133   \n",
       "6    ...         0.463981        0.019041              130   \n",
       "7    ...         0.462981        0.021387              131   \n",
       "8    ...         0.423231        0.022121              146   \n",
       "9    ...         0.408444        0.010719              239   \n",
       "10   ...         0.417565        0.007101              170   \n",
       "11   ...         0.420648        0.005686              154   \n",
       "12   ...         0.407259        0.015336              244   \n",
       "13   ...         0.424269        0.009492              144   \n",
       "14   ...         0.404426        0.009232              250   \n",
       "15   ...         0.416259        0.004308              183   \n",
       "16   ...         0.347769        0.025205              320   \n",
       "17   ...         0.366537        0.015316              288   \n",
       "18   ...         0.357361        0.016124              303   \n",
       "19   ...         0.364417        0.009334              293   \n",
       "20   ...         0.534611        0.012022               74   \n",
       "21   ...         0.532287        0.008163               77   \n",
       "22   ...         0.534250        0.012534               75   \n",
       "23   ...         0.533148        0.012363               76   \n",
       "24   ...         0.467954        0.020177              116   \n",
       "25   ...         0.464898        0.014718              127   \n",
       "26   ...         0.454769        0.013775              138   \n",
       "27   ...         0.480417        0.011187               93   \n",
       "28   ...         0.418352        0.015553              168   \n",
       "29   ...         0.418352        0.017783              168   \n",
       "..   ...              ...             ...              ...   \n",
       "390  ...         0.415815        0.005117              188   \n",
       "391  ...         0.421602        0.010382              150   \n",
       "392  ...         0.408574        0.010843              237   \n",
       "393  ...         0.412426        0.007112              214   \n",
       "394  ...         0.420296        0.003741              156   \n",
       "395  ...         0.399880        0.012469              262   \n",
       "396  ...         0.369398        0.025183              285   \n",
       "397  ...         0.345741        0.026880              322   \n",
       "398  ...         0.362333        0.016151              296   \n",
       "399  ...         0.341769        0.029053              328   \n",
       "400  ...         0.536815        0.010649               72   \n",
       "401  ...         0.538852        0.007866               67   \n",
       "402  ...         0.542907        0.010025               63   \n",
       "403  ...         0.545667        0.006868               55   \n",
       "404  ...         0.400602        0.015971              261   \n",
       "405  ...         0.393102        0.019108              268   \n",
       "406  ...         0.409611        0.026639              229   \n",
       "407  ...         0.408880        0.000914              235   \n",
       "408  ...         0.313213        0.000856              359   \n",
       "409  ...         0.313213        0.000854              359   \n",
       "410  ...         0.313296        0.000900              337   \n",
       "411  ...         0.313213        0.000856              359   \n",
       "412  ...         0.313185        0.000847              391   \n",
       "413  ...         0.313213        0.000854              359   \n",
       "414  ...         0.313213        0.000856              359   \n",
       "415  ...         0.313250        0.000892              342   \n",
       "416  ...         0.217769        0.000578              393   \n",
       "417  ...         0.217769        0.000578              393   \n",
       "418  ...         0.217769        0.000578              393   \n",
       "419  ...         0.217769        0.000578              393   \n",
       "\n",
       "     split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0              0.502049            0.500069            0.541400   \n",
       "1              0.531076            0.534294            0.540868   \n",
       "2              0.545197            0.540475            0.534549   \n",
       "3              0.517731            0.538981            0.509213   \n",
       "4              0.472882            0.456620            0.465301   \n",
       "5              0.442500            0.447512            0.496227   \n",
       "6              0.466667            0.471412            0.481227   \n",
       "7              0.469757            0.505833            0.441019   \n",
       "8              0.414676            0.431458            0.383495   \n",
       "9              0.403484            0.401007            0.399792   \n",
       "10             0.429167            0.420729            0.415382   \n",
       "11             0.414282            0.419653            0.422963   \n",
       "12             0.424329            0.421273            0.408194   \n",
       "13             0.423472            0.422546            0.438032   \n",
       "14             0.409850            0.398715            0.414039   \n",
       "15             0.412431            0.423634            0.411736   \n",
       "16             0.365984            0.352002            0.300752   \n",
       "17             0.340926            0.363958            0.372002   \n",
       "18             0.337882            0.349641            0.349259   \n",
       "19             0.375139            0.358079            0.370012   \n",
       "20             0.533495            0.525903            0.555706   \n",
       "21             0.547361            0.529225            0.523438   \n",
       "22             0.535810            0.514213            0.534109   \n",
       "23             0.539954            0.514132            0.544271   \n",
       "24             0.495972            0.493472            0.446424   \n",
       "25             0.487928            0.475336            0.446238   \n",
       "26             0.446713            0.484352            0.454884   \n",
       "27             0.497442            0.471771            0.482789   \n",
       "28             0.420463            0.393738            0.431042   \n",
       "29             0.440810            0.423958            0.380961   \n",
       "..                  ...                 ...                 ...   \n",
       "390            0.410625            0.415833            0.422164   \n",
       "391            0.419687            0.419815            0.438715   \n",
       "392            0.390336            0.420556            0.407095   \n",
       "393            0.412002            0.423600            0.404815   \n",
       "394            0.420567            0.415752            0.420845   \n",
       "395            0.412072            0.402350            0.397975   \n",
       "396            0.320741            0.378750            0.386100   \n",
       "397            0.358634            0.376852            0.339687   \n",
       "398            0.378935            0.353009            0.352361   \n",
       "399            0.301308            0.355046            0.360613   \n",
       "400            0.529363            0.545046            0.526169   \n",
       "401            0.542755            0.544780            0.526030   \n",
       "402            0.542407            0.545104            0.529410   \n",
       "403            0.541771            0.544780            0.545081   \n",
       "404            0.408819            0.370556            0.408345   \n",
       "405            0.410613            0.370741            0.408345   \n",
       "406            0.408819            0.370556            0.410000   \n",
       "407            0.410625            0.408553            0.410012   \n",
       "408            0.312975            0.313623            0.313287   \n",
       "409            0.313009            0.313623            0.313287   \n",
       "410            0.313032            0.313600            0.313461   \n",
       "411            0.312986            0.313623            0.313287   \n",
       "412            0.312986            0.313623            0.313218   \n",
       "413            0.313021            0.313623            0.313287   \n",
       "414            0.312986            0.313623            0.313299   \n",
       "415            0.313032            0.313623            0.313264   \n",
       "416            0.217720            0.217940            0.217616   \n",
       "417            0.217720            0.217940            0.217616   \n",
       "418            0.217720            0.217940            0.217616   \n",
       "419            0.217720            0.217940            0.217616   \n",
       "\n",
       "     split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0              0.518843            0.489201          0.510313         0.018211  \n",
       "1              0.491331            0.543947          0.528303         0.019043  \n",
       "2              0.545602            0.529711          0.539106         0.006168  \n",
       "3              0.536840            0.540729          0.528699         0.012781  \n",
       "4              0.441852            0.464259          0.460183         0.010515  \n",
       "5              0.432593            0.495845          0.462935         0.027450  \n",
       "6              0.473750            0.427789          0.464169         0.018788  \n",
       "7              0.457141            0.447743          0.464299         0.022901  \n",
       "8              0.442095            0.447292          0.423803         0.023034  \n",
       "9              0.420116            0.425498          0.409979         0.010678  \n",
       "10             0.412674            0.409340          0.417458         0.006941  \n",
       "11             0.413588            0.433565          0.420810         0.007258  \n",
       "12             0.399757            0.385197          0.407750         0.014356  \n",
       "13             0.423681            0.408924          0.423331         0.009214  \n",
       "14             0.407500            0.390937          0.404208         0.008314  \n",
       "15             0.416840            0.421887          0.417306         0.004817  \n",
       "16             0.346817            0.376447          0.348400         0.026006  \n",
       "17             0.387292            0.368287          0.366493         0.015008  \n",
       "18             0.385579            0.364606          0.357394         0.016452  \n",
       "19             0.352604            0.364271          0.364021         0.008065  \n",
       "20             0.523044            0.534051          0.534440         0.011455  \n",
       "21             0.525509            0.542836          0.533674         0.009618  \n",
       "22             0.542963            0.540046          0.533428         0.010100  \n",
       "23             0.534190            0.538414          0.534192         0.010536  \n",
       "24             0.459062            0.453553          0.469697         0.020838  \n",
       "25             0.468600            0.447465          0.465113         0.016155  \n",
       "26             0.437454            0.460104          0.456701         0.015809  \n",
       "27             0.482593            0.472500          0.481419         0.009302  \n",
       "28             0.406586            0.442917          0.418949         0.017386  \n",
       "29             0.423102            0.421447          0.418056         0.019827  \n",
       "..                  ...                 ...               ...              ...  \n",
       "390            0.408681            0.418912          0.415243         0.005022  \n",
       "391            0.408079            0.419375          0.421134         0.009864  \n",
       "392            0.409178            0.416227          0.408678         0.010366  \n",
       "393            0.402257            0.422963          0.413127         0.008887  \n",
       "394            0.420648            0.424456          0.420454         0.002769  \n",
       "395            0.375486            0.410764          0.399729         0.013204  \n",
       "396            0.386250            0.377708          0.369910         0.024842  \n",
       "397            0.296551            0.356424          0.345630         0.027219  \n",
       "398            0.345394            0.388287          0.363597         0.016820  \n",
       "399            0.309225            0.384884          0.342215         0.031892  \n",
       "400            0.543160            0.544294          0.537606         0.008120  \n",
       "401            0.543067            0.544201          0.540167         0.007107  \n",
       "402            0.543391            0.557234          0.543509         0.008842  \n",
       "403            0.543669            0.557234          0.546507         0.005488  \n",
       "404            0.408206            0.408449          0.400875         0.015161  \n",
       "405            0.408380            0.370370          0.393690         0.018907  \n",
       "406            0.408229            0.453160          0.410153         0.026165  \n",
       "407            0.408356            0.408310          0.409171         0.000960  \n",
       "408            0.313032            0.313345          0.313252         0.000233  \n",
       "409            0.313021            0.313322          0.313252         0.000226  \n",
       "410            0.313032            0.313356          0.313296         0.000229  \n",
       "411            0.313032            0.313345          0.313255         0.000231  \n",
       "412            0.313021            0.313356          0.313241         0.000234  \n",
       "413            0.313021            0.313356          0.313262         0.000226  \n",
       "414            0.313021            0.313322          0.313250         0.000232  \n",
       "415            0.313009            0.313356          0.313257         0.000226  \n",
       "416            0.217627            0.217940          0.217769         0.000144  \n",
       "417            0.217627            0.217940          0.217769         0.000144  \n",
       "418            0.217627            0.217940          0.217769         0.000144  \n",
       "419            0.217627            0.217940          0.217769         0.000144  \n",
       "\n",
       "[420 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 20.7min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 21.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  abc\n",
      "Best parameters: {'abc__learning_rate': 0.3571428571428572, 'abc__n_estimators': 50}\n",
      "Best score: 0.4740740740740741\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_abc__learning_rate</th>\n",
       "      <th>param_abc__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.860247</td>\n",
       "      <td>0.195773</td>\n",
       "      <td>0.809437</td>\n",
       "      <td>0.030432</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'abc__learning_rate': 0.1, 'abc__n_estimators...</td>\n",
       "      <td>0.402407</td>\n",
       "      <td>0.410046</td>\n",
       "      <td>0.410787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410806</td>\n",
       "      <td>0.004858</td>\n",
       "      <td>24</td>\n",
       "      <td>0.406400</td>\n",
       "      <td>0.408310</td>\n",
       "      <td>0.409919</td>\n",
       "      <td>0.413021</td>\n",
       "      <td>0.417512</td>\n",
       "      <td>0.411032</td>\n",
       "      <td>0.003900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.151246</td>\n",
       "      <td>3.023377</td>\n",
       "      <td>1.418808</td>\n",
       "      <td>0.505837</td>\n",
       "      <td>0.1</td>\n",
       "      <td>75</td>\n",
       "      <td>{'abc__learning_rate': 0.1, 'abc__n_estimators...</td>\n",
       "      <td>0.424352</td>\n",
       "      <td>0.422407</td>\n",
       "      <td>0.421481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422722</td>\n",
       "      <td>0.002601</td>\n",
       "      <td>20</td>\n",
       "      <td>0.426910</td>\n",
       "      <td>0.420868</td>\n",
       "      <td>0.420741</td>\n",
       "      <td>0.424144</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.422743</td>\n",
       "      <td>0.002437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.707268</td>\n",
       "      <td>2.611382</td>\n",
       "      <td>1.828114</td>\n",
       "      <td>0.220812</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'abc__learning_rate': 0.1, 'abc__n_estimators...</td>\n",
       "      <td>0.439306</td>\n",
       "      <td>0.435278</td>\n",
       "      <td>0.426667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.436417</td>\n",
       "      <td>0.006051</td>\n",
       "      <td>14</td>\n",
       "      <td>0.442442</td>\n",
       "      <td>0.433426</td>\n",
       "      <td>0.428171</td>\n",
       "      <td>0.439340</td>\n",
       "      <td>0.437697</td>\n",
       "      <td>0.436215</td>\n",
       "      <td>0.004964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.021426</td>\n",
       "      <td>1.704024</td>\n",
       "      <td>2.496328</td>\n",
       "      <td>0.279994</td>\n",
       "      <td>0.1</td>\n",
       "      <td>125</td>\n",
       "      <td>{'abc__learning_rate': 0.1, 'abc__n_estimators...</td>\n",
       "      <td>0.450370</td>\n",
       "      <td>0.450694</td>\n",
       "      <td>0.447593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448787</td>\n",
       "      <td>0.004121</td>\n",
       "      <td>10</td>\n",
       "      <td>0.453611</td>\n",
       "      <td>0.448912</td>\n",
       "      <td>0.451412</td>\n",
       "      <td>0.435150</td>\n",
       "      <td>0.453727</td>\n",
       "      <td>0.448563</td>\n",
       "      <td>0.006932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.235274</td>\n",
       "      <td>2.228168</td>\n",
       "      <td>2.311024</td>\n",
       "      <td>0.146858</td>\n",
       "      <td>0.1</td>\n",
       "      <td>150</td>\n",
       "      <td>{'abc__learning_rate': 0.1, 'abc__n_estimators...</td>\n",
       "      <td>0.458981</td>\n",
       "      <td>0.469028</td>\n",
       "      <td>0.459028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.461565</td>\n",
       "      <td>0.004106</td>\n",
       "      <td>7</td>\n",
       "      <td>0.462986</td>\n",
       "      <td>0.469699</td>\n",
       "      <td>0.461829</td>\n",
       "      <td>0.457199</td>\n",
       "      <td>0.461227</td>\n",
       "      <td>0.462588</td>\n",
       "      <td>0.004055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.818632</td>\n",
       "      <td>0.160459</td>\n",
       "      <td>0.751990</td>\n",
       "      <td>0.046050</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>50</td>\n",
       "      <td>{'abc__learning_rate': 0.2285714285714286, 'ab...</td>\n",
       "      <td>0.440648</td>\n",
       "      <td>0.457500</td>\n",
       "      <td>0.436389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443722</td>\n",
       "      <td>0.008125</td>\n",
       "      <td>12</td>\n",
       "      <td>0.444063</td>\n",
       "      <td>0.455521</td>\n",
       "      <td>0.438704</td>\n",
       "      <td>0.429456</td>\n",
       "      <td>0.450752</td>\n",
       "      <td>0.443699</td>\n",
       "      <td>0.009137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13.408493</td>\n",
       "      <td>0.283440</td>\n",
       "      <td>1.062959</td>\n",
       "      <td>0.031192</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>75</td>\n",
       "      <td>{'abc__learning_rate': 0.2285714285714286, 'ab...</td>\n",
       "      <td>0.460509</td>\n",
       "      <td>0.465648</td>\n",
       "      <td>0.467593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.462574</td>\n",
       "      <td>0.004906</td>\n",
       "      <td>5</td>\n",
       "      <td>0.464803</td>\n",
       "      <td>0.465150</td>\n",
       "      <td>0.469630</td>\n",
       "      <td>0.455359</td>\n",
       "      <td>0.459317</td>\n",
       "      <td>0.462852</td>\n",
       "      <td>0.004973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18.108632</td>\n",
       "      <td>0.767440</td>\n",
       "      <td>1.540684</td>\n",
       "      <td>0.059412</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>100</td>\n",
       "      <td>{'abc__learning_rate': 0.2285714285714286, 'ab...</td>\n",
       "      <td>0.466944</td>\n",
       "      <td>0.462130</td>\n",
       "      <td>0.466620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.465213</td>\n",
       "      <td>0.002171</td>\n",
       "      <td>3</td>\n",
       "      <td>0.470336</td>\n",
       "      <td>0.462373</td>\n",
       "      <td>0.465532</td>\n",
       "      <td>0.455579</td>\n",
       "      <td>0.470868</td>\n",
       "      <td>0.464938</td>\n",
       "      <td>0.005636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22.278644</td>\n",
       "      <td>0.587521</td>\n",
       "      <td>2.161848</td>\n",
       "      <td>0.329258</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>125</td>\n",
       "      <td>{'abc__learning_rate': 0.2285714285714286, 'ab...</td>\n",
       "      <td>0.459074</td>\n",
       "      <td>0.460417</td>\n",
       "      <td>0.466389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463954</td>\n",
       "      <td>0.004693</td>\n",
       "      <td>4</td>\n",
       "      <td>0.461574</td>\n",
       "      <td>0.462674</td>\n",
       "      <td>0.465405</td>\n",
       "      <td>0.463819</td>\n",
       "      <td>0.466736</td>\n",
       "      <td>0.464042</td>\n",
       "      <td>0.001851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>27.640328</td>\n",
       "      <td>1.163775</td>\n",
       "      <td>2.480910</td>\n",
       "      <td>0.208393</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>150</td>\n",
       "      <td>{'abc__learning_rate': 0.2285714285714286, 'ab...</td>\n",
       "      <td>0.454537</td>\n",
       "      <td>0.452731</td>\n",
       "      <td>0.459861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.457852</td>\n",
       "      <td>0.004634</td>\n",
       "      <td>8</td>\n",
       "      <td>0.457639</td>\n",
       "      <td>0.455694</td>\n",
       "      <td>0.458634</td>\n",
       "      <td>0.457801</td>\n",
       "      <td>0.461655</td>\n",
       "      <td>0.458285</td>\n",
       "      <td>0.001941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.319130</td>\n",
       "      <td>0.302208</td>\n",
       "      <td>0.878675</td>\n",
       "      <td>0.038479</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>50</td>\n",
       "      <td>{'abc__learning_rate': 0.3571428571428572, 'ab...</td>\n",
       "      <td>0.473102</td>\n",
       "      <td>0.460509</td>\n",
       "      <td>0.484074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.474074</td>\n",
       "      <td>0.007953</td>\n",
       "      <td>1</td>\n",
       "      <td>0.476852</td>\n",
       "      <td>0.459664</td>\n",
       "      <td>0.486366</td>\n",
       "      <td>0.470683</td>\n",
       "      <td>0.476620</td>\n",
       "      <td>0.474037</td>\n",
       "      <td>0.008768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15.726173</td>\n",
       "      <td>1.278863</td>\n",
       "      <td>1.258795</td>\n",
       "      <td>0.270518</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>75</td>\n",
       "      <td>{'abc__learning_rate': 0.3571428571428572, 'ab...</td>\n",
       "      <td>0.460278</td>\n",
       "      <td>0.468935</td>\n",
       "      <td>0.471250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.468287</td>\n",
       "      <td>0.006287</td>\n",
       "      <td>2</td>\n",
       "      <td>0.463981</td>\n",
       "      <td>0.467049</td>\n",
       "      <td>0.471667</td>\n",
       "      <td>0.457836</td>\n",
       "      <td>0.480995</td>\n",
       "      <td>0.468306</td>\n",
       "      <td>0.007775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17.159880</td>\n",
       "      <td>0.241825</td>\n",
       "      <td>1.442675</td>\n",
       "      <td>0.094926</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>100</td>\n",
       "      <td>{'abc__learning_rate': 0.3571428571428572, 'ab...</td>\n",
       "      <td>0.451898</td>\n",
       "      <td>0.467870</td>\n",
       "      <td>0.452639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.462398</td>\n",
       "      <td>0.008456</td>\n",
       "      <td>6</td>\n",
       "      <td>0.454803</td>\n",
       "      <td>0.467743</td>\n",
       "      <td>0.451123</td>\n",
       "      <td>0.458079</td>\n",
       "      <td>0.477373</td>\n",
       "      <td>0.461824</td>\n",
       "      <td>0.009536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>21.793942</td>\n",
       "      <td>1.020979</td>\n",
       "      <td>1.921768</td>\n",
       "      <td>0.203932</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>125</td>\n",
       "      <td>{'abc__learning_rate': 0.3571428571428572, 'ab...</td>\n",
       "      <td>0.443889</td>\n",
       "      <td>0.450787</td>\n",
       "      <td>0.436250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440454</td>\n",
       "      <td>0.006662</td>\n",
       "      <td>13</td>\n",
       "      <td>0.445949</td>\n",
       "      <td>0.451296</td>\n",
       "      <td>0.436563</td>\n",
       "      <td>0.435914</td>\n",
       "      <td>0.439641</td>\n",
       "      <td>0.441873</td>\n",
       "      <td>0.005901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>28.571419</td>\n",
       "      <td>0.529576</td>\n",
       "      <td>2.381683</td>\n",
       "      <td>0.093041</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>150</td>\n",
       "      <td>{'abc__learning_rate': 0.3571428571428572, 'ab...</td>\n",
       "      <td>0.431806</td>\n",
       "      <td>0.435093</td>\n",
       "      <td>0.439630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.431046</td>\n",
       "      <td>0.006746</td>\n",
       "      <td>16</td>\n",
       "      <td>0.431968</td>\n",
       "      <td>0.436389</td>\n",
       "      <td>0.440613</td>\n",
       "      <td>0.423322</td>\n",
       "      <td>0.424583</td>\n",
       "      <td>0.431375</td>\n",
       "      <td>0.006661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9.388509</td>\n",
       "      <td>0.572710</td>\n",
       "      <td>0.773932</td>\n",
       "      <td>0.048725</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>50</td>\n",
       "      <td>{'abc__learning_rate': 0.48571428571428577, 'a...</td>\n",
       "      <td>0.463796</td>\n",
       "      <td>0.457500</td>\n",
       "      <td>0.443611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456676</td>\n",
       "      <td>0.008074</td>\n",
       "      <td>9</td>\n",
       "      <td>0.467975</td>\n",
       "      <td>0.456250</td>\n",
       "      <td>0.444201</td>\n",
       "      <td>0.459502</td>\n",
       "      <td>0.457407</td>\n",
       "      <td>0.457067</td>\n",
       "      <td>0.007632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13.902084</td>\n",
       "      <td>0.112351</td>\n",
       "      <td>1.153560</td>\n",
       "      <td>0.140838</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>75</td>\n",
       "      <td>{'abc__learning_rate': 0.48571428571428577, 'a...</td>\n",
       "      <td>0.447917</td>\n",
       "      <td>0.452731</td>\n",
       "      <td>0.433241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447185</td>\n",
       "      <td>0.008930</td>\n",
       "      <td>11</td>\n",
       "      <td>0.451123</td>\n",
       "      <td>0.453044</td>\n",
       "      <td>0.432338</td>\n",
       "      <td>0.451690</td>\n",
       "      <td>0.447454</td>\n",
       "      <td>0.447130</td>\n",
       "      <td>0.007624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17.940395</td>\n",
       "      <td>0.279809</td>\n",
       "      <td>1.591474</td>\n",
       "      <td>0.150009</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>100</td>\n",
       "      <td>{'abc__learning_rate': 0.48571428571428577, 'a...</td>\n",
       "      <td>0.438935</td>\n",
       "      <td>0.431019</td>\n",
       "      <td>0.435648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.429167</td>\n",
       "      <td>0.009577</td>\n",
       "      <td>18</td>\n",
       "      <td>0.441759</td>\n",
       "      <td>0.431447</td>\n",
       "      <td>0.435451</td>\n",
       "      <td>0.403866</td>\n",
       "      <td>0.435301</td>\n",
       "      <td>0.429565</td>\n",
       "      <td>0.013268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>23.284549</td>\n",
       "      <td>0.373810</td>\n",
       "      <td>2.020622</td>\n",
       "      <td>0.265395</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>125</td>\n",
       "      <td>{'abc__learning_rate': 0.48571428571428577, 'a...</td>\n",
       "      <td>0.409769</td>\n",
       "      <td>0.413519</td>\n",
       "      <td>0.429306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422676</td>\n",
       "      <td>0.014382</td>\n",
       "      <td>21</td>\n",
       "      <td>0.413299</td>\n",
       "      <td>0.414907</td>\n",
       "      <td>0.428287</td>\n",
       "      <td>0.440150</td>\n",
       "      <td>0.421134</td>\n",
       "      <td>0.423556</td>\n",
       "      <td>0.009835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>28.589372</td>\n",
       "      <td>0.384272</td>\n",
       "      <td>2.603841</td>\n",
       "      <td>0.171421</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>150</td>\n",
       "      <td>{'abc__learning_rate': 0.48571428571428577, 'a...</td>\n",
       "      <td>0.430370</td>\n",
       "      <td>0.413611</td>\n",
       "      <td>0.413843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418806</td>\n",
       "      <td>0.010058</td>\n",
       "      <td>22</td>\n",
       "      <td>0.431921</td>\n",
       "      <td>0.412708</td>\n",
       "      <td>0.415058</td>\n",
       "      <td>0.421354</td>\n",
       "      <td>0.414826</td>\n",
       "      <td>0.419174</td>\n",
       "      <td>0.006999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9.208588</td>\n",
       "      <td>0.358695</td>\n",
       "      <td>0.792652</td>\n",
       "      <td>0.151716</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>50</td>\n",
       "      <td>{'abc__learning_rate': 0.6142857142857143, 'ab...</td>\n",
       "      <td>0.439352</td>\n",
       "      <td>0.440324</td>\n",
       "      <td>0.420278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.436296</td>\n",
       "      <td>0.009286</td>\n",
       "      <td>15</td>\n",
       "      <td>0.445417</td>\n",
       "      <td>0.437477</td>\n",
       "      <td>0.418646</td>\n",
       "      <td>0.426748</td>\n",
       "      <td>0.450231</td>\n",
       "      <td>0.435704</td>\n",
       "      <td>0.011660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>13.607414</td>\n",
       "      <td>1.671031</td>\n",
       "      <td>1.270149</td>\n",
       "      <td>0.212804</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>75</td>\n",
       "      <td>{'abc__learning_rate': 0.6142857142857143, 'ab...</td>\n",
       "      <td>0.428241</td>\n",
       "      <td>0.446667</td>\n",
       "      <td>0.425324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430880</td>\n",
       "      <td>0.008077</td>\n",
       "      <td>17</td>\n",
       "      <td>0.435220</td>\n",
       "      <td>0.448866</td>\n",
       "      <td>0.423588</td>\n",
       "      <td>0.416204</td>\n",
       "      <td>0.436713</td>\n",
       "      <td>0.432118</td>\n",
       "      <td>0.011289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20.696088</td>\n",
       "      <td>1.050837</td>\n",
       "      <td>1.653382</td>\n",
       "      <td>0.084334</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>100</td>\n",
       "      <td>{'abc__learning_rate': 0.6142857142857143, 'ab...</td>\n",
       "      <td>0.392269</td>\n",
       "      <td>0.415417</td>\n",
       "      <td>0.414676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400074</td>\n",
       "      <td>0.014278</td>\n",
       "      <td>25</td>\n",
       "      <td>0.397674</td>\n",
       "      <td>0.416262</td>\n",
       "      <td>0.413530</td>\n",
       "      <td>0.396713</td>\n",
       "      <td>0.380648</td>\n",
       "      <td>0.400965</td>\n",
       "      <td>0.012912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23.401749</td>\n",
       "      <td>0.322050</td>\n",
       "      <td>1.862422</td>\n",
       "      <td>0.105537</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>125</td>\n",
       "      <td>{'abc__learning_rate': 0.6142857142857143, 'ab...</td>\n",
       "      <td>0.374398</td>\n",
       "      <td>0.394630</td>\n",
       "      <td>0.393102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.392120</td>\n",
       "      <td>0.010619</td>\n",
       "      <td>26</td>\n",
       "      <td>0.378947</td>\n",
       "      <td>0.393600</td>\n",
       "      <td>0.396053</td>\n",
       "      <td>0.385440</td>\n",
       "      <td>0.413681</td>\n",
       "      <td>0.393544</td>\n",
       "      <td>0.011752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>27.551839</td>\n",
       "      <td>0.904966</td>\n",
       "      <td>2.398390</td>\n",
       "      <td>0.271813</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>150</td>\n",
       "      <td>{'abc__learning_rate': 0.6142857142857143, 'ab...</td>\n",
       "      <td>0.373287</td>\n",
       "      <td>0.368796</td>\n",
       "      <td>0.402639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382139</td>\n",
       "      <td>0.011924</td>\n",
       "      <td>28</td>\n",
       "      <td>0.376169</td>\n",
       "      <td>0.371238</td>\n",
       "      <td>0.402361</td>\n",
       "      <td>0.380683</td>\n",
       "      <td>0.383808</td>\n",
       "      <td>0.382852</td>\n",
       "      <td>0.010637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9.401279</td>\n",
       "      <td>0.864612</td>\n",
       "      <td>0.739423</td>\n",
       "      <td>0.055330</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>50</td>\n",
       "      <td>{'abc__learning_rate': 0.7428571428571429, 'ab...</td>\n",
       "      <td>0.411343</td>\n",
       "      <td>0.425509</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.426380</td>\n",
       "      <td>0.022953</td>\n",
       "      <td>19</td>\n",
       "      <td>0.415069</td>\n",
       "      <td>0.425081</td>\n",
       "      <td>0.433160</td>\n",
       "      <td>0.458275</td>\n",
       "      <td>0.398449</td>\n",
       "      <td>0.426007</td>\n",
       "      <td>0.019861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>14.064604</td>\n",
       "      <td>0.744998</td>\n",
       "      <td>1.169674</td>\n",
       "      <td>0.121541</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>75</td>\n",
       "      <td>{'abc__learning_rate': 0.7428571428571429, 'ab...</td>\n",
       "      <td>0.422824</td>\n",
       "      <td>0.424306</td>\n",
       "      <td>0.416898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.413852</td>\n",
       "      <td>0.013923</td>\n",
       "      <td>23</td>\n",
       "      <td>0.423889</td>\n",
       "      <td>0.426088</td>\n",
       "      <td>0.419618</td>\n",
       "      <td>0.414340</td>\n",
       "      <td>0.390556</td>\n",
       "      <td>0.414898</td>\n",
       "      <td>0.012816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>18.174176</td>\n",
       "      <td>0.966213</td>\n",
       "      <td>1.720602</td>\n",
       "      <td>0.134607</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>100</td>\n",
       "      <td>{'abc__learning_rate': 0.7428571428571429, 'ab...</td>\n",
       "      <td>0.365139</td>\n",
       "      <td>0.361343</td>\n",
       "      <td>0.415278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.376417</td>\n",
       "      <td>0.019719</td>\n",
       "      <td>31</td>\n",
       "      <td>0.368368</td>\n",
       "      <td>0.362326</td>\n",
       "      <td>0.413657</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.371157</td>\n",
       "      <td>0.376435</td>\n",
       "      <td>0.018830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>23.120439</td>\n",
       "      <td>0.570008</td>\n",
       "      <td>1.984067</td>\n",
       "      <td>0.225782</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>125</td>\n",
       "      <td>{'abc__learning_rate': 0.7428571428571429, 'ab...</td>\n",
       "      <td>0.373241</td>\n",
       "      <td>0.361713</td>\n",
       "      <td>0.413935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.376787</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>30</td>\n",
       "      <td>0.376806</td>\n",
       "      <td>0.364965</td>\n",
       "      <td>0.411262</td>\n",
       "      <td>0.373588</td>\n",
       "      <td>0.361817</td>\n",
       "      <td>0.377688</td>\n",
       "      <td>0.017655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>26.192570</td>\n",
       "      <td>0.601670</td>\n",
       "      <td>2.185464</td>\n",
       "      <td>0.233302</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>150</td>\n",
       "      <td>{'abc__learning_rate': 0.7428571428571429, 'ab...</td>\n",
       "      <td>0.373796</td>\n",
       "      <td>0.337870</td>\n",
       "      <td>0.329259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339102</td>\n",
       "      <td>0.019919</td>\n",
       "      <td>36</td>\n",
       "      <td>0.375139</td>\n",
       "      <td>0.342662</td>\n",
       "      <td>0.324537</td>\n",
       "      <td>0.337789</td>\n",
       "      <td>0.315046</td>\n",
       "      <td>0.339035</td>\n",
       "      <td>0.020513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>8.595614</td>\n",
       "      <td>0.579400</td>\n",
       "      <td>0.697546</td>\n",
       "      <td>0.016707</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>50</td>\n",
       "      <td>{'abc__learning_rate': 0.8714285714285716, 'ab...</td>\n",
       "      <td>0.394028</td>\n",
       "      <td>0.387824</td>\n",
       "      <td>0.386389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382269</td>\n",
       "      <td>0.018673</td>\n",
       "      <td>27</td>\n",
       "      <td>0.398194</td>\n",
       "      <td>0.388287</td>\n",
       "      <td>0.386331</td>\n",
       "      <td>0.396609</td>\n",
       "      <td>0.343738</td>\n",
       "      <td>0.382632</td>\n",
       "      <td>0.019980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>12.461786</td>\n",
       "      <td>0.302793</td>\n",
       "      <td>1.041287</td>\n",
       "      <td>0.056160</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>75</td>\n",
       "      <td>{'abc__learning_rate': 0.8714285714285716, 'ab...</td>\n",
       "      <td>0.398565</td>\n",
       "      <td>0.338194</td>\n",
       "      <td>0.400231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370019</td>\n",
       "      <td>0.025542</td>\n",
       "      <td>32</td>\n",
       "      <td>0.402512</td>\n",
       "      <td>0.336690</td>\n",
       "      <td>0.400127</td>\n",
       "      <td>0.343634</td>\n",
       "      <td>0.366204</td>\n",
       "      <td>0.369833</td>\n",
       "      <td>0.027509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>15.686606</td>\n",
       "      <td>0.131653</td>\n",
       "      <td>1.333693</td>\n",
       "      <td>0.048857</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>100</td>\n",
       "      <td>{'abc__learning_rate': 0.8714285714285716, 'ab...</td>\n",
       "      <td>0.403472</td>\n",
       "      <td>0.339167</td>\n",
       "      <td>0.383194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361093</td>\n",
       "      <td>0.030015</td>\n",
       "      <td>34</td>\n",
       "      <td>0.406574</td>\n",
       "      <td>0.337581</td>\n",
       "      <td>0.381412</td>\n",
       "      <td>0.316169</td>\n",
       "      <td>0.363032</td>\n",
       "      <td>0.360954</td>\n",
       "      <td>0.031799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>19.717167</td>\n",
       "      <td>0.178408</td>\n",
       "      <td>1.634812</td>\n",
       "      <td>0.027764</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>125</td>\n",
       "      <td>{'abc__learning_rate': 0.8714285714285716, 'ab...</td>\n",
       "      <td>0.406343</td>\n",
       "      <td>0.303981</td>\n",
       "      <td>0.344907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344861</td>\n",
       "      <td>0.037100</td>\n",
       "      <td>35</td>\n",
       "      <td>0.408137</td>\n",
       "      <td>0.301887</td>\n",
       "      <td>0.340660</td>\n",
       "      <td>0.309063</td>\n",
       "      <td>0.362604</td>\n",
       "      <td>0.344470</td>\n",
       "      <td>0.038636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>23.410910</td>\n",
       "      <td>0.174821</td>\n",
       "      <td>2.007371</td>\n",
       "      <td>0.071424</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>150</td>\n",
       "      <td>{'abc__learning_rate': 0.8714285714285716, 'ab...</td>\n",
       "      <td>0.344676</td>\n",
       "      <td>0.302963</td>\n",
       "      <td>0.335278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.324083</td>\n",
       "      <td>0.014562</td>\n",
       "      <td>38</td>\n",
       "      <td>0.349595</td>\n",
       "      <td>0.304178</td>\n",
       "      <td>0.334560</td>\n",
       "      <td>0.314213</td>\n",
       "      <td>0.327037</td>\n",
       "      <td>0.325917</td>\n",
       "      <td>0.015787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>7.767477</td>\n",
       "      <td>0.025472</td>\n",
       "      <td>0.655368</td>\n",
       "      <td>0.011138</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'abc__learning_rate': 1.0, 'abc__n_estimators...</td>\n",
       "      <td>0.392130</td>\n",
       "      <td>0.387500</td>\n",
       "      <td>0.329259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378898</td>\n",
       "      <td>0.027974</td>\n",
       "      <td>29</td>\n",
       "      <td>0.396771</td>\n",
       "      <td>0.389931</td>\n",
       "      <td>0.328472</td>\n",
       "      <td>0.369236</td>\n",
       "      <td>0.409213</td>\n",
       "      <td>0.378725</td>\n",
       "      <td>0.028271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>11.714753</td>\n",
       "      <td>0.080614</td>\n",
       "      <td>0.995791</td>\n",
       "      <td>0.025554</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>{'abc__learning_rate': 1.0, 'abc__n_estimators...</td>\n",
       "      <td>0.373009</td>\n",
       "      <td>0.397176</td>\n",
       "      <td>0.312361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366583</td>\n",
       "      <td>0.035972</td>\n",
       "      <td>33</td>\n",
       "      <td>0.380718</td>\n",
       "      <td>0.402269</td>\n",
       "      <td>0.311505</td>\n",
       "      <td>0.335486</td>\n",
       "      <td>0.408356</td>\n",
       "      <td>0.367667</td>\n",
       "      <td>0.037982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>15.731888</td>\n",
       "      <td>0.199087</td>\n",
       "      <td>1.319545</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'abc__learning_rate': 1.0, 'abc__n_estimators...</td>\n",
       "      <td>0.264398</td>\n",
       "      <td>0.392083</td>\n",
       "      <td>0.334074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332620</td>\n",
       "      <td>0.040560</td>\n",
       "      <td>37</td>\n",
       "      <td>0.270613</td>\n",
       "      <td>0.393229</td>\n",
       "      <td>0.332153</td>\n",
       "      <td>0.337477</td>\n",
       "      <td>0.335347</td>\n",
       "      <td>0.333764</td>\n",
       "      <td>0.038841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>19.676638</td>\n",
       "      <td>0.196962</td>\n",
       "      <td>1.694396</td>\n",
       "      <td>0.061053</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>{'abc__learning_rate': 1.0, 'abc__n_estimators...</td>\n",
       "      <td>0.276713</td>\n",
       "      <td>0.312083</td>\n",
       "      <td>0.383611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.315713</td>\n",
       "      <td>0.041598</td>\n",
       "      <td>39</td>\n",
       "      <td>0.281505</td>\n",
       "      <td>0.307280</td>\n",
       "      <td>0.382407</td>\n",
       "      <td>0.334942</td>\n",
       "      <td>0.276516</td>\n",
       "      <td>0.316530</td>\n",
       "      <td>0.038967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>23.136108</td>\n",
       "      <td>0.569613</td>\n",
       "      <td>1.858110</td>\n",
       "      <td>0.202131</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>{'abc__learning_rate': 1.0, 'abc__n_estimators...</td>\n",
       "      <td>0.281574</td>\n",
       "      <td>0.319676</td>\n",
       "      <td>0.320278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.299000</td>\n",
       "      <td>0.019735</td>\n",
       "      <td>40</td>\n",
       "      <td>0.285116</td>\n",
       "      <td>0.319653</td>\n",
       "      <td>0.316088</td>\n",
       "      <td>0.301887</td>\n",
       "      <td>0.275833</td>\n",
       "      <td>0.299715</td>\n",
       "      <td>0.017052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        9.860247      0.195773         0.809437        0.030432   \n",
       "1       16.151246      3.023377         1.418808        0.505837   \n",
       "2       23.707268      2.611382         1.828114        0.220812   \n",
       "3       28.021426      1.704024         2.496328        0.279994   \n",
       "4       30.235274      2.228168         2.311024        0.146858   \n",
       "5        8.818632      0.160459         0.751990        0.046050   \n",
       "6       13.408493      0.283440         1.062959        0.031192   \n",
       "7       18.108632      0.767440         1.540684        0.059412   \n",
       "8       22.278644      0.587521         2.161848        0.329258   \n",
       "9       27.640328      1.163775         2.480910        0.208393   \n",
       "10      10.319130      0.302208         0.878675        0.038479   \n",
       "11      15.726173      1.278863         1.258795        0.270518   \n",
       "12      17.159880      0.241825         1.442675        0.094926   \n",
       "13      21.793942      1.020979         1.921768        0.203932   \n",
       "14      28.571419      0.529576         2.381683        0.093041   \n",
       "15       9.388509      0.572710         0.773932        0.048725   \n",
       "16      13.902084      0.112351         1.153560        0.140838   \n",
       "17      17.940395      0.279809         1.591474        0.150009   \n",
       "18      23.284549      0.373810         2.020622        0.265395   \n",
       "19      28.589372      0.384272         2.603841        0.171421   \n",
       "20       9.208588      0.358695         0.792652        0.151716   \n",
       "21      13.607414      1.671031         1.270149        0.212804   \n",
       "22      20.696088      1.050837         1.653382        0.084334   \n",
       "23      23.401749      0.322050         1.862422        0.105537   \n",
       "24      27.551839      0.904966         2.398390        0.271813   \n",
       "25       9.401279      0.864612         0.739423        0.055330   \n",
       "26      14.064604      0.744998         1.169674        0.121541   \n",
       "27      18.174176      0.966213         1.720602        0.134607   \n",
       "28      23.120439      0.570008         1.984067        0.225782   \n",
       "29      26.192570      0.601670         2.185464        0.233302   \n",
       "30       8.595614      0.579400         0.697546        0.016707   \n",
       "31      12.461786      0.302793         1.041287        0.056160   \n",
       "32      15.686606      0.131653         1.333693        0.048857   \n",
       "33      19.717167      0.178408         1.634812        0.027764   \n",
       "34      23.410910      0.174821         2.007371        0.071424   \n",
       "35       7.767477      0.025472         0.655368        0.011138   \n",
       "36      11.714753      0.080614         0.995791        0.025554   \n",
       "37      15.731888      0.199087         1.319545        0.027027   \n",
       "38      19.676638      0.196962         1.694396        0.061053   \n",
       "39      23.136108      0.569613         1.858110        0.202131   \n",
       "\n",
       "   param_abc__learning_rate param_abc__n_estimators  \\\n",
       "0                       0.1                      50   \n",
       "1                       0.1                      75   \n",
       "2                       0.1                     100   \n",
       "3                       0.1                     125   \n",
       "4                       0.1                     150   \n",
       "5                  0.228571                      50   \n",
       "6                  0.228571                      75   \n",
       "7                  0.228571                     100   \n",
       "8                  0.228571                     125   \n",
       "9                  0.228571                     150   \n",
       "10                 0.357143                      50   \n",
       "11                 0.357143                      75   \n",
       "12                 0.357143                     100   \n",
       "13                 0.357143                     125   \n",
       "14                 0.357143                     150   \n",
       "15                 0.485714                      50   \n",
       "16                 0.485714                      75   \n",
       "17                 0.485714                     100   \n",
       "18                 0.485714                     125   \n",
       "19                 0.485714                     150   \n",
       "20                 0.614286                      50   \n",
       "21                 0.614286                      75   \n",
       "22                 0.614286                     100   \n",
       "23                 0.614286                     125   \n",
       "24                 0.614286                     150   \n",
       "25                 0.742857                      50   \n",
       "26                 0.742857                      75   \n",
       "27                 0.742857                     100   \n",
       "28                 0.742857                     125   \n",
       "29                 0.742857                     150   \n",
       "30                 0.871429                      50   \n",
       "31                 0.871429                      75   \n",
       "32                 0.871429                     100   \n",
       "33                 0.871429                     125   \n",
       "34                 0.871429                     150   \n",
       "35                        1                      50   \n",
       "36                        1                      75   \n",
       "37                        1                     100   \n",
       "38                        1                     125   \n",
       "39                        1                     150   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'abc__learning_rate': 0.1, 'abc__n_estimators...           0.402407   \n",
       "1   {'abc__learning_rate': 0.1, 'abc__n_estimators...           0.424352   \n",
       "2   {'abc__learning_rate': 0.1, 'abc__n_estimators...           0.439306   \n",
       "3   {'abc__learning_rate': 0.1, 'abc__n_estimators...           0.450370   \n",
       "4   {'abc__learning_rate': 0.1, 'abc__n_estimators...           0.458981   \n",
       "5   {'abc__learning_rate': 0.2285714285714286, 'ab...           0.440648   \n",
       "6   {'abc__learning_rate': 0.2285714285714286, 'ab...           0.460509   \n",
       "7   {'abc__learning_rate': 0.2285714285714286, 'ab...           0.466944   \n",
       "8   {'abc__learning_rate': 0.2285714285714286, 'ab...           0.459074   \n",
       "9   {'abc__learning_rate': 0.2285714285714286, 'ab...           0.454537   \n",
       "10  {'abc__learning_rate': 0.3571428571428572, 'ab...           0.473102   \n",
       "11  {'abc__learning_rate': 0.3571428571428572, 'ab...           0.460278   \n",
       "12  {'abc__learning_rate': 0.3571428571428572, 'ab...           0.451898   \n",
       "13  {'abc__learning_rate': 0.3571428571428572, 'ab...           0.443889   \n",
       "14  {'abc__learning_rate': 0.3571428571428572, 'ab...           0.431806   \n",
       "15  {'abc__learning_rate': 0.48571428571428577, 'a...           0.463796   \n",
       "16  {'abc__learning_rate': 0.48571428571428577, 'a...           0.447917   \n",
       "17  {'abc__learning_rate': 0.48571428571428577, 'a...           0.438935   \n",
       "18  {'abc__learning_rate': 0.48571428571428577, 'a...           0.409769   \n",
       "19  {'abc__learning_rate': 0.48571428571428577, 'a...           0.430370   \n",
       "20  {'abc__learning_rate': 0.6142857142857143, 'ab...           0.439352   \n",
       "21  {'abc__learning_rate': 0.6142857142857143, 'ab...           0.428241   \n",
       "22  {'abc__learning_rate': 0.6142857142857143, 'ab...           0.392269   \n",
       "23  {'abc__learning_rate': 0.6142857142857143, 'ab...           0.374398   \n",
       "24  {'abc__learning_rate': 0.6142857142857143, 'ab...           0.373287   \n",
       "25  {'abc__learning_rate': 0.7428571428571429, 'ab...           0.411343   \n",
       "26  {'abc__learning_rate': 0.7428571428571429, 'ab...           0.422824   \n",
       "27  {'abc__learning_rate': 0.7428571428571429, 'ab...           0.365139   \n",
       "28  {'abc__learning_rate': 0.7428571428571429, 'ab...           0.373241   \n",
       "29  {'abc__learning_rate': 0.7428571428571429, 'ab...           0.373796   \n",
       "30  {'abc__learning_rate': 0.8714285714285716, 'ab...           0.394028   \n",
       "31  {'abc__learning_rate': 0.8714285714285716, 'ab...           0.398565   \n",
       "32  {'abc__learning_rate': 0.8714285714285716, 'ab...           0.403472   \n",
       "33  {'abc__learning_rate': 0.8714285714285716, 'ab...           0.406343   \n",
       "34  {'abc__learning_rate': 0.8714285714285716, 'ab...           0.344676   \n",
       "35  {'abc__learning_rate': 1.0, 'abc__n_estimators...           0.392130   \n",
       "36  {'abc__learning_rate': 1.0, 'abc__n_estimators...           0.373009   \n",
       "37  {'abc__learning_rate': 1.0, 'abc__n_estimators...           0.264398   \n",
       "38  {'abc__learning_rate': 1.0, 'abc__n_estimators...           0.276713   \n",
       "39  {'abc__learning_rate': 1.0, 'abc__n_estimators...           0.281574   \n",
       "\n",
       "    split1_test_score  split2_test_score  ...  mean_test_score  \\\n",
       "0            0.410046           0.410787  ...         0.410806   \n",
       "1            0.422407           0.421481  ...         0.422722   \n",
       "2            0.435278           0.426667  ...         0.436417   \n",
       "3            0.450694           0.447593  ...         0.448787   \n",
       "4            0.469028           0.459028  ...         0.461565   \n",
       "5            0.457500           0.436389  ...         0.443722   \n",
       "6            0.465648           0.467593  ...         0.462574   \n",
       "7            0.462130           0.466620  ...         0.465213   \n",
       "8            0.460417           0.466389  ...         0.463954   \n",
       "9            0.452731           0.459861  ...         0.457852   \n",
       "10           0.460509           0.484074  ...         0.474074   \n",
       "11           0.468935           0.471250  ...         0.468287   \n",
       "12           0.467870           0.452639  ...         0.462398   \n",
       "13           0.450787           0.436250  ...         0.440454   \n",
       "14           0.435093           0.439630  ...         0.431046   \n",
       "15           0.457500           0.443611  ...         0.456676   \n",
       "16           0.452731           0.433241  ...         0.447185   \n",
       "17           0.431019           0.435648  ...         0.429167   \n",
       "18           0.413519           0.429306  ...         0.422676   \n",
       "19           0.413611           0.413843  ...         0.418806   \n",
       "20           0.440324           0.420278  ...         0.436296   \n",
       "21           0.446667           0.425324  ...         0.430880   \n",
       "22           0.415417           0.414676  ...         0.400074   \n",
       "23           0.394630           0.393102  ...         0.392120   \n",
       "24           0.368796           0.402639  ...         0.382139   \n",
       "25           0.425509           0.433333  ...         0.426380   \n",
       "26           0.424306           0.416898  ...         0.413852   \n",
       "27           0.361343           0.415278  ...         0.376417   \n",
       "28           0.361713           0.413935  ...         0.376787   \n",
       "29           0.337870           0.329259  ...         0.339102   \n",
       "30           0.387824           0.386389  ...         0.382269   \n",
       "31           0.338194           0.400231  ...         0.370019   \n",
       "32           0.339167           0.383194  ...         0.361093   \n",
       "33           0.303981           0.344907  ...         0.344861   \n",
       "34           0.302963           0.335278  ...         0.324083   \n",
       "35           0.387500           0.329259  ...         0.378898   \n",
       "36           0.397176           0.312361  ...         0.366583   \n",
       "37           0.392083           0.334074  ...         0.332620   \n",
       "38           0.312083           0.383611  ...         0.315713   \n",
       "39           0.319676           0.320278  ...         0.299000   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0         0.004858               24            0.406400            0.408310   \n",
       "1         0.002601               20            0.426910            0.420868   \n",
       "2         0.006051               14            0.442442            0.433426   \n",
       "3         0.004121               10            0.453611            0.448912   \n",
       "4         0.004106                7            0.462986            0.469699   \n",
       "5         0.008125               12            0.444063            0.455521   \n",
       "6         0.004906                5            0.464803            0.465150   \n",
       "7         0.002171                3            0.470336            0.462373   \n",
       "8         0.004693                4            0.461574            0.462674   \n",
       "9         0.004634                8            0.457639            0.455694   \n",
       "10        0.007953                1            0.476852            0.459664   \n",
       "11        0.006287                2            0.463981            0.467049   \n",
       "12        0.008456                6            0.454803            0.467743   \n",
       "13        0.006662               13            0.445949            0.451296   \n",
       "14        0.006746               16            0.431968            0.436389   \n",
       "15        0.008074                9            0.467975            0.456250   \n",
       "16        0.008930               11            0.451123            0.453044   \n",
       "17        0.009577               18            0.441759            0.431447   \n",
       "18        0.014382               21            0.413299            0.414907   \n",
       "19        0.010058               22            0.431921            0.412708   \n",
       "20        0.009286               15            0.445417            0.437477   \n",
       "21        0.008077               17            0.435220            0.448866   \n",
       "22        0.014278               25            0.397674            0.416262   \n",
       "23        0.010619               26            0.378947            0.393600   \n",
       "24        0.011924               28            0.376169            0.371238   \n",
       "25        0.022953               19            0.415069            0.425081   \n",
       "26        0.013923               23            0.423889            0.426088   \n",
       "27        0.019719               31            0.368368            0.362326   \n",
       "28        0.019907               30            0.376806            0.364965   \n",
       "29        0.019919               36            0.375139            0.342662   \n",
       "30        0.018673               27            0.398194            0.388287   \n",
       "31        0.025542               32            0.402512            0.336690   \n",
       "32        0.030015               34            0.406574            0.337581   \n",
       "33        0.037100               35            0.408137            0.301887   \n",
       "34        0.014562               38            0.349595            0.304178   \n",
       "35        0.027974               29            0.396771            0.389931   \n",
       "36        0.035972               33            0.380718            0.402269   \n",
       "37        0.040560               37            0.270613            0.393229   \n",
       "38        0.041598               39            0.281505            0.307280   \n",
       "39        0.019735               40            0.285116            0.319653   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0             0.409919            0.413021            0.417512   \n",
       "1             0.420741            0.424144            0.421053   \n",
       "2             0.428171            0.439340            0.437697   \n",
       "3             0.451412            0.435150            0.453727   \n",
       "4             0.461829            0.457199            0.461227   \n",
       "5             0.438704            0.429456            0.450752   \n",
       "6             0.469630            0.455359            0.459317   \n",
       "7             0.465532            0.455579            0.470868   \n",
       "8             0.465405            0.463819            0.466736   \n",
       "9             0.458634            0.457801            0.461655   \n",
       "10            0.486366            0.470683            0.476620   \n",
       "11            0.471667            0.457836            0.480995   \n",
       "12            0.451123            0.458079            0.477373   \n",
       "13            0.436563            0.435914            0.439641   \n",
       "14            0.440613            0.423322            0.424583   \n",
       "15            0.444201            0.459502            0.457407   \n",
       "16            0.432338            0.451690            0.447454   \n",
       "17            0.435451            0.403866            0.435301   \n",
       "18            0.428287            0.440150            0.421134   \n",
       "19            0.415058            0.421354            0.414826   \n",
       "20            0.418646            0.426748            0.450231   \n",
       "21            0.423588            0.416204            0.436713   \n",
       "22            0.413530            0.396713            0.380648   \n",
       "23            0.396053            0.385440            0.413681   \n",
       "24            0.402361            0.380683            0.383808   \n",
       "25            0.433160            0.458275            0.398449   \n",
       "26            0.419618            0.414340            0.390556   \n",
       "27            0.413657            0.366667            0.371157   \n",
       "28            0.411262            0.373588            0.361817   \n",
       "29            0.324537            0.337789            0.315046   \n",
       "30            0.386331            0.396609            0.343738   \n",
       "31            0.400127            0.343634            0.366204   \n",
       "32            0.381412            0.316169            0.363032   \n",
       "33            0.340660            0.309063            0.362604   \n",
       "34            0.334560            0.314213            0.327037   \n",
       "35            0.328472            0.369236            0.409213   \n",
       "36            0.311505            0.335486            0.408356   \n",
       "37            0.332153            0.337477            0.335347   \n",
       "38            0.382407            0.334942            0.276516   \n",
       "39            0.316088            0.301887            0.275833   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "0           0.411032         0.003900  \n",
       "1           0.422743         0.002437  \n",
       "2           0.436215         0.004964  \n",
       "3           0.448563         0.006932  \n",
       "4           0.462588         0.004055  \n",
       "5           0.443699         0.009137  \n",
       "6           0.462852         0.004973  \n",
       "7           0.464938         0.005636  \n",
       "8           0.464042         0.001851  \n",
       "9           0.458285         0.001941  \n",
       "10          0.474037         0.008768  \n",
       "11          0.468306         0.007775  \n",
       "12          0.461824         0.009536  \n",
       "13          0.441873         0.005901  \n",
       "14          0.431375         0.006661  \n",
       "15          0.457067         0.007632  \n",
       "16          0.447130         0.007624  \n",
       "17          0.429565         0.013268  \n",
       "18          0.423556         0.009835  \n",
       "19          0.419174         0.006999  \n",
       "20          0.435704         0.011660  \n",
       "21          0.432118         0.011289  \n",
       "22          0.400965         0.012912  \n",
       "23          0.393544         0.011752  \n",
       "24          0.382852         0.010637  \n",
       "25          0.426007         0.019861  \n",
       "26          0.414898         0.012816  \n",
       "27          0.376435         0.018830  \n",
       "28          0.377688         0.017655  \n",
       "29          0.339035         0.020513  \n",
       "30          0.382632         0.019980  \n",
       "31          0.369833         0.027509  \n",
       "32          0.360954         0.031799  \n",
       "33          0.344470         0.038636  \n",
       "34          0.325917         0.015787  \n",
       "35          0.378725         0.028271  \n",
       "36          0.367667         0.037982  \n",
       "37          0.333764         0.038841  \n",
       "38          0.316530         0.038967  \n",
       "39          0.299715         0.017052  \n",
       "\n",
       "[40 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 168 candidates, totalling 840 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 52.2min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 127.7min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed: 231.8min\n",
      "[Parallel(n_jobs=-1)]: Done 840 out of 840 | elapsed: 253.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  gbc\n",
      "Best parameters: {'gbc__learning_rate': 0.6142857142857143, 'gbc__max_depth': 3, 'gbc__n_estimators': 100}\n",
      "Best score: 0.9749629629629629\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_gbc__learning_rate</th>\n",
       "      <th>param_gbc__max_depth</th>\n",
       "      <th>param_gbc__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.000124</td>\n",
       "      <td>0.216395</td>\n",
       "      <td>0.072209</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'gbc__learning_rate': 0.1, 'gbc__max_depth': ...</td>\n",
       "      <td>0.517130</td>\n",
       "      <td>0.515556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517935</td>\n",
       "      <td>0.002437</td>\n",
       "      <td>168</td>\n",
       "      <td>0.517326</td>\n",
       "      <td>0.517280</td>\n",
       "      <td>0.518484</td>\n",
       "      <td>0.518113</td>\n",
       "      <td>0.519942</td>\n",
       "      <td>0.518229</td>\n",
       "      <td>0.000972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.465018</td>\n",
       "      <td>0.751115</td>\n",
       "      <td>0.103106</td>\n",
       "      <td>0.006266</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'gbc__learning_rate': 0.1, 'gbc__max_depth': ...</td>\n",
       "      <td>0.570324</td>\n",
       "      <td>0.571111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572602</td>\n",
       "      <td>0.002474</td>\n",
       "      <td>166</td>\n",
       "      <td>0.572905</td>\n",
       "      <td>0.573530</td>\n",
       "      <td>0.573576</td>\n",
       "      <td>0.572940</td>\n",
       "      <td>0.575058</td>\n",
       "      <td>0.573602</td>\n",
       "      <td>0.000781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.859259</td>\n",
       "      <td>0.272400</td>\n",
       "      <td>0.146268</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>{'gbc__learning_rate': 0.1, 'gbc__max_depth': ...</td>\n",
       "      <td>0.595972</td>\n",
       "      <td>0.592037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.598963</td>\n",
       "      <td>0.005412</td>\n",
       "      <td>163</td>\n",
       "      <td>0.599433</td>\n",
       "      <td>0.595880</td>\n",
       "      <td>0.604884</td>\n",
       "      <td>0.597488</td>\n",
       "      <td>0.604271</td>\n",
       "      <td>0.600391</td>\n",
       "      <td>0.003604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.343044</td>\n",
       "      <td>2.240957</td>\n",
       "      <td>0.197599</td>\n",
       "      <td>0.017383</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>{'gbc__learning_rate': 0.1, 'gbc__max_depth': ...</td>\n",
       "      <td>0.618009</td>\n",
       "      <td>0.615648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.616806</td>\n",
       "      <td>0.001531</td>\n",
       "      <td>156</td>\n",
       "      <td>0.620336</td>\n",
       "      <td>0.619942</td>\n",
       "      <td>0.615266</td>\n",
       "      <td>0.617500</td>\n",
       "      <td>0.615347</td>\n",
       "      <td>0.617678</td>\n",
       "      <td>0.002167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58.678673</td>\n",
       "      <td>1.581699</td>\n",
       "      <td>0.236860</td>\n",
       "      <td>0.007721</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>{'gbc__learning_rate': 0.1, 'gbc__max_depth': ...</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.623843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.627602</td>\n",
       "      <td>0.002440</td>\n",
       "      <td>147</td>\n",
       "      <td>0.630451</td>\n",
       "      <td>0.628553</td>\n",
       "      <td>0.628669</td>\n",
       "      <td>0.628611</td>\n",
       "      <td>0.627512</td>\n",
       "      <td>0.628759</td>\n",
       "      <td>0.000948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>70.143752</td>\n",
       "      <td>0.421753</td>\n",
       "      <td>0.289088</td>\n",
       "      <td>0.022960</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>{'gbc__learning_rate': 0.1, 'gbc__max_depth': ...</td>\n",
       "      <td>0.636759</td>\n",
       "      <td>0.635787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.639083</td>\n",
       "      <td>0.002613</td>\n",
       "      <td>143</td>\n",
       "      <td>0.639317</td>\n",
       "      <td>0.639375</td>\n",
       "      <td>0.638970</td>\n",
       "      <td>0.643715</td>\n",
       "      <td>0.641296</td>\n",
       "      <td>0.640535</td>\n",
       "      <td>0.001787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>82.869452</td>\n",
       "      <td>0.874638</td>\n",
       "      <td>0.318968</td>\n",
       "      <td>0.004510</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'gbc__learning_rate': 0.1, 'gbc__max_depth': ...</td>\n",
       "      <td>0.653981</td>\n",
       "      <td>0.653102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.653639</td>\n",
       "      <td>0.001778</td>\n",
       "      <td>139</td>\n",
       "      <td>0.657847</td>\n",
       "      <td>0.655127</td>\n",
       "      <td>0.653947</td>\n",
       "      <td>0.655729</td>\n",
       "      <td>0.651539</td>\n",
       "      <td>0.654838</td>\n",
       "      <td>0.002079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.327048</td>\n",
       "      <td>0.173426</td>\n",
       "      <td>0.073684</td>\n",
       "      <td>0.007179</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>{'gbc__learning_rate': 0.1, 'gbc__max_depth': ...</td>\n",
       "      <td>0.592500</td>\n",
       "      <td>0.592963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.593611</td>\n",
       "      <td>0.003733</td>\n",
       "      <td>164</td>\n",
       "      <td>0.597616</td>\n",
       "      <td>0.595359</td>\n",
       "      <td>0.589711</td>\n",
       "      <td>0.595081</td>\n",
       "      <td>0.596771</td>\n",
       "      <td>0.594907</td>\n",
       "      <td>0.002759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32.380767</td>\n",
       "      <td>1.334099</td>\n",
       "      <td>0.137466</td>\n",
       "      <td>0.013890</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>{'gbc__learning_rate': 0.1, 'gbc__max_depth': ...</td>\n",
       "      <td>0.640417</td>\n",
       "      <td>0.646898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.648713</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>141</td>\n",
       "      <td>0.647616</td>\n",
       "      <td>0.651111</td>\n",
       "      <td>0.653032</td>\n",
       "      <td>0.653160</td>\n",
       "      <td>0.648970</td>\n",
       "      <td>0.650778</td>\n",
       "      <td>0.002197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>52.557128</td>\n",
       "      <td>2.082649</td>\n",
       "      <td>0.184326</td>\n",
       "      <td>0.017956</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>{'gbc__learning_rate': 0.1, 'gbc__max_depth': ...</td>\n",
       "      <td>0.694861</td>\n",
       "      <td>0.695463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.695620</td>\n",
       "      <td>0.003238</td>\n",
       "      <td>115</td>\n",
       "      <td>0.701076</td>\n",
       "      <td>0.695417</td>\n",
       "      <td>0.700069</td>\n",
       "      <td>0.697512</td>\n",
       "      <td>0.693600</td>\n",
       "      <td>0.697535</td>\n",
       "      <td>0.002791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>68.264497</td>\n",
       "      <td>0.698086</td>\n",
       "      <td>0.233126</td>\n",
       "      <td>0.002568</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>{'gbc__learning_rate': 0.1, 'gbc__max_depth': ...</td>\n",
       "      <td>0.734769</td>\n",
       "      <td>0.742500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.736306</td>\n",
       "      <td>0.003406</td>\n",
       "      <td>96</td>\n",
       "      <td>0.741215</td>\n",
       "      <td>0.746123</td>\n",
       "      <td>0.733102</td>\n",
       "      <td>0.734178</td>\n",
       "      <td>0.738252</td>\n",
       "      <td>0.738574</td>\n",
       "      <td>0.004761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>86.367007</td>\n",
       "      <td>0.352757</td>\n",
       "      <td>0.290603</td>\n",
       "      <td>0.010691</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>{'gbc__learning_rate': 0.1, 'gbc__max_depth': ...</td>\n",
       "      <td>0.754398</td>\n",
       "      <td>0.754907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.757120</td>\n",
       "      <td>0.002859</td>\n",
       "      <td>91</td>\n",
       "      <td>0.761262</td>\n",
       "      <td>0.758287</td>\n",
       "      <td>0.760799</td>\n",
       "      <td>0.760625</td>\n",
       "      <td>0.759062</td>\n",
       "      <td>0.760007</td>\n",
       "      <td>0.001134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>104.790304</td>\n",
       "      <td>0.361888</td>\n",
       "      <td>0.340625</td>\n",
       "      <td>0.015081</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>{'gbc__learning_rate': 0.1, 'gbc__max_depth': ...</td>\n",
       "      <td>0.771019</td>\n",
       "      <td>0.776481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.775796</td>\n",
       "      <td>0.005156</td>\n",
       "      <td>89</td>\n",
       "      <td>0.778044</td>\n",
       "      <td>0.779850</td>\n",
       "      <td>0.777396</td>\n",
       "      <td>0.784213</td>\n",
       "      <td>0.774363</td>\n",
       "      <td>0.778773</td>\n",
       "      <td>0.003244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>123.854204</td>\n",
       "      <td>0.530788</td>\n",
       "      <td>0.386210</td>\n",
       "      <td>0.005326</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'gbc__learning_rate': 0.1, 'gbc__max_depth': ...</td>\n",
       "      <td>0.787222</td>\n",
       "      <td>0.789491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.794083</td>\n",
       "      <td>0.005567</td>\n",
       "      <td>83</td>\n",
       "      <td>0.795521</td>\n",
       "      <td>0.792465</td>\n",
       "      <td>0.803912</td>\n",
       "      <td>0.798669</td>\n",
       "      <td>0.797581</td>\n",
       "      <td>0.797630</td>\n",
       "      <td>0.003786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17.071684</td>\n",
       "      <td>0.292955</td>\n",
       "      <td>0.080385</td>\n",
       "      <td>0.005447</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'gbc__learning_rate': 0.1, 'gbc__max_depth': ...</td>\n",
       "      <td>0.646435</td>\n",
       "      <td>0.648796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.655435</td>\n",
       "      <td>0.006456</td>\n",
       "      <td>137</td>\n",
       "      <td>0.652685</td>\n",
       "      <td>0.650637</td>\n",
       "      <td>0.658368</td>\n",
       "      <td>0.660625</td>\n",
       "      <td>0.660521</td>\n",
       "      <td>0.656567</td>\n",
       "      <td>0.004137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>42.603677</td>\n",
       "      <td>0.112104</td>\n",
       "      <td>0.146940</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>{'gbc__learning_rate': 0.1, 'gbc__max_depth': ...</td>\n",
       "      <td>0.734213</td>\n",
       "      <td>0.740972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.739806</td>\n",
       "      <td>0.004869</td>\n",
       "      <td>94</td>\n",
       "      <td>0.741655</td>\n",
       "      <td>0.743044</td>\n",
       "      <td>0.740972</td>\n",
       "      <td>0.737963</td>\n",
       "      <td>0.747940</td>\n",
       "      <td>0.742315</td>\n",
       "      <td>0.003266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>68.068799</td>\n",
       "      <td>0.115778</td>\n",
       "      <td>0.212632</td>\n",
       "      <td>0.002044</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>{'gbc__learning_rate': 0.1, 'gbc__max_depth': ...</td>\n",
       "      <td>0.808148</td>\n",
       "      <td>0.802546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.801833</td>\n",
       "      <td>0.003608</td>\n",
       "      <td>76</td>\n",
       "      <td>0.813449</td>\n",
       "      <td>0.806366</td>\n",
       "      <td>0.799803</td>\n",
       "      <td>0.799537</td>\n",
       "      <td>0.802697</td>\n",
       "      <td>0.804370</td>\n",
       "      <td>0.005166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>93.546063</td>\n",
       "      <td>0.639949</td>\n",
       "      <td>0.276050</td>\n",
       "      <td>0.003291</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "      <td>{'gbc__learning_rate': 0.1, 'gbc__max_depth': ...</td>\n",
       "      <td>0.839213</td>\n",
       "      <td>0.838102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.839176</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>67</td>\n",
       "      <td>0.845903</td>\n",
       "      <td>0.840729</td>\n",
       "      <td>0.837465</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.842350</td>\n",
       "      <td>0.841829</td>\n",
       "      <td>0.002752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>119.473614</td>\n",
       "      <td>1.046381</td>\n",
       "      <td>0.336403</td>\n",
       "      <td>0.003617</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>{'gbc__learning_rate': 0.1, 'gbc__max_depth': ...</td>\n",
       "      <td>0.858333</td>\n",
       "      <td>0.863565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.861759</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>57</td>\n",
       "      <td>0.867002</td>\n",
       "      <td>0.866250</td>\n",
       "      <td>0.864537</td>\n",
       "      <td>0.864965</td>\n",
       "      <td>0.866100</td>\n",
       "      <td>0.865771</td>\n",
       "      <td>0.000897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>144.045514</td>\n",
       "      <td>0.752579</td>\n",
       "      <td>0.399223</td>\n",
       "      <td>0.006099</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>85</td>\n",
       "      <td>{'gbc__learning_rate': 0.1, 'gbc__max_depth': ...</td>\n",
       "      <td>0.874815</td>\n",
       "      <td>0.879352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.877222</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>49</td>\n",
       "      <td>0.883553</td>\n",
       "      <td>0.882477</td>\n",
       "      <td>0.878345</td>\n",
       "      <td>0.885312</td>\n",
       "      <td>0.878125</td>\n",
       "      <td>0.881563</td>\n",
       "      <td>0.002865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>169.275392</td>\n",
       "      <td>0.499545</td>\n",
       "      <td>0.480153</td>\n",
       "      <td>0.014185</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'gbc__learning_rate': 0.1, 'gbc__max_depth': ...</td>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.890185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.890370</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>43</td>\n",
       "      <td>0.893669</td>\n",
       "      <td>0.895174</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.895567</td>\n",
       "      <td>0.896424</td>\n",
       "      <td>0.895167</td>\n",
       "      <td>0.000896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8.299250</td>\n",
       "      <td>0.076714</td>\n",
       "      <td>0.060638</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'gbc__learning_rate': 0.2285714285714286, 'gb...</td>\n",
       "      <td>0.569861</td>\n",
       "      <td>0.564259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.569269</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>167</td>\n",
       "      <td>0.572662</td>\n",
       "      <td>0.568333</td>\n",
       "      <td>0.569722</td>\n",
       "      <td>0.567361</td>\n",
       "      <td>0.573380</td>\n",
       "      <td>0.570292</td>\n",
       "      <td>0.002362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20.591975</td>\n",
       "      <td>0.162261</td>\n",
       "      <td>0.101182</td>\n",
       "      <td>0.004123</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'gbc__learning_rate': 0.2285714285714286, 'gb...</td>\n",
       "      <td>0.621528</td>\n",
       "      <td>0.617639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.622537</td>\n",
       "      <td>0.003426</td>\n",
       "      <td>149</td>\n",
       "      <td>0.624907</td>\n",
       "      <td>0.621389</td>\n",
       "      <td>0.621331</td>\n",
       "      <td>0.622211</td>\n",
       "      <td>0.624525</td>\n",
       "      <td>0.622873</td>\n",
       "      <td>0.001542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>32.807524</td>\n",
       "      <td>0.304471</td>\n",
       "      <td>0.147694</td>\n",
       "      <td>0.005301</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>{'gbc__learning_rate': 0.2285714285714286, 'gb...</td>\n",
       "      <td>0.648935</td>\n",
       "      <td>0.646435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.652324</td>\n",
       "      <td>0.004112</td>\n",
       "      <td>140</td>\n",
       "      <td>0.651620</td>\n",
       "      <td>0.650498</td>\n",
       "      <td>0.655775</td>\n",
       "      <td>0.655671</td>\n",
       "      <td>0.653762</td>\n",
       "      <td>0.653465</td>\n",
       "      <td>0.002121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>45.161011</td>\n",
       "      <td>0.550502</td>\n",
       "      <td>0.191562</td>\n",
       "      <td>0.007782</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>{'gbc__learning_rate': 0.2285714285714286, 'gb...</td>\n",
       "      <td>0.671944</td>\n",
       "      <td>0.668241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.671324</td>\n",
       "      <td>0.002624</td>\n",
       "      <td>133</td>\n",
       "      <td>0.676007</td>\n",
       "      <td>0.670567</td>\n",
       "      <td>0.672141</td>\n",
       "      <td>0.671308</td>\n",
       "      <td>0.670058</td>\n",
       "      <td>0.672016</td>\n",
       "      <td>0.002116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>57.950363</td>\n",
       "      <td>0.827168</td>\n",
       "      <td>0.236983</td>\n",
       "      <td>0.006063</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>{'gbc__learning_rate': 0.2285714285714286, 'gb...</td>\n",
       "      <td>0.673935</td>\n",
       "      <td>0.677593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.677648</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>130</td>\n",
       "      <td>0.679190</td>\n",
       "      <td>0.677697</td>\n",
       "      <td>0.679514</td>\n",
       "      <td>0.680243</td>\n",
       "      <td>0.676574</td>\n",
       "      <td>0.678644</td>\n",
       "      <td>0.001326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>71.296082</td>\n",
       "      <td>2.443681</td>\n",
       "      <td>0.281002</td>\n",
       "      <td>0.013184</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>{'gbc__learning_rate': 0.2285714285714286, 'gb...</td>\n",
       "      <td>0.681806</td>\n",
       "      <td>0.688472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.685333</td>\n",
       "      <td>0.002681</td>\n",
       "      <td>123</td>\n",
       "      <td>0.688403</td>\n",
       "      <td>0.688368</td>\n",
       "      <td>0.686227</td>\n",
       "      <td>0.683692</td>\n",
       "      <td>0.687708</td>\n",
       "      <td>0.686880</td>\n",
       "      <td>0.001778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>86.047799</td>\n",
       "      <td>2.088110</td>\n",
       "      <td>0.319901</td>\n",
       "      <td>0.003827</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'gbc__learning_rate': 0.2285714285714286, 'gb...</td>\n",
       "      <td>0.692963</td>\n",
       "      <td>0.693889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.696889</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>113</td>\n",
       "      <td>0.700023</td>\n",
       "      <td>0.693958</td>\n",
       "      <td>0.697789</td>\n",
       "      <td>0.699907</td>\n",
       "      <td>0.700984</td>\n",
       "      <td>0.698532</td>\n",
       "      <td>0.002514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>12.212018</td>\n",
       "      <td>0.051074</td>\n",
       "      <td>0.073218</td>\n",
       "      <td>0.004990</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>{'gbc__learning_rate': 0.2285714285714286, 'gb...</td>\n",
       "      <td>0.631944</td>\n",
       "      <td>0.635833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.644102</td>\n",
       "      <td>0.008699</td>\n",
       "      <td>142</td>\n",
       "      <td>0.638831</td>\n",
       "      <td>0.638206</td>\n",
       "      <td>0.652315</td>\n",
       "      <td>0.653426</td>\n",
       "      <td>0.647315</td>\n",
       "      <td>0.646019</td>\n",
       "      <td>0.006464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.892759</td>\n",
       "      <td>0.160707</td>\n",
       "      <td>0.120296</td>\n",
       "      <td>0.003533</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>{'gbc__learning_rate': 0.2285714285714286, 'gb...</td>\n",
       "      <td>0.743611</td>\n",
       "      <td>0.745231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.744231</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>93</td>\n",
       "      <td>0.749028</td>\n",
       "      <td>0.748553</td>\n",
       "      <td>0.746516</td>\n",
       "      <td>0.744583</td>\n",
       "      <td>0.746204</td>\n",
       "      <td>0.746977</td>\n",
       "      <td>0.001627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>106.332794</td>\n",
       "      <td>2.902193</td>\n",
       "      <td>0.326117</td>\n",
       "      <td>0.015116</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>{'gbc__learning_rate': 0.8714285714285716, 'gb...</td>\n",
       "      <td>0.797963</td>\n",
       "      <td>0.885370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838833</td>\n",
       "      <td>0.048147</td>\n",
       "      <td>68</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.893877</td>\n",
       "      <td>0.777106</td>\n",
       "      <td>0.901019</td>\n",
       "      <td>0.851308</td>\n",
       "      <td>0.845912</td>\n",
       "      <td>0.048319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>125.892016</td>\n",
       "      <td>3.508273</td>\n",
       "      <td>0.375623</td>\n",
       "      <td>0.021911</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'gbc__learning_rate': 0.8714285714285716, 'gb...</td>\n",
       "      <td>0.815046</td>\n",
       "      <td>0.893194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847093</td>\n",
       "      <td>0.050582</td>\n",
       "      <td>62</td>\n",
       "      <td>0.822789</td>\n",
       "      <td>0.902373</td>\n",
       "      <td>0.772662</td>\n",
       "      <td>0.909664</td>\n",
       "      <td>0.861539</td>\n",
       "      <td>0.853806</td>\n",
       "      <td>0.051157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>17.231455</td>\n",
       "      <td>0.574736</td>\n",
       "      <td>0.081304</td>\n",
       "      <td>0.007961</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'gbc__learning_rate': 0.8714285714285716, 'gb...</td>\n",
       "      <td>0.812639</td>\n",
       "      <td>0.835370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795769</td>\n",
       "      <td>0.033131</td>\n",
       "      <td>82</td>\n",
       "      <td>0.820961</td>\n",
       "      <td>0.839063</td>\n",
       "      <td>0.749502</td>\n",
       "      <td>0.818935</td>\n",
       "      <td>0.770382</td>\n",
       "      <td>0.799769</td>\n",
       "      <td>0.033914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>44.527760</td>\n",
       "      <td>2.213665</td>\n",
       "      <td>0.145790</td>\n",
       "      <td>0.008579</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>{'gbc__learning_rate': 0.8714285714285716, 'gb...</td>\n",
       "      <td>0.873380</td>\n",
       "      <td>0.893380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.843519</td>\n",
       "      <td>0.060192</td>\n",
       "      <td>64</td>\n",
       "      <td>0.880961</td>\n",
       "      <td>0.898947</td>\n",
       "      <td>0.740440</td>\n",
       "      <td>0.896759</td>\n",
       "      <td>0.829630</td>\n",
       "      <td>0.849347</td>\n",
       "      <td>0.059928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>71.016171</td>\n",
       "      <td>3.500105</td>\n",
       "      <td>0.210348</td>\n",
       "      <td>0.019203</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>{'gbc__learning_rate': 0.8714285714285716, 'gb...</td>\n",
       "      <td>0.895694</td>\n",
       "      <td>0.910694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857278</td>\n",
       "      <td>0.070655</td>\n",
       "      <td>58</td>\n",
       "      <td>0.901863</td>\n",
       "      <td>0.917650</td>\n",
       "      <td>0.746030</td>\n",
       "      <td>0.934086</td>\n",
       "      <td>0.817211</td>\n",
       "      <td>0.863368</td>\n",
       "      <td>0.071173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>97.561630</td>\n",
       "      <td>5.220811</td>\n",
       "      <td>0.275397</td>\n",
       "      <td>0.021291</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "      <td>{'gbc__learning_rate': 0.8714285714285716, 'gb...</td>\n",
       "      <td>0.900787</td>\n",
       "      <td>0.924167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.863806</td>\n",
       "      <td>0.072982</td>\n",
       "      <td>56</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.930231</td>\n",
       "      <td>0.747905</td>\n",
       "      <td>0.941285</td>\n",
       "      <td>0.823553</td>\n",
       "      <td>0.869727</td>\n",
       "      <td>0.073546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>125.170987</td>\n",
       "      <td>6.863720</td>\n",
       "      <td>0.330843</td>\n",
       "      <td>0.015858</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>{'gbc__learning_rate': 0.8714285714285716, 'gb...</td>\n",
       "      <td>0.906204</td>\n",
       "      <td>0.929259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.868694</td>\n",
       "      <td>0.074256</td>\n",
       "      <td>55</td>\n",
       "      <td>0.912049</td>\n",
       "      <td>0.935428</td>\n",
       "      <td>0.751887</td>\n",
       "      <td>0.949699</td>\n",
       "      <td>0.825810</td>\n",
       "      <td>0.874975</td>\n",
       "      <td>0.075074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>151.060037</td>\n",
       "      <td>7.857128</td>\n",
       "      <td>0.387775</td>\n",
       "      <td>0.015946</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>3</td>\n",
       "      <td>85</td>\n",
       "      <td>{'gbc__learning_rate': 0.8714285714285716, 'gb...</td>\n",
       "      <td>0.910093</td>\n",
       "      <td>0.932593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.872333</td>\n",
       "      <td>0.075660</td>\n",
       "      <td>53</td>\n",
       "      <td>0.916030</td>\n",
       "      <td>0.938704</td>\n",
       "      <td>0.752095</td>\n",
       "      <td>0.955104</td>\n",
       "      <td>0.829491</td>\n",
       "      <td>0.878285</td>\n",
       "      <td>0.076526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>176.960377</td>\n",
       "      <td>9.581642</td>\n",
       "      <td>0.452891</td>\n",
       "      <td>0.030454</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'gbc__learning_rate': 0.8714285714285716, 'gb...</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.934583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.874259</td>\n",
       "      <td>0.076226</td>\n",
       "      <td>50</td>\n",
       "      <td>0.919873</td>\n",
       "      <td>0.940498</td>\n",
       "      <td>0.753032</td>\n",
       "      <td>0.957778</td>\n",
       "      <td>0.831181</td>\n",
       "      <td>0.880472</td>\n",
       "      <td>0.077204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>8.331456</td>\n",
       "      <td>0.294646</td>\n",
       "      <td>0.069092</td>\n",
       "      <td>0.006847</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'gbc__learning_rate': 1.0, 'gbc__max_depth': ...</td>\n",
       "      <td>0.576204</td>\n",
       "      <td>0.608380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580852</td>\n",
       "      <td>0.028099</td>\n",
       "      <td>165</td>\n",
       "      <td>0.577326</td>\n",
       "      <td>0.611516</td>\n",
       "      <td>0.609954</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.576632</td>\n",
       "      <td>0.581752</td>\n",
       "      <td>0.028536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>24.906434</td>\n",
       "      <td>0.877885</td>\n",
       "      <td>0.101210</td>\n",
       "      <td>0.009351</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'gbc__learning_rate': 1.0, 'gbc__max_depth': ...</td>\n",
       "      <td>0.597685</td>\n",
       "      <td>0.642917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.613815</td>\n",
       "      <td>0.031882</td>\n",
       "      <td>158</td>\n",
       "      <td>0.599398</td>\n",
       "      <td>0.645845</td>\n",
       "      <td>0.650984</td>\n",
       "      <td>0.563993</td>\n",
       "      <td>0.617315</td>\n",
       "      <td>0.615507</td>\n",
       "      <td>0.031923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>40.168039</td>\n",
       "      <td>1.461550</td>\n",
       "      <td>0.144523</td>\n",
       "      <td>0.006293</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>{'gbc__learning_rate': 1.0, 'gbc__max_depth': ...</td>\n",
       "      <td>0.601019</td>\n",
       "      <td>0.647593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617148</td>\n",
       "      <td>0.030745</td>\n",
       "      <td>155</td>\n",
       "      <td>0.601875</td>\n",
       "      <td>0.650683</td>\n",
       "      <td>0.649468</td>\n",
       "      <td>0.568125</td>\n",
       "      <td>0.619942</td>\n",
       "      <td>0.618019</td>\n",
       "      <td>0.031015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>55.516684</td>\n",
       "      <td>1.623710</td>\n",
       "      <td>0.176603</td>\n",
       "      <td>0.007155</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>{'gbc__learning_rate': 1.0, 'gbc__max_depth': ...</td>\n",
       "      <td>0.603611</td>\n",
       "      <td>0.651898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620546</td>\n",
       "      <td>0.031298</td>\n",
       "      <td>152</td>\n",
       "      <td>0.604248</td>\n",
       "      <td>0.653924</td>\n",
       "      <td>0.656898</td>\n",
       "      <td>0.572917</td>\n",
       "      <td>0.619514</td>\n",
       "      <td>0.621500</td>\n",
       "      <td>0.031516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>71.707712</td>\n",
       "      <td>2.999030</td>\n",
       "      <td>0.195154</td>\n",
       "      <td>0.002699</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>{'gbc__learning_rate': 1.0, 'gbc__max_depth': ...</td>\n",
       "      <td>0.603704</td>\n",
       "      <td>0.652315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.621139</td>\n",
       "      <td>0.029845</td>\n",
       "      <td>151</td>\n",
       "      <td>0.604537</td>\n",
       "      <td>0.654942</td>\n",
       "      <td>0.656516</td>\n",
       "      <td>0.577731</td>\n",
       "      <td>0.617917</td>\n",
       "      <td>0.622329</td>\n",
       "      <td>0.030191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>87.176071</td>\n",
       "      <td>2.735793</td>\n",
       "      <td>0.234474</td>\n",
       "      <td>0.006094</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>{'gbc__learning_rate': 1.0, 'gbc__max_depth': ...</td>\n",
       "      <td>0.603704</td>\n",
       "      <td>0.652315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.621778</td>\n",
       "      <td>0.029928</td>\n",
       "      <td>150</td>\n",
       "      <td>0.604537</td>\n",
       "      <td>0.654942</td>\n",
       "      <td>0.657338</td>\n",
       "      <td>0.578403</td>\n",
       "      <td>0.619734</td>\n",
       "      <td>0.622991</td>\n",
       "      <td>0.030133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>103.754173</td>\n",
       "      <td>3.886397</td>\n",
       "      <td>0.285757</td>\n",
       "      <td>0.022025</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'gbc__learning_rate': 1.0, 'gbc__max_depth': ...</td>\n",
       "      <td>0.603704</td>\n",
       "      <td>0.652315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.622704</td>\n",
       "      <td>0.029683</td>\n",
       "      <td>148</td>\n",
       "      <td>0.604537</td>\n",
       "      <td>0.654942</td>\n",
       "      <td>0.657720</td>\n",
       "      <td>0.579294</td>\n",
       "      <td>0.622755</td>\n",
       "      <td>0.623850</td>\n",
       "      <td>0.029911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>11.278801</td>\n",
       "      <td>0.531691</td>\n",
       "      <td>0.063082</td>\n",
       "      <td>0.003269</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>{'gbc__learning_rate': 1.0, 'gbc__max_depth': ...</td>\n",
       "      <td>0.677176</td>\n",
       "      <td>0.651667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.679880</td>\n",
       "      <td>0.017060</td>\n",
       "      <td>127</td>\n",
       "      <td>0.679653</td>\n",
       "      <td>0.654653</td>\n",
       "      <td>0.696181</td>\n",
       "      <td>0.679850</td>\n",
       "      <td>0.699896</td>\n",
       "      <td>0.682046</td>\n",
       "      <td>0.015996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>32.222280</td>\n",
       "      <td>2.430533</td>\n",
       "      <td>0.128139</td>\n",
       "      <td>0.024657</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>{'gbc__learning_rate': 1.0, 'gbc__max_depth': ...</td>\n",
       "      <td>0.754352</td>\n",
       "      <td>0.554259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.712926</td>\n",
       "      <td>0.084125</td>\n",
       "      <td>103</td>\n",
       "      <td>0.757199</td>\n",
       "      <td>0.555347</td>\n",
       "      <td>0.744988</td>\n",
       "      <td>0.714294</td>\n",
       "      <td>0.805775</td>\n",
       "      <td>0.715521</td>\n",
       "      <td>0.085333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>55.814899</td>\n",
       "      <td>13.547514</td>\n",
       "      <td>0.190176</td>\n",
       "      <td>0.039847</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>{'gbc__learning_rate': 1.0, 'gbc__max_depth': ...</td>\n",
       "      <td>0.778889</td>\n",
       "      <td>0.104120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.602593</td>\n",
       "      <td>0.262917</td>\n",
       "      <td>161</td>\n",
       "      <td>0.780926</td>\n",
       "      <td>0.102778</td>\n",
       "      <td>0.578414</td>\n",
       "      <td>0.726551</td>\n",
       "      <td>0.834317</td>\n",
       "      <td>0.604597</td>\n",
       "      <td>0.265045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>80.187529</td>\n",
       "      <td>25.710212</td>\n",
       "      <td>0.220587</td>\n",
       "      <td>0.050721</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>{'gbc__learning_rate': 1.0, 'gbc__max_depth': ...</td>\n",
       "      <td>0.787176</td>\n",
       "      <td>0.104120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.609676</td>\n",
       "      <td>0.268948</td>\n",
       "      <td>160</td>\n",
       "      <td>0.789074</td>\n",
       "      <td>0.102778</td>\n",
       "      <td>0.574757</td>\n",
       "      <td>0.739363</td>\n",
       "      <td>0.855324</td>\n",
       "      <td>0.612259</td>\n",
       "      <td>0.271100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>104.213814</td>\n",
       "      <td>37.360088</td>\n",
       "      <td>0.288585</td>\n",
       "      <td>0.046036</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>{'gbc__learning_rate': 1.0, 'gbc__max_depth': ...</td>\n",
       "      <td>0.791991</td>\n",
       "      <td>0.104120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.612833</td>\n",
       "      <td>0.269043</td>\n",
       "      <td>159</td>\n",
       "      <td>0.793403</td>\n",
       "      <td>0.102778</td>\n",
       "      <td>0.582338</td>\n",
       "      <td>0.749294</td>\n",
       "      <td>0.849456</td>\n",
       "      <td>0.615454</td>\n",
       "      <td>0.271392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>135.224506</td>\n",
       "      <td>50.756753</td>\n",
       "      <td>0.324581</td>\n",
       "      <td>0.050711</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>{'gbc__learning_rate': 1.0, 'gbc__max_depth': ...</td>\n",
       "      <td>0.801111</td>\n",
       "      <td>0.104120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.615926</td>\n",
       "      <td>0.270845</td>\n",
       "      <td>157</td>\n",
       "      <td>0.800764</td>\n",
       "      <td>0.102778</td>\n",
       "      <td>0.583785</td>\n",
       "      <td>0.754595</td>\n",
       "      <td>0.849977</td>\n",
       "      <td>0.618380</td>\n",
       "      <td>0.272946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>152.597561</td>\n",
       "      <td>62.726451</td>\n",
       "      <td>0.373291</td>\n",
       "      <td>0.065272</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'gbc__learning_rate': 1.0, 'gbc__max_depth': ...</td>\n",
       "      <td>0.801343</td>\n",
       "      <td>0.104120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.618546</td>\n",
       "      <td>0.272495</td>\n",
       "      <td>153</td>\n",
       "      <td>0.802593</td>\n",
       "      <td>0.102778</td>\n",
       "      <td>0.583704</td>\n",
       "      <td>0.760394</td>\n",
       "      <td>0.854606</td>\n",
       "      <td>0.620815</td>\n",
       "      <td>0.274563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>16.134313</td>\n",
       "      <td>0.585144</td>\n",
       "      <td>0.076820</td>\n",
       "      <td>0.004614</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'gbc__learning_rate': 1.0, 'gbc__max_depth': ...</td>\n",
       "      <td>0.763056</td>\n",
       "      <td>0.782269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.781083</td>\n",
       "      <td>0.027225</td>\n",
       "      <td>88</td>\n",
       "      <td>0.770475</td>\n",
       "      <td>0.784873</td>\n",
       "      <td>0.802535</td>\n",
       "      <td>0.822315</td>\n",
       "      <td>0.745637</td>\n",
       "      <td>0.785167</td>\n",
       "      <td>0.026307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>42.496906</td>\n",
       "      <td>2.087939</td>\n",
       "      <td>0.142619</td>\n",
       "      <td>0.009162</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>{'gbc__learning_rate': 1.0, 'gbc__max_depth': ...</td>\n",
       "      <td>0.788843</td>\n",
       "      <td>0.837639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.813176</td>\n",
       "      <td>0.040369</td>\n",
       "      <td>75</td>\n",
       "      <td>0.795556</td>\n",
       "      <td>0.842512</td>\n",
       "      <td>0.816736</td>\n",
       "      <td>0.873669</td>\n",
       "      <td>0.756458</td>\n",
       "      <td>0.816986</td>\n",
       "      <td>0.039969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>73.325338</td>\n",
       "      <td>2.539597</td>\n",
       "      <td>0.215886</td>\n",
       "      <td>0.015721</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>{'gbc__learning_rate': 1.0, 'gbc__max_depth': ...</td>\n",
       "      <td>0.756898</td>\n",
       "      <td>0.830926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786898</td>\n",
       "      <td>0.029373</td>\n",
       "      <td>87</td>\n",
       "      <td>0.763877</td>\n",
       "      <td>0.835613</td>\n",
       "      <td>0.779028</td>\n",
       "      <td>0.816076</td>\n",
       "      <td>0.763322</td>\n",
       "      <td>0.791583</td>\n",
       "      <td>0.029198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>100.840654</td>\n",
       "      <td>5.626475</td>\n",
       "      <td>0.265187</td>\n",
       "      <td>0.011509</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "      <td>{'gbc__learning_rate': 1.0, 'gbc__max_depth': ...</td>\n",
       "      <td>0.760556</td>\n",
       "      <td>0.831019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.801315</td>\n",
       "      <td>0.041509</td>\n",
       "      <td>77</td>\n",
       "      <td>0.767396</td>\n",
       "      <td>0.835822</td>\n",
       "      <td>0.779491</td>\n",
       "      <td>0.875579</td>\n",
       "      <td>0.776354</td>\n",
       "      <td>0.806928</td>\n",
       "      <td>0.041948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>128.440894</td>\n",
       "      <td>6.642943</td>\n",
       "      <td>0.322707</td>\n",
       "      <td>0.017128</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>{'gbc__learning_rate': 1.0, 'gbc__max_depth': ...</td>\n",
       "      <td>0.758750</td>\n",
       "      <td>0.833796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798009</td>\n",
       "      <td>0.033578</td>\n",
       "      <td>79</td>\n",
       "      <td>0.765845</td>\n",
       "      <td>0.838565</td>\n",
       "      <td>0.785428</td>\n",
       "      <td>0.848785</td>\n",
       "      <td>0.778657</td>\n",
       "      <td>0.803456</td>\n",
       "      <td>0.033591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>157.461096</td>\n",
       "      <td>6.553847</td>\n",
       "      <td>0.370886</td>\n",
       "      <td>0.015240</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>85</td>\n",
       "      <td>{'gbc__learning_rate': 1.0, 'gbc__max_depth': ...</td>\n",
       "      <td>0.759444</td>\n",
       "      <td>0.835741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.796213</td>\n",
       "      <td>0.029899</td>\n",
       "      <td>81</td>\n",
       "      <td>0.766250</td>\n",
       "      <td>0.840174</td>\n",
       "      <td>0.791829</td>\n",
       "      <td>0.830914</td>\n",
       "      <td>0.776111</td>\n",
       "      <td>0.801056</td>\n",
       "      <td>0.029464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>170.493785</td>\n",
       "      <td>19.088221</td>\n",
       "      <td>0.344743</td>\n",
       "      <td>0.070998</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'gbc__learning_rate': 1.0, 'gbc__max_depth': ...</td>\n",
       "      <td>0.759491</td>\n",
       "      <td>0.836389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.799231</td>\n",
       "      <td>0.034501</td>\n",
       "      <td>78</td>\n",
       "      <td>0.766331</td>\n",
       "      <td>0.840764</td>\n",
       "      <td>0.794363</td>\n",
       "      <td>0.849155</td>\n",
       "      <td>0.770718</td>\n",
       "      <td>0.804266</td>\n",
       "      <td>0.034669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        10.000124      0.216395         0.072209        0.009804   \n",
       "1        21.465018      0.751115         0.103106        0.006266   \n",
       "2        32.859259      0.272400         0.146268        0.001588   \n",
       "3        50.343044      2.240957         0.197599        0.017383   \n",
       "4        58.678673      1.581699         0.236860        0.007721   \n",
       "5        70.143752      0.421753         0.289088        0.022960   \n",
       "6        82.869452      0.874638         0.318968        0.004510   \n",
       "7        12.327048      0.173426         0.073684        0.007179   \n",
       "8        32.380767      1.334099         0.137466        0.013890   \n",
       "9        52.557128      2.082649         0.184326        0.017956   \n",
       "10       68.264497      0.698086         0.233126        0.002568   \n",
       "11       86.367007      0.352757         0.290603        0.010691   \n",
       "12      104.790304      0.361888         0.340625        0.015081   \n",
       "13      123.854204      0.530788         0.386210        0.005326   \n",
       "14       17.071684      0.292955         0.080385        0.005447   \n",
       "15       42.603677      0.112104         0.146940        0.003008   \n",
       "16       68.068799      0.115778         0.212632        0.002044   \n",
       "17       93.546063      0.639949         0.276050        0.003291   \n",
       "18      119.473614      1.046381         0.336403        0.003617   \n",
       "19      144.045514      0.752579         0.399223        0.006099   \n",
       "20      169.275392      0.499545         0.480153        0.014185   \n",
       "21        8.299250      0.076714         0.060638        0.001716   \n",
       "22       20.591975      0.162261         0.101182        0.004123   \n",
       "23       32.807524      0.304471         0.147694        0.005301   \n",
       "24       45.161011      0.550502         0.191562        0.007782   \n",
       "25       57.950363      0.827168         0.236983        0.006063   \n",
       "26       71.296082      2.443681         0.281002        0.013184   \n",
       "27       86.047799      2.088110         0.319901        0.003827   \n",
       "28       12.212018      0.051074         0.073218        0.004990   \n",
       "29       30.892759      0.160707         0.120296        0.003533   \n",
       "..             ...           ...              ...             ...   \n",
       "138     106.332794      2.902193         0.326117        0.015116   \n",
       "139     125.892016      3.508273         0.375623        0.021911   \n",
       "140      17.231455      0.574736         0.081304        0.007961   \n",
       "141      44.527760      2.213665         0.145790        0.008579   \n",
       "142      71.016171      3.500105         0.210348        0.019203   \n",
       "143      97.561630      5.220811         0.275397        0.021291   \n",
       "144     125.170987      6.863720         0.330843        0.015858   \n",
       "145     151.060037      7.857128         0.387775        0.015946   \n",
       "146     176.960377      9.581642         0.452891        0.030454   \n",
       "147       8.331456      0.294646         0.069092        0.006847   \n",
       "148      24.906434      0.877885         0.101210        0.009351   \n",
       "149      40.168039      1.461550         0.144523        0.006293   \n",
       "150      55.516684      1.623710         0.176603        0.007155   \n",
       "151      71.707712      2.999030         0.195154        0.002699   \n",
       "152      87.176071      2.735793         0.234474        0.006094   \n",
       "153     103.754173      3.886397         0.285757        0.022025   \n",
       "154      11.278801      0.531691         0.063082        0.003269   \n",
       "155      32.222280      2.430533         0.128139        0.024657   \n",
       "156      55.814899     13.547514         0.190176        0.039847   \n",
       "157      80.187529     25.710212         0.220587        0.050721   \n",
       "158     104.213814     37.360088         0.288585        0.046036   \n",
       "159     135.224506     50.756753         0.324581        0.050711   \n",
       "160     152.597561     62.726451         0.373291        0.065272   \n",
       "161      16.134313      0.585144         0.076820        0.004614   \n",
       "162      42.496906      2.087939         0.142619        0.009162   \n",
       "163      73.325338      2.539597         0.215886        0.015721   \n",
       "164     100.840654      5.626475         0.265187        0.011509   \n",
       "165     128.440894      6.642943         0.322707        0.017128   \n",
       "166     157.461096      6.553847         0.370886        0.015240   \n",
       "167     170.493785     19.088221         0.344743        0.070998   \n",
       "\n",
       "    param_gbc__learning_rate param_gbc__max_depth param_gbc__n_estimators  \\\n",
       "0                        0.1                    1                      10   \n",
       "1                        0.1                    1                      25   \n",
       "2                        0.1                    1                      40   \n",
       "3                        0.1                    1                      55   \n",
       "4                        0.1                    1                      70   \n",
       "5                        0.1                    1                      85   \n",
       "6                        0.1                    1                     100   \n",
       "7                        0.1                    2                      10   \n",
       "8                        0.1                    2                      25   \n",
       "9                        0.1                    2                      40   \n",
       "10                       0.1                    2                      55   \n",
       "11                       0.1                    2                      70   \n",
       "12                       0.1                    2                      85   \n",
       "13                       0.1                    2                     100   \n",
       "14                       0.1                    3                      10   \n",
       "15                       0.1                    3                      25   \n",
       "16                       0.1                    3                      40   \n",
       "17                       0.1                    3                      55   \n",
       "18                       0.1                    3                      70   \n",
       "19                       0.1                    3                      85   \n",
       "20                       0.1                    3                     100   \n",
       "21                  0.228571                    1                      10   \n",
       "22                  0.228571                    1                      25   \n",
       "23                  0.228571                    1                      40   \n",
       "24                  0.228571                    1                      55   \n",
       "25                  0.228571                    1                      70   \n",
       "26                  0.228571                    1                      85   \n",
       "27                  0.228571                    1                     100   \n",
       "28                  0.228571                    2                      10   \n",
       "29                  0.228571                    2                      25   \n",
       "..                       ...                  ...                     ...   \n",
       "138                 0.871429                    2                      85   \n",
       "139                 0.871429                    2                     100   \n",
       "140                 0.871429                    3                      10   \n",
       "141                 0.871429                    3                      25   \n",
       "142                 0.871429                    3                      40   \n",
       "143                 0.871429                    3                      55   \n",
       "144                 0.871429                    3                      70   \n",
       "145                 0.871429                    3                      85   \n",
       "146                 0.871429                    3                     100   \n",
       "147                        1                    1                      10   \n",
       "148                        1                    1                      25   \n",
       "149                        1                    1                      40   \n",
       "150                        1                    1                      55   \n",
       "151                        1                    1                      70   \n",
       "152                        1                    1                      85   \n",
       "153                        1                    1                     100   \n",
       "154                        1                    2                      10   \n",
       "155                        1                    2                      25   \n",
       "156                        1                    2                      40   \n",
       "157                        1                    2                      55   \n",
       "158                        1                    2                      70   \n",
       "159                        1                    2                      85   \n",
       "160                        1                    2                     100   \n",
       "161                        1                    3                      10   \n",
       "162                        1                    3                      25   \n",
       "163                        1                    3                      40   \n",
       "164                        1                    3                      55   \n",
       "165                        1                    3                      70   \n",
       "166                        1                    3                      85   \n",
       "167                        1                    3                     100   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "0    {'gbc__learning_rate': 0.1, 'gbc__max_depth': ...           0.517130   \n",
       "1    {'gbc__learning_rate': 0.1, 'gbc__max_depth': ...           0.570324   \n",
       "2    {'gbc__learning_rate': 0.1, 'gbc__max_depth': ...           0.595972   \n",
       "3    {'gbc__learning_rate': 0.1, 'gbc__max_depth': ...           0.618009   \n",
       "4    {'gbc__learning_rate': 0.1, 'gbc__max_depth': ...           0.626667   \n",
       "5    {'gbc__learning_rate': 0.1, 'gbc__max_depth': ...           0.636759   \n",
       "6    {'gbc__learning_rate': 0.1, 'gbc__max_depth': ...           0.653981   \n",
       "7    {'gbc__learning_rate': 0.1, 'gbc__max_depth': ...           0.592500   \n",
       "8    {'gbc__learning_rate': 0.1, 'gbc__max_depth': ...           0.640417   \n",
       "9    {'gbc__learning_rate': 0.1, 'gbc__max_depth': ...           0.694861   \n",
       "10   {'gbc__learning_rate': 0.1, 'gbc__max_depth': ...           0.734769   \n",
       "11   {'gbc__learning_rate': 0.1, 'gbc__max_depth': ...           0.754398   \n",
       "12   {'gbc__learning_rate': 0.1, 'gbc__max_depth': ...           0.771019   \n",
       "13   {'gbc__learning_rate': 0.1, 'gbc__max_depth': ...           0.787222   \n",
       "14   {'gbc__learning_rate': 0.1, 'gbc__max_depth': ...           0.646435   \n",
       "15   {'gbc__learning_rate': 0.1, 'gbc__max_depth': ...           0.734213   \n",
       "16   {'gbc__learning_rate': 0.1, 'gbc__max_depth': ...           0.808148   \n",
       "17   {'gbc__learning_rate': 0.1, 'gbc__max_depth': ...           0.839213   \n",
       "18   {'gbc__learning_rate': 0.1, 'gbc__max_depth': ...           0.858333   \n",
       "19   {'gbc__learning_rate': 0.1, 'gbc__max_depth': ...           0.874815   \n",
       "20   {'gbc__learning_rate': 0.1, 'gbc__max_depth': ...           0.885417   \n",
       "21   {'gbc__learning_rate': 0.2285714285714286, 'gb...           0.569861   \n",
       "22   {'gbc__learning_rate': 0.2285714285714286, 'gb...           0.621528   \n",
       "23   {'gbc__learning_rate': 0.2285714285714286, 'gb...           0.648935   \n",
       "24   {'gbc__learning_rate': 0.2285714285714286, 'gb...           0.671944   \n",
       "25   {'gbc__learning_rate': 0.2285714285714286, 'gb...           0.673935   \n",
       "26   {'gbc__learning_rate': 0.2285714285714286, 'gb...           0.681806   \n",
       "27   {'gbc__learning_rate': 0.2285714285714286, 'gb...           0.692963   \n",
       "28   {'gbc__learning_rate': 0.2285714285714286, 'gb...           0.631944   \n",
       "29   {'gbc__learning_rate': 0.2285714285714286, 'gb...           0.743611   \n",
       "..                                                 ...                ...   \n",
       "138  {'gbc__learning_rate': 0.8714285714285716, 'gb...           0.797963   \n",
       "139  {'gbc__learning_rate': 0.8714285714285716, 'gb...           0.815046   \n",
       "140  {'gbc__learning_rate': 0.8714285714285716, 'gb...           0.812639   \n",
       "141  {'gbc__learning_rate': 0.8714285714285716, 'gb...           0.873380   \n",
       "142  {'gbc__learning_rate': 0.8714285714285716, 'gb...           0.895694   \n",
       "143  {'gbc__learning_rate': 0.8714285714285716, 'gb...           0.900787   \n",
       "144  {'gbc__learning_rate': 0.8714285714285716, 'gb...           0.906204   \n",
       "145  {'gbc__learning_rate': 0.8714285714285716, 'gb...           0.910093   \n",
       "146  {'gbc__learning_rate': 0.8714285714285716, 'gb...           0.912500   \n",
       "147  {'gbc__learning_rate': 1.0, 'gbc__max_depth': ...           0.576204   \n",
       "148  {'gbc__learning_rate': 1.0, 'gbc__max_depth': ...           0.597685   \n",
       "149  {'gbc__learning_rate': 1.0, 'gbc__max_depth': ...           0.601019   \n",
       "150  {'gbc__learning_rate': 1.0, 'gbc__max_depth': ...           0.603611   \n",
       "151  {'gbc__learning_rate': 1.0, 'gbc__max_depth': ...           0.603704   \n",
       "152  {'gbc__learning_rate': 1.0, 'gbc__max_depth': ...           0.603704   \n",
       "153  {'gbc__learning_rate': 1.0, 'gbc__max_depth': ...           0.603704   \n",
       "154  {'gbc__learning_rate': 1.0, 'gbc__max_depth': ...           0.677176   \n",
       "155  {'gbc__learning_rate': 1.0, 'gbc__max_depth': ...           0.754352   \n",
       "156  {'gbc__learning_rate': 1.0, 'gbc__max_depth': ...           0.778889   \n",
       "157  {'gbc__learning_rate': 1.0, 'gbc__max_depth': ...           0.787176   \n",
       "158  {'gbc__learning_rate': 1.0, 'gbc__max_depth': ...           0.791991   \n",
       "159  {'gbc__learning_rate': 1.0, 'gbc__max_depth': ...           0.801111   \n",
       "160  {'gbc__learning_rate': 1.0, 'gbc__max_depth': ...           0.801343   \n",
       "161  {'gbc__learning_rate': 1.0, 'gbc__max_depth': ...           0.763056   \n",
       "162  {'gbc__learning_rate': 1.0, 'gbc__max_depth': ...           0.788843   \n",
       "163  {'gbc__learning_rate': 1.0, 'gbc__max_depth': ...           0.756898   \n",
       "164  {'gbc__learning_rate': 1.0, 'gbc__max_depth': ...           0.760556   \n",
       "165  {'gbc__learning_rate': 1.0, 'gbc__max_depth': ...           0.758750   \n",
       "166  {'gbc__learning_rate': 1.0, 'gbc__max_depth': ...           0.759444   \n",
       "167  {'gbc__learning_rate': 1.0, 'gbc__max_depth': ...           0.759491   \n",
       "\n",
       "     split1_test_score  ...  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0             0.515556  ...         0.517935        0.002437              168   \n",
       "1             0.571111  ...         0.572602        0.002474              166   \n",
       "2             0.592037  ...         0.598963        0.005412              163   \n",
       "3             0.615648  ...         0.616806        0.001531              156   \n",
       "4             0.623843  ...         0.627602        0.002440              147   \n",
       "5             0.635787  ...         0.639083        0.002613              143   \n",
       "6             0.653102  ...         0.653639        0.001778              139   \n",
       "7             0.592963  ...         0.593611        0.003733              164   \n",
       "8             0.646898  ...         0.648713        0.005360              141   \n",
       "9             0.695463  ...         0.695620        0.003238              115   \n",
       "10            0.742500  ...         0.736306        0.003406               96   \n",
       "11            0.754907  ...         0.757120        0.002859               91   \n",
       "12            0.776481  ...         0.775796        0.005156               89   \n",
       "13            0.789491  ...         0.794083        0.005567               83   \n",
       "14            0.648796  ...         0.655435        0.006456              137   \n",
       "15            0.740972  ...         0.739806        0.004869               94   \n",
       "16            0.802546  ...         0.801833        0.003608               76   \n",
       "17            0.838102  ...         0.839176        0.001906               67   \n",
       "18            0.863565  ...         0.861759        0.001824               57   \n",
       "19            0.879352  ...         0.877222        0.002801               49   \n",
       "20            0.890185  ...         0.890370        0.002939               43   \n",
       "21            0.564259  ...         0.569269        0.003279              167   \n",
       "22            0.617639  ...         0.622537        0.003426              149   \n",
       "23            0.646435  ...         0.652324        0.004112              140   \n",
       "24            0.668241  ...         0.671324        0.002624              133   \n",
       "25            0.677593  ...         0.677648        0.002930              130   \n",
       "26            0.688472  ...         0.685333        0.002681              123   \n",
       "27            0.693889  ...         0.696889        0.002917              113   \n",
       "28            0.635833  ...         0.644102        0.008699              142   \n",
       "29            0.745231  ...         0.744231        0.000600               93   \n",
       "..                 ...  ...              ...             ...              ...   \n",
       "138           0.885370  ...         0.838833        0.048147               68   \n",
       "139           0.893194  ...         0.847093        0.050582               62   \n",
       "140           0.835370  ...         0.795769        0.033131               82   \n",
       "141           0.893380  ...         0.843519        0.060192               64   \n",
       "142           0.910694  ...         0.857278        0.070655               58   \n",
       "143           0.924167  ...         0.863806        0.072982               56   \n",
       "144           0.929259  ...         0.868694        0.074256               55   \n",
       "145           0.932593  ...         0.872333        0.075660               53   \n",
       "146           0.934583  ...         0.874259        0.076226               50   \n",
       "147           0.608380  ...         0.580852        0.028099              165   \n",
       "148           0.642917  ...         0.613815        0.031882              158   \n",
       "149           0.647593  ...         0.617148        0.030745              155   \n",
       "150           0.651898  ...         0.620546        0.031298              152   \n",
       "151           0.652315  ...         0.621139        0.029845              151   \n",
       "152           0.652315  ...         0.621778        0.029928              150   \n",
       "153           0.652315  ...         0.622704        0.029683              148   \n",
       "154           0.651667  ...         0.679880        0.017060              127   \n",
       "155           0.554259  ...         0.712926        0.084125              103   \n",
       "156           0.104120  ...         0.602593        0.262917              161   \n",
       "157           0.104120  ...         0.609676        0.268948              160   \n",
       "158           0.104120  ...         0.612833        0.269043              159   \n",
       "159           0.104120  ...         0.615926        0.270845              157   \n",
       "160           0.104120  ...         0.618546        0.272495              153   \n",
       "161           0.782269  ...         0.781083        0.027225               88   \n",
       "162           0.837639  ...         0.813176        0.040369               75   \n",
       "163           0.830926  ...         0.786898        0.029373               87   \n",
       "164           0.831019  ...         0.801315        0.041509               77   \n",
       "165           0.833796  ...         0.798009        0.033578               79   \n",
       "166           0.835741  ...         0.796213        0.029899               81   \n",
       "167           0.836389  ...         0.799231        0.034501               78   \n",
       "\n",
       "     split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0              0.517326            0.517280            0.518484   \n",
       "1              0.572905            0.573530            0.573576   \n",
       "2              0.599433            0.595880            0.604884   \n",
       "3              0.620336            0.619942            0.615266   \n",
       "4              0.630451            0.628553            0.628669   \n",
       "5              0.639317            0.639375            0.638970   \n",
       "6              0.657847            0.655127            0.653947   \n",
       "7              0.597616            0.595359            0.589711   \n",
       "8              0.647616            0.651111            0.653032   \n",
       "9              0.701076            0.695417            0.700069   \n",
       "10             0.741215            0.746123            0.733102   \n",
       "11             0.761262            0.758287            0.760799   \n",
       "12             0.778044            0.779850            0.777396   \n",
       "13             0.795521            0.792465            0.803912   \n",
       "14             0.652685            0.650637            0.658368   \n",
       "15             0.741655            0.743044            0.740972   \n",
       "16             0.813449            0.806366            0.799803   \n",
       "17             0.845903            0.840729            0.837465   \n",
       "18             0.867002            0.866250            0.864537   \n",
       "19             0.883553            0.882477            0.878345   \n",
       "20             0.893669            0.895174            0.895000   \n",
       "21             0.572662            0.568333            0.569722   \n",
       "22             0.624907            0.621389            0.621331   \n",
       "23             0.651620            0.650498            0.655775   \n",
       "24             0.676007            0.670567            0.672141   \n",
       "25             0.679190            0.677697            0.679514   \n",
       "26             0.688403            0.688368            0.686227   \n",
       "27             0.700023            0.693958            0.697789   \n",
       "28             0.638831            0.638206            0.652315   \n",
       "29             0.749028            0.748553            0.746516   \n",
       "..                  ...                 ...                 ...   \n",
       "138            0.806250            0.893877            0.777106   \n",
       "139            0.822789            0.902373            0.772662   \n",
       "140            0.820961            0.839063            0.749502   \n",
       "141            0.880961            0.898947            0.740440   \n",
       "142            0.901863            0.917650            0.746030   \n",
       "143            0.905660            0.930231            0.747905   \n",
       "144            0.912049            0.935428            0.751887   \n",
       "145            0.916030            0.938704            0.752095   \n",
       "146            0.919873            0.940498            0.753032   \n",
       "147            0.577326            0.611516            0.609954   \n",
       "148            0.599398            0.645845            0.650984   \n",
       "149            0.601875            0.650683            0.649468   \n",
       "150            0.604248            0.653924            0.656898   \n",
       "151            0.604537            0.654942            0.656516   \n",
       "152            0.604537            0.654942            0.657338   \n",
       "153            0.604537            0.654942            0.657720   \n",
       "154            0.679653            0.654653            0.696181   \n",
       "155            0.757199            0.555347            0.744988   \n",
       "156            0.780926            0.102778            0.578414   \n",
       "157            0.789074            0.102778            0.574757   \n",
       "158            0.793403            0.102778            0.582338   \n",
       "159            0.800764            0.102778            0.583785   \n",
       "160            0.802593            0.102778            0.583704   \n",
       "161            0.770475            0.784873            0.802535   \n",
       "162            0.795556            0.842512            0.816736   \n",
       "163            0.763877            0.835613            0.779028   \n",
       "164            0.767396            0.835822            0.779491   \n",
       "165            0.765845            0.838565            0.785428   \n",
       "166            0.766250            0.840174            0.791829   \n",
       "167            0.766331            0.840764            0.794363   \n",
       "\n",
       "     split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0              0.518113            0.519942          0.518229         0.000972  \n",
       "1              0.572940            0.575058          0.573602         0.000781  \n",
       "2              0.597488            0.604271          0.600391         0.003604  \n",
       "3              0.617500            0.615347          0.617678         0.002167  \n",
       "4              0.628611            0.627512          0.628759         0.000948  \n",
       "5              0.643715            0.641296          0.640535         0.001787  \n",
       "6              0.655729            0.651539          0.654838         0.002079  \n",
       "7              0.595081            0.596771          0.594907         0.002759  \n",
       "8              0.653160            0.648970          0.650778         0.002197  \n",
       "9              0.697512            0.693600          0.697535         0.002791  \n",
       "10             0.734178            0.738252          0.738574         0.004761  \n",
       "11             0.760625            0.759062          0.760007         0.001134  \n",
       "12             0.784213            0.774363          0.778773         0.003244  \n",
       "13             0.798669            0.797581          0.797630         0.003786  \n",
       "14             0.660625            0.660521          0.656567         0.004137  \n",
       "15             0.737963            0.747940          0.742315         0.003266  \n",
       "16             0.799537            0.802697          0.804370         0.005166  \n",
       "17             0.842697            0.842350          0.841829         0.002752  \n",
       "18             0.864965            0.866100          0.865771         0.000897  \n",
       "19             0.885312            0.878125          0.881563         0.002865  \n",
       "20             0.895567            0.896424          0.895167         0.000896  \n",
       "21             0.567361            0.573380          0.570292         0.002362  \n",
       "22             0.622211            0.624525          0.622873         0.001542  \n",
       "23             0.655671            0.653762          0.653465         0.002121  \n",
       "24             0.671308            0.670058          0.672016         0.002116  \n",
       "25             0.680243            0.676574          0.678644         0.001326  \n",
       "26             0.683692            0.687708          0.686880         0.001778  \n",
       "27             0.699907            0.700984          0.698532         0.002514  \n",
       "28             0.653426            0.647315          0.646019         0.006464  \n",
       "29             0.744583            0.746204          0.746977         0.001627  \n",
       "..                  ...                 ...               ...              ...  \n",
       "138            0.901019            0.851308          0.845912         0.048319  \n",
       "139            0.909664            0.861539          0.853806         0.051157  \n",
       "140            0.818935            0.770382          0.799769         0.033914  \n",
       "141            0.896759            0.829630          0.849347         0.059928  \n",
       "142            0.934086            0.817211          0.863368         0.071173  \n",
       "143            0.941285            0.823553          0.869727         0.073546  \n",
       "144            0.949699            0.825810          0.874975         0.075074  \n",
       "145            0.955104            0.829491          0.878285         0.076526  \n",
       "146            0.957778            0.831181          0.880472         0.077204  \n",
       "147            0.533333            0.576632          0.581752         0.028536  \n",
       "148            0.563993            0.617315          0.615507         0.031923  \n",
       "149            0.568125            0.619942          0.618019         0.031015  \n",
       "150            0.572917            0.619514          0.621500         0.031516  \n",
       "151            0.577731            0.617917          0.622329         0.030191  \n",
       "152            0.578403            0.619734          0.622991         0.030133  \n",
       "153            0.579294            0.622755          0.623850         0.029911  \n",
       "154            0.679850            0.699896          0.682046         0.015996  \n",
       "155            0.714294            0.805775          0.715521         0.085333  \n",
       "156            0.726551            0.834317          0.604597         0.265045  \n",
       "157            0.739363            0.855324          0.612259         0.271100  \n",
       "158            0.749294            0.849456          0.615454         0.271392  \n",
       "159            0.754595            0.849977          0.618380         0.272946  \n",
       "160            0.760394            0.854606          0.620815         0.274563  \n",
       "161            0.822315            0.745637          0.785167         0.026307  \n",
       "162            0.873669            0.756458          0.816986         0.039969  \n",
       "163            0.816076            0.763322          0.791583         0.029198  \n",
       "164            0.875579            0.776354          0.806928         0.041948  \n",
       "165            0.848785            0.778657          0.803456         0.033591  \n",
       "166            0.830914            0.776111          0.801056         0.029464  \n",
       "167            0.849155            0.770718          0.804266         0.034669  \n",
       "\n",
       "[168 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = []\n",
    "parameters = []\n",
    "best_score = []\n",
    "roc_auc = []\n",
    "\n",
    "for k,v in estimators:\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "            #('sc', StandardScaler()),\n",
    "            (k,v)\n",
    "                    ])\n",
    "    \n",
    "    gridsearch = GridSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_grid=params[k],\n",
    "        verbose=1,\n",
    "        cv= 5,\n",
    "        n_jobs=-1,\n",
    "        return_train_score= True\n",
    "    )\n",
    "\n",
    "    gridsearch.fit(X_train, y_train)\n",
    "    \n",
    "    model = gridsearch.best_estimator_\n",
    "    cv_score = gridsearch.cv_results_\n",
    "    best_params = gridsearch.best_params_\n",
    "\n",
    "    # predict y\n",
    "    y_pred = model.predict(X_test)\n",
    "    #y_pred = model.predict_proba(X_test)\n",
    "    \n",
    "    # print results\n",
    "    print(\"Model: \", k)\n",
    "    print(\"Best parameters:\", best_params)\n",
    "    print(\"Best score:\", gridsearch.best_score_)\n",
    "    display(pd.DataFrame(cv_score, columns = cv_score.keys()))    \n",
    "    \n",
    "    # append info to list\n",
    "    models.append(k)\n",
    "    best_score.append(gridsearch.best_score_)\n",
    "    parameters.append(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lr', 'knn', 'dtc', 'rfc', 'abc', 'gbc']\n",
      "[0.5149907407407407, 0.9781481481481481, 0.5673888888888889, 0.5728518518518518, 0.4740740740740741, 0.9749629629629629]\n",
      "[{'lr__penalty': 'l1'}, {'knn__n_neighbors': 3, 'knn__weights': 'distance'}, {'dtc__max_depth': 7, 'dtc__max_features': None, 'dtc__min_samples_split': 0.1}, {'rfc__max_depth': 11, 'rfc__max_features': 'auto', 'rfc__min_samples_split': 0.1, 'rfc__n_estimators': 25}, {'abc__learning_rate': 0.3571428571428572, 'abc__n_estimators': 50}, {'gbc__learning_rate': 0.6142857142857143, 'gbc__max_depth': 3, 'gbc__n_estimators': 100}]\n"
     ]
    }
   ],
   "source": [
    "# output gridsearch results\n",
    "\n",
    "print(models)\n",
    "print(best_score)\n",
    "print(parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
